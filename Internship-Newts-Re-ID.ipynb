{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Implémentation_Triplet_loss_stage.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KszXCTSzgs3o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "b81ec6d1-80d3-4be8-ca0e-023b9a8df594"
      },
      "source": [
        "!pip install hdbscan\n",
        "!pip install umap-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCSp7HQ0btJj",
        "colab_type": "text"
      },
      "source": [
        "# Counting the different newts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMzqwU_jcKzh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        },
        "outputId": "1c8a489c-ffd2-49d2-cfd8-16279c4066e6"
      },
      "source": [
        "!pip install ax-platform\n",
        "!pip install hdbscan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYa1n__pcP0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import calinski_harabasz_score, silhouette_score, davies_bouldin_score, silhouette_samples\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "# Dimension reduction and clustering libraries\n",
        "import umap\n",
        "import hdbscan\n",
        "import sklearn.cluster as cluster\n",
        "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
        "from ax import optimize\n",
        "\n",
        "import pathlib\n",
        "import os\n",
        "import shutil\n",
        "import fnmatch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "186whbMgcae4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set(style='white', rc={'figure.figsize':(10,8)})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utb4suhfcmX1",
        "colab_type": "text"
      },
      "source": [
        "## Import the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7gXz4Osce4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "#width = 56\n",
        "#height = 56\n",
        "\n",
        "train_path = '/content/newtDataset/train'\n",
        "test_path = '/content/newtDataset/test'\n",
        "#train_path = '/content/newtDataset/train'\n",
        "\n",
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  print(parts[-2])\n",
        "  # The second to last is the class-directory\n",
        "  return parts[-2] == CLASS_NAMES\n",
        "\n",
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
        "  #img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  # resize the image to the desired size.\n",
        "  return img\n",
        "\n",
        "def process_path(file_path):\n",
        "  #print(file_path)\n",
        "  label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  try:\n",
        "    img = decode_img(img)\n",
        "    #print(np.max(img))\n",
        "    print(\"decoded\")\n",
        "    counter +=1\n",
        "  except:\n",
        "    print(\"erreur décodage\")\n",
        "\n",
        "  return img, label\n",
        "\n",
        "def format_image(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image = tf.image.rgb_to_grayscale(image)\n",
        "  image = (image/127.5) - 1\n",
        "  image = tf.image.resize(image, (input_shape[0], input_shape[1]))\n",
        "  return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPGiHdI0ckbo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "88a06b5c-bfe1-4e3a-823d-7e5f079aaba3"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "#train_path = '/content/ds_final/train'\n",
        "#test_path = '/content/ds_final/test'\n",
        "\n",
        "train_size = sum(len(files) for _, _, files in os.walk(train_path))\n",
        "print(train_size)\n",
        "test_size = sum(len(files) for _, _, files in os.walk(test_path))\n",
        "print(test_size)\n",
        "\n",
        "\n",
        "input_shape = (75,30,3)\n",
        "\n",
        "\n",
        "\n",
        "data_dir = pathlib.Path(train_path)\n",
        "test_dir = pathlib.Path(test_path)\n",
        "\n",
        "list_ds = tf.data.Dataset.list_files(str(data_dir)+'/*/*')\n",
        "list_ds_test = tf.data.Dataset.list_files(str(test_dir)+'/*/*')\n",
        "\n",
        "CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"])\n",
        "\n",
        "print(CLASS_NAMES)\n",
        "\n",
        "\n",
        "def show_batch(image_batch, label_batch):\n",
        "  plt.figure(figsize=(10,10))\n",
        "  for n in range(25):\n",
        "      ax = plt.subplot(5,5,n+1)\n",
        "      plt.imshow(image_batch[n])\n",
        "      plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n",
        "      plt.axis('off')\n",
        "\n",
        "def augment(image,label):\n",
        "  #image,label = convert(image, label)\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32) # Cast and normalize the image to [0,1]\n",
        "  #image = tf.image.rgb_to_grayscale(image)\n",
        "  #image = tf.image.resize_with_crop_or_pad(image, 34, 34) # Add 6 pixels of padding\n",
        "  #image = tf.image.random_crop(image, size=[28, 28, 1]) # Random crop back to 28x28\n",
        "  #image = tf.image.random_brightness(image, max_delta=0.5) # Random brightness\n",
        "  #image = tf.image.flip_left_right(image)\n",
        "\n",
        "  return image,label\n",
        "#Use Dataset.map to create a dataset of image, label pairs:\n",
        "\n",
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "labeled_ds_test = list_ds_test.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "\n",
        "\n",
        "train_dataset = labeled_ds.map(format_image, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "test_dataset = labeled_ds_test.map(format_image, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "count_label = len(os.listdir(train_path))\n",
        "print(count_label)\n",
        "\n",
        "x_train = np.zeros((train_size,input_shape[0],input_shape[1],input_shape[2]))\n",
        "y_train = np.zeros((train_size))\n",
        "x_test = np.zeros((test_size,input_shape[0],input_shape[1],input_shape[2]))\n",
        "y_test = np.zeros((test_size))\n",
        "\n",
        "k=0\n",
        "for image, label in train_dataset:\n",
        "  #print(label)\n",
        "  x_train[k,:,:,:] = image\n",
        "  y_train[k] = np.where(label)[0][0]\n",
        "  k += 1\n",
        "k=0\n",
        "for image, label in test_dataset:\n",
        "  x_test[k,:,:,:] = image\n",
        "  y_test[k] = np.where(label)[0][0]\n",
        "  k += 1\n",
        "  #print(np.where(label)[0])\n",
        "\n",
        "#tfds_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "#tfds_train = tfds_train.batch(32)\n",
        "#for i,j in tfds_train:\n",
        " # print(i)\n",
        "  #print(j)\n",
        "#tfds_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "#tfds_test = tfds_test.batch(32)\n",
        "  #print(\"Image shape: \", image.numpy().shape)\n",
        "  #print(\"Label: \", label.numpy())\n",
        "#print(y_train)\n",
        "\n",
        "print(\"number of individual classes : \"+ str(count_label))\n",
        "dataset = []\n",
        "dataset_test = []\n",
        "    \n",
        "#Sorting images by classes and normalize values 0=>\n",
        "for n in range(count_label):\n",
        "    images_class_n_train = np.asarray([row for idx,row in enumerate(x_train) if y_train[idx]==n])\n",
        "    dataset.append(images_class_n_train)\n",
        "\n",
        "\n",
        "    images_class_n_test = np.asarray([row for idx,row in enumerate(x_test) if y_test[idx]==n])\n",
        "    dataset_test.append(images_class_n_test)\n",
        "\n",
        "#input_shape = [width,height,3]\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaYc2rDTcuC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1]*x_train.shape[2]*x_train.shape[3]))  # adapt this if using `channels_first` image data format\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1]*x_test.shape[2]*x_test.shape[3]))  # adapt this if using `channels_first` image data format\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aue4uK87cyR8",
        "colab_type": "text"
      },
      "source": [
        "## Train the autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwZBwAV_ct8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "#x_train = x_train_lite\n",
        "#x_test = x_test_lite\n",
        "\n",
        "def autoencoder(dims, act='relu'):\n",
        "    n_stacks = len(dims) - 1\n",
        "    x = Input(shape=(dims[0],), name='input')\n",
        "    h = x\n",
        "    for i in range(n_stacks - 1):\n",
        "        h = Dense(dims[i + 1], activation=act, name='encoder_%d' % i)(h)\n",
        "    h = Dense(dims[-1], name='encoder_%d' % (n_stacks - 1))(h)\n",
        "    for i in range(n_stacks - 1, 0, -1):\n",
        "        h = Dense(dims[i], activation=act, name='decoder_%d' % i)(h)\n",
        "    h = Dense(dims[0], name='decoder_0')(h)\n",
        "\n",
        "    return Model(inputs=x, outputs=h)\n",
        "\n",
        "shape = [x_train.shape[-1], 2000, 2000, 4000, 128]\n",
        "autoencoder = autoencoder(shape)\n",
        "\n",
        "hidden = autoencoder.get_layer(name='encoder_%d' % (len(shape) - 2)).output\n",
        "encoder = Model(inputs=autoencoder.input, outputs=hidden)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-vct1vsc3-I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "589bb33b-da58-4642-a14c-e948eee417f2"
      },
      "source": [
        "autoencoder.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005))\n",
        "autoencoder.fit(\n",
        "            x_train,\n",
        "            x_train,\n",
        "            batch_size=100,\n",
        "            epochs=400,\n",
        "            validation_data=(x_test, x_test),\n",
        "            verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkOdq2m-uBzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = Input(shape=(75, 30, 3), name=\"inputs\")\n",
        "x = inputs\n",
        "\n",
        "x = Conv2D(512, (7, 7), padding=\"same\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU(alpha=0.2)(x)\n",
        "x = MaxPool2D()(x)\n",
        "\n",
        "x = Conv2D(256, (5, 5), padding=\"same\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU(alpha=0.2)(x)\n",
        "x = MaxPool2D()(x)\n",
        "\n",
        "x = Conv2D(256, (3, 3), padding=\"same\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU(alpha=0.2)(x)\n",
        "x = MaxPool2D()(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "units = x.shape[1]\n",
        "x = Dense(latent_dim, name=\"latent\")(x)\n",
        "x = Dense(units)(x)\n",
        "x = LeakyReLU(alpha=0.2)(x)\n",
        "x = Reshape((7, 7, 64))(x)\n",
        "    \n",
        "    network.add(Flatten())\n",
        "    #network.add(Dense(4096, activation='relu',\n",
        "     #              kernel_regularizer=l2(1e-3),\n",
        "      #             kernel_initializer='he_uniform'))\n",
        "    network.add(BatchNormalization())\n",
        "    \n",
        "    network.add(Dense(embeddingsize, activation=None,\n",
        "                   kernel_initializer='he_uniform'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuzygR7Fc76d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model, save_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPfVy1NIc9_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder = load_model('/content/my_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW9w1Lv6Dk4r",
        "colab_type": "text"
      },
      "source": [
        "## Embedding retrieval from the Encoder trained on 50 classes of images of newts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC9Fji0gc_le",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "\n",
        "shape = [x_train.shape[-1], 2000, 2000, 4000, 128]\n",
        "hidden = autoencoder.get_layer(name='encoder_%d' % (len(shape) - 2)).output\n",
        "encoder = Model(inputs=autoencoder.input, outputs=hidden)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ktpygkS2VDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "embedding = encoder.predict(x_train)\n",
        "embedding = StandardScaler().fit_transform(embedding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Yc3S6w_7159g"
      },
      "source": [
        "## Define metrics to evaluate the performances of the neural networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "on5QDvnA159i",
        "colab": {}
      },
      "source": [
        "def compute_dist(a,b):\n",
        "    return np.sum(np.square(a-b))\n",
        "#count_label = len(dataset)\n",
        "\n",
        "def mean_average_precision_autoencoder(dataset, x_test, y_test, network, rank):\n",
        "    '''\n",
        "    Returns\n",
        "        MAP : the mean of the average precision of the model for each images of the dataset\n",
        "    '''\n",
        "    nb_classes = count_label\n",
        "    print(nb_classes)\n",
        "    #m = X.shape[0]\n",
        "    #nbtrain = 10\n",
        "    nbevaluation = 200\n",
        "    probs = np.zeros((nbevaluation))\n",
        "    distances = np.zeros((nbevaluation,nb_classes))\n",
        "    ypreds = np.zeros((nbevaluation,nb_classes))\n",
        "    y = np.zeros((nbevaluation))\n",
        "\n",
        "    \n",
        "    #Compute all embeddings for all pics with current network\n",
        "    embeddings = network.predict(x_train[0:2,:])\n",
        "    \n",
        "    size_embedding = embeddings.shape[1]\n",
        "\n",
        "    ref_images = np.zeros((nb_classes,size_embedding))\n",
        "    \n",
        "    #generates embeddings for reference images\n",
        "    for i in range(nb_classes):\n",
        "          #print(dataset_train[i][:,0,0,1])\n",
        "          #idx_ref = np.random.choice(dataset_train[i][:,0,0,1],size=200,replace=False)\n",
        "          #print(idx_ref)\n",
        "          #print(len(dataset_train[i][0]))\n",
        "          #print(np.take(dataset_train[, idx_ref))\n",
        "          selected_ref = dataset[i][:,:,:,:]\n",
        "          #print(selected_ref.shape)\n",
        "          #print(np.max(selected_ref))\n",
        "          #print(selected_ref[0].shape)\n",
        "          #print(selected_ref[1]*selected_ref[2]*selected_ref[3].shape)\n",
        "          selected_ref = np.reshape(selected_ref, (selected_ref.shape[0], selected_ref.shape[1]*selected_ref.shape[2]*selected_ref.shape[3]))\n",
        "          #print(selected_ref.shape)\n",
        "          ref_images[i,:] = np.mean(network.predict(selected_ref),axis=0)\n",
        "          #print(ref_images[i,:].shape)\n",
        "    #print(np.mean(network.predict(selected_ref),axis=0).shape)\n",
        "    \n",
        "    #test = compute_dist(ref_images[0,:],network.predict(np.expand_dims(dataset[15][0,:,:,:], axis=0)))\n",
        "    #print(test)\n",
        "    for j in range(nbevaluation):\n",
        "          print(j)\n",
        "          for k in range(nb_classes):\n",
        "              #print(X[j,:,:,:].shape)\n",
        "              #print(np.max(ref_images[k,:]))\n",
        "              distances[j,k] = compute_dist(ref_images[k,:],network.predict(np.expand_dims(x_test[j,:], axis=0)))\n",
        "              #print(distances[j,k])\n",
        "          #print(distances[j,:])\n",
        "    #for i in range(nb_classes):\n",
        "     #for k in range(nb_classes):\n",
        "      #for j in range(nbevaluation):\n",
        "              #print(X[j,:,:,:].shape)\n",
        "       #       distances[j,k] = compute_dist(ref_images[i,:],network.predict(np.expand_dims(dataset[k][j,:,:,:], axis=0)))\n",
        "        #      print(distances[j,k])\n",
        "          #print(distances[j,:])\n",
        "    #print(\"affichage des distances triées selon l'axe des classes\")\n",
        "    ypreds = np.argsort(distances,axis=-1)\n",
        "    #print(ypreds[0])\n",
        "    #print(\"affichage des distances triées selon l'axe des classes\")\n",
        "    #ypreds = np.flip(ypreds,axis = -1)\n",
        "    #print(ypreds[0])\n",
        "    ytrue = y_test[:nbevaluation]\n",
        "    #print(ytrue)\n",
        "\n",
        "    AP = 0\n",
        "    #print(len(ytrue))\n",
        "    \n",
        "    for i in range(len(ytrue)):\n",
        "      #print(ypreds[i,:rank])\n",
        "      #print(ytrue[i])\n",
        "      print(ytrue)\n",
        "      print(ypreds[i,0])\n",
        "      for k in range(rank):\n",
        "        \n",
        "        if(ytrue[i] == ypreds[i,k]):\n",
        "          AP += 1/(k+1)\n",
        "    \n",
        "    MAP = AP/len(ytrue)\n",
        "    print(MAP)\n",
        "    return MAP\n",
        "\n",
        "def cumulative_matching_curve(X,Y,network,rank):\n",
        "  \n",
        "    '''\n",
        "    Returns\n",
        "        CMC : \n",
        "    '''\n",
        "    nb_classes = count_label\n",
        "    m = X.shape[0]\n",
        "    nbtrain = 1000\n",
        "    nbevaluation = 50\n",
        "    probs = np.zeros((nbevaluation))\n",
        "    distances = np.zeros((nbevaluation,nb_classes))\n",
        "    ypreds = np.zeros((nbevaluation,nb_classes))\n",
        "    y = np.zeros((nbevaluation))\n",
        "\n",
        "    \n",
        "    #Compute all embeddings for all pics with current network\n",
        "    embeddings = network.predict(X)\n",
        "    \n",
        "    size_embedding = embeddings.shape[1]\n",
        "\n",
        "    ref_images = np.zeros((nb_classes,size_embedding))\n",
        "    \n",
        "    #generates embeddings for reference images\n",
        "    for i in range(nb_classes):\n",
        "          #print(dataset_train[i][:,0,0,1])\n",
        "          #idx_ref = np.random.choice(dataset_train[i][:,0,0,1],size=200,replace=False)\n",
        "          #print(idx_ref)\n",
        "          #print(len(dataset_train[i][0]))\n",
        "          #print(np.take(dataset_train[, idx_ref))\n",
        "          selected_ref = dataset[i][:nbtrain,:,:,:]\n",
        "          #print(selected_ref.shape)\n",
        "          ref_images[i,:] = np.mean(network.predict(selected_ref),axis=0)\n",
        "          #print(ref_images[i,:].shape)\n",
        "    #print(np.mean(network.predict(selected_ref),axis=0).shape)\n",
        "    \n",
        "    #test = compute_dist(ref_images[0,:],network.predict(np.expand_dims(dataset[15][0,:,:,:], axis=0)))\n",
        "    #print(test)\n",
        "    for j in range(nbevaluation):\n",
        "          print(j)\n",
        "          for k in range(nb_classes):\n",
        "              #print(X[j,:,:,:].shape)\n",
        "              distances[j,k] = compute_dist(ref_images[k,:],network.predict(np.expand_dims(X[j,:,:,:]/255, axis=0)))\n",
        "              #print(distances[j,k])\n",
        "          #print(distances[j,:])\n",
        "    #for i in range(nb_classes):\n",
        "     #for k in range(nb_classes):\n",
        "      #for j in range(nbevaluation):\n",
        "              #print(X[j,:,:,:].shape)\n",
        "       #       distances[j,k] = compute_dist(ref_images[i,:],network.predict(np.expand_dims(dataset[k][j,:,:,:], axis=0)))\n",
        "        #      print(distances[j,k])\n",
        "          #print(distances[j,:])\n",
        "    #print(\"affichage des distances triées selon l'axe des classes\")\n",
        "    ypreds = np.argsort(distances,axis=-1)\n",
        "    #print(ypreds[0])\n",
        "    #print(\"affichage des distances triées selon l'axe des classes\")\n",
        "    #ypreds = np.flip(ypreds,axis = -1)\n",
        "    #print(ypreds[0])\n",
        "    ytrue = Y[:nbevaluation]\n",
        "    #print(ytrue)\n",
        "\n",
        "    present = 0\n",
        "    #print(len(ytrue))\n",
        "    \n",
        "    for i in range(len(ytrue)):\n",
        "      #print(ypreds[i,:rank])\n",
        "      #print(ytrue[i])\n",
        "      for k in range(rank):\n",
        "        #print(ytrue)\n",
        "        #print(ypreds[i,k])\n",
        "        if(ytrue[i] == ypreds[i,k]):\n",
        "          present += 1\n",
        "    \n",
        "    CMC = present/len(ytrue)\n",
        "    print(CMC)\n",
        "    return CMC\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "def compute_interdist(network):\n",
        "    '''\n",
        "    Computes sum of distances between all classes embeddings on our reference test image: \n",
        "        d(0,1) + d(0,2) + ... + d(0,9) + d(1,2) + d(1,3) + ... d(8,9)\n",
        "        A good model should have a large distance between all theses embeddings\n",
        "        \n",
        "    Returns:\n",
        "        array of shape (nb_classes,nb_classes) \n",
        "    '''\n",
        "    nb_classes = count_label\n",
        "    res = np.zeros((nb_classes,nb_classes))\n",
        "    \n",
        "    ref_images = np.zeros((nb_classes,28,28,3))\n",
        "    \n",
        "    #generates embeddings for reference images\n",
        "    for i in range(nb_classes):\n",
        "        ref_images[i,:,:,:] = dataset[i][0,:,:,:]\n",
        "    ref_embeddings = network.predict(ref_images)\n",
        "    \n",
        "    for i in range(nb_classes):\n",
        "        for j in range(nb_classes):\n",
        "            res[i,j] = compute_dist(ref_embeddings[i],ref_embeddings[j])\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTP9URnj1vD8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d9d5e87a-305f-4bee-bca3-a7cf526d5671"
      },
      "source": [
        "MAP = mean_average_precision_autoencoder(dataset,x_test,y_test,encoder, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9i1vQSV6seh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Free memory by removing useless variables after the training\n",
        "x_test = 0\n",
        "y_test = 0\n",
        "x_train = 0\n",
        "y_train = 0\n",
        "dataset = 0\n",
        "dataset_test = 0\n",
        "autoencoder = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxaaGf-TIfdJ",
        "colab_type": "text"
      },
      "source": [
        "## UMAP Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpVzkaN_NHyB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "672b9f72-6800-4104-f0fe-d59b72618ce8"
      },
      "source": [
        "def hdbscan_evaluation_function(parameterization):\n",
        "    x = []\n",
        "    x.append(parameterization.get(f\"min_samples\"))\n",
        "    x.append(parameterization.get(f\"min_cluster_size\"))\n",
        "    x.append(parameterization.get(f\"n_neighbors\"))\n",
        "    x.append(parameterization.get(f\"min_dist\"))\n",
        "    x.append(parameterization.get(f\"n_components\"))\n",
        "    x = np.array(x)\n",
        "\n",
        "\n",
        "    umap_embedding = umap.UMAP(\n",
        "    n_neighbors=x[2],\n",
        "    min_dist=x[3]/100,\n",
        "    n_components=x[4],\n",
        "    random_state=42,\n",
        "    low_memory = True,\n",
        "    ).fit_transform(embedding)\n",
        "\n",
        "    print(x)\n",
        "    print(x.shape)\n",
        "    print(int(x[0]))\n",
        "    print(int(x[1]))\n",
        "    labels = hdbscan.HDBSCAN(\n",
        "    min_samples=int(x[0]),\n",
        "    min_cluster_size=int(x[1]),\n",
        "    ).fit_predict(umap_embedding)\n",
        "\n",
        "    if (len(np.unique(labels)) > 2):\n",
        "      scores = -(davies_bouldin_score(umap_embedding, labels))  + silhouette_score(umap_embedding, labels)\n",
        "      print(scores)\n",
        "    else:\n",
        "      scores = -5\n",
        "    #silhouette_samples(umap_embedding, labels, metric='euclidean'), + calinski_harabasz_score(umap_embedding, labels)\n",
        "    \n",
        "    # In our case, standard error is 0, since we are computing a synthetic function.\n",
        "    return scores\n",
        "\n",
        "best_parameters, best_values, experiment, model = optimize(\n",
        "        parameters=[\n",
        "          {\n",
        "            \"name\": \"n_neighbors\",\n",
        "            \"type\": \"range\",\n",
        "            \"bounds\": [3, 20],\n",
        "          },\n",
        "          {\n",
        "            \"name\": \"min_dist\",\n",
        "            \"type\": \"range\",\n",
        "            \"bounds\": [0, 10],\n",
        "          },\n",
        "          {\n",
        "            \"name\": \"n_components\",\n",
        "            \"type\": \"range\",\n",
        "            \"bounds\": [2,8],\n",
        "         },\n",
        "          {\n",
        "            \"name\": \"min_samples\",\n",
        "            \"type\": \"range\",\n",
        "            \"bounds\": [3, 20],\n",
        "          },\n",
        "          {\n",
        "            \"name\": \"min_cluster_size\",\n",
        "            \"type\": \"range\",\n",
        "            \"bounds\": [10, 60],\n",
        "          },\n",
        "        ],\n",
        "        # Booth function\n",
        "        experiment_name=\"test\",\n",
        "        objective_name=\"scores\",\n",
        "        evaluation_function=hdbscan_evaluation_function,\n",
        "        #evaluation_function=lambda p: (p[\"x1\"] + 2*p[\"x2\"] - 7)**2 + (2*p[\"x1\"] + p[\"x2\"] - 5)**2,\n",
        "        total_trials=30,\n",
        "        minimize=False,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-2L9No4cWe9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "7cd3b3d3-b0dd-4288-b6bb-03331ee2b2f3"
      },
      "source": [
        "\n",
        "best_parameters\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS5DICzlaG_d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "umap_embedding = umap.UMAP(\n",
        "    n_neighbors=8,\n",
        "    min_dist=0.06,\n",
        "    n_components=7,\n",
        "    random_state=42,\n",
        ").fit_transform(embedding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJaxjOg4aO89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = hdbscan.HDBSCAN(\n",
        "    min_samples=17,\n",
        "    min_cluster_size=60,\n",
        ").fit_predict(umap_embedding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSkHvBRcaelN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "bf62a719-bbe1-483c-8ae9-1358917ffc8d"
      },
      "source": [
        "np.unique(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmYrr3PhHCGM",
        "colab_type": "text"
      },
      "source": [
        "# Segmentation algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xqxq49PpyhEr",
        "colab_type": "text"
      },
      "source": [
        "## Segmentation of newts using a Mask R-CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCMPZeXeJRet",
        "colab_type": "text"
      },
      "source": [
        "### Import necessary modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQ3iJFLHRROH",
        "colab_type": "text"
      },
      "source": [
        "import the preaugmented dataset generated from the method preaugment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR0UAoTHYBHM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "ad222d60-7dd2-481b-9690-5ff132b35b6e"
      },
      "source": [
        "\"\"\" the Mask RCNN has been implemented with Tensorflow 1.x\n",
        "    Restart the runtime if Tensorflow 2.x were imported.\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "  %tensorflow_version 1.x\n",
        "except:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "!pip install keras==2.2.5\n",
        "\n",
        "!git clone https://github.com/matterport/Mask_RCNN.git\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import datetime\n",
        "import numpy as np\n",
        "import skimage.draw\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import itertools\n",
        "import math\n",
        "import logging\n",
        "import json\n",
        "import re\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.lines as lines\n",
        "from matplotlib.patches import Polygon\n",
        "\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"/content/Mask_RCNN\")\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "# Root directory of the project\n",
        "#ROOT_DIR = os.getcwd()\n",
        "#if ROOT_DIR.endswith(\"samples/balloon\"):\n",
        "    # Go up two levels to the repo root\n",
        "   # ROOT_DIR = os.path.dirname(os.path.dirname(ROOT_DIR))\n",
        "\n",
        "# Import Mask RCNN\n",
        "#sys.path.append(ROOT_DIR)\n",
        "\n",
        "import mrcnn.utils\n",
        "import mrcnn.visualize as visualize\n",
        "from mrcnn.visualize import display_images\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn.model import log\n",
        "\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import PIL.Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.figsize'] = (12, 5)\n",
        "\n",
        "import skimage\n",
        "from skimage import measure\n",
        "import numpy as np\n",
        "from skimage.io import imread, imsave\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import transform\n",
        "from skimage.transform import rotate, AffineTransform, swirl, resize\n",
        "from skimage.util import random_noise\n",
        "from skimage.filters import gaussian\n",
        "from skimage import io, img_as_float, img_as_float64\n",
        "from scipy import ndimage\n",
        "from pathlib import Path\n",
        "\n",
        "from random import random, uniform\n",
        "\n",
        "import os\n",
        "import pathlib\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "import numba\n",
        "from numba import jit\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7t3KqNAlrnvd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a686a5f9-e9a3-4ed5-a8e6-ed7a7bd08410"
      },
      "source": [
        "import shutil\n",
        "\"\"\" Define useful paths and download the pretrained weights of the Mask RCNN \"\"\"\n",
        "# Root directory of the project\n",
        "ROOT_DIR = os.path.abspath(\"/content/Mask_RCNN\")\n",
        "source = '/content/pattern_annotated/pattern_annotated/' \n",
        "destination = '/content/Mask_RCNN/'\n",
        "shutil.move(source, destination)\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import model as modellib, utils\n",
        "\n",
        "# Path to trained weights file\n",
        "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_WEIGHTS_PATH):\n",
        "    utils.download_trained_weights(COCO_WEIGHTS_PATH)\n",
        "\n",
        "\n",
        "# Directory to save logs and model checkpoints, if not provided\n",
        "# through the command line argument --logs\n",
        "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baixlcO0sdC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################################################\n",
        "#  Configurations\n",
        "############################################################\n",
        "\n",
        "\n",
        "class NewtsConfig(Config):\n",
        "    \"\"\"Configuration for training on the toy  dataset.\n",
        "    Derives from the base Config class and overrides some values.\n",
        "    \"\"\"\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"newt\"\n",
        "\n",
        "    # We use a GPU with 12GB memory, which can fit two images.\n",
        "    # Adjust down if you use a smaller GPU.\n",
        "    IMAGES_PER_GPU = 2\n",
        "\n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 1  # Background + newts\n",
        "\n",
        "    # Number of training steps per epoch\n",
        "    STEPS_PER_EPOCH = 100\n",
        "\n",
        "    # Skip detections with < 90% confidence\n",
        "    DETECTION_MIN_CONFIDENCE = 0.9\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLWAtzv4tD9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################################################\n",
        "#  Dataset\n",
        "############################################################\n",
        "\n",
        "class NewtsDataset(utils.Dataset):\n",
        "\n",
        "    def load_newts(self, dataset_dir, subset):\n",
        "        \"\"\"Load a subset of the newts dataset.\n",
        "        dataset_dir: Root directory of the dataset.\n",
        "        subset: Subset to load: train or val\n",
        "        \"\"\"\n",
        "        # Add classes. We have only one class to add.\n",
        "        self.add_class(\"newt_pattern\", 1, \"newt_pattern\")\n",
        "\n",
        "        # Train or validation dataset?\n",
        "        #assert subset in [\"train\", \"test\"]\n",
        "        #dataset_dir = os.path.join(dataset_dir, subset)\n",
        "\n",
        "        # Load annotations\n",
        "        # VGG Image Annotator (up to version 1.6) saves each image in the form:\n",
        "        # { 'filename': '28503151_5b5b7ec140_b.jpg',\n",
        "        #   'regions': {\n",
        "        #       '0': {\n",
        "        #           'region_attributes': {},\n",
        "        #           'shape_attributes': {\n",
        "        #               'all_points_x': [...],\n",
        "        #               'all_points_y': [...],\n",
        "        #               'name': 'polygon'}},\n",
        "        #       ... more regions ...\n",
        "        #   },\n",
        "        #   'size': 100202\n",
        "        # }\n",
        "        # We mostly care about the x and y coordinates of each region\n",
        "        # Note: In VIA 2.0, regions was changed from a dict to a list.\n",
        "        #/content/images_annotated/via_export_newts.json\n",
        "        annotations = json.load(open(os.path.join(dataset_dir, \"via_export_newts_pattern.json\")))\n",
        "        annotations = list(annotations.values())  # don't need the dict keys\n",
        "\n",
        "        # The VIA tool saves images in the JSON even if they don't have any\n",
        "        # annotations. Skip unannotated images.\n",
        "        annotations = [a for a in annotations if a['regions']]\n",
        "\n",
        "        # Add images\n",
        "        for a in annotations:\n",
        "            # Get the x, y coordinaets of points of the polygons that make up\n",
        "            # the outline of each object instance. These are stores in the\n",
        "            # shape_attributes (see json format above)\n",
        "            # The if condition is needed to support VIA versions 1.x and 2.x.\n",
        "            if type(a['regions']) is dict:\n",
        "                polygons = [r['shape_attributes'] for r in a['regions'].values()]\n",
        "            else:\n",
        "                polygons = [r['shape_attributes'] for r in a['regions']] \n",
        "\n",
        "            # load_mask() needs the image size to convert polygons to masks.\n",
        "            # Unfortunately, VIA doesn't include it in JSON, so we must read\n",
        "            # the image. This is only managable since the dataset is tiny.\n",
        "            image_path = os.path.join(dataset_dir, a['filename'])\n",
        "            image = skimage.io.imread(image_path)\n",
        "            height, width = image.shape[:2]\n",
        "\n",
        "            self.add_image(\n",
        "                \"newt_pattern\",\n",
        "                image_id=a['filename'],  # use file name as a unique image id\n",
        "                path=image_path,\n",
        "                width=width, height=height,\n",
        "                polygons=polygons)\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\"Generate instance masks for an image.\n",
        "       Returns:\n",
        "        masks: A bool array of shape [height, width, instance count] with\n",
        "            one mask per instance.\n",
        "        class_ids: a 1D array of class IDs of the instance masks.\n",
        "        \"\"\"\n",
        "        # If not a newt dataset image, delegate to parent class.\n",
        "        image_info = self.image_info[image_id]\n",
        "        if image_info[\"source\"] != \"newt_pattern\":\n",
        "            return super(self.__class__, self).load_mask(image_id)\n",
        "\n",
        "        # Convert polygons to a bitmap mask of shape\n",
        "        # [height, width, instance_count]\n",
        "        info = self.image_info[image_id]\n",
        "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
        "                        dtype=np.uint8)\n",
        "        for i, p in enumerate(info[\"polygons\"]):\n",
        "            # Get indexes of pixels inside the polygon and set them to 1\n",
        "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
        "            mask[rr, cc, i] = 1\n",
        "\n",
        "        # Return mask, and array of class IDs of each instance. Since we have\n",
        "        # one class ID only, we return an array of 1s\n",
        "        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n",
        "\n",
        "    def image_reference(self, image_id):\n",
        "        \"\"\"Return the path of the image.\"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == \"newt_pattern\":\n",
        "            return info[\"path\"]\n",
        "        else:\n",
        "            super(self.__class__, self).image_reference(image_id)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mY4bKKeudgeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = NewtsConfig()\n",
        "NEWTS_DIR = os.path.join(ROOT_DIR, \"pattern_annotated\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei9bh42LexHD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "3d9c0758-4df2-456e-e5e7-5c514b07b1d8"
      },
      "source": [
        "\n",
        "# Load dataset\n",
        "# Get the dataset from the releases page\n",
        "# https://github.com/matterport/Mask_RCNN/releases\n",
        "dataset = NewtsDataset()\n",
        "#dataset.load_newts(IMAGE_DIR, \"train\")\n",
        "dataset.load_newts(NEWTS_DIR, \"train\")\n",
        "# Must call before using the dataset\n",
        "dataset.prepare()\n",
        "\n",
        "print(\"Image Count: {}\".format(len(dataset.image_ids)))\n",
        "print(\"Class Count: {}\".format(dataset.num_classes))\n",
        "for i, info in enumerate(dataset.class_info):\n",
        "    print(\"{:3}. {:50}\".format(i, info['name']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DA80r3ylfIt9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "08061ecd-d4ab-4c0d-80b0-3ea620144977"
      },
      "source": [
        "# Load and display random samples\n",
        "image_ids = np.random.choice(dataset.image_ids, 4)\n",
        "for image_id in image_ids:\n",
        "    image = dataset.load_image(image_id)\n",
        "    mask, class_ids = dataset.load_mask(image_id)\n",
        "    visualize.display_top_masks(image, mask, class_ids, dataset.class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZhbUZlL2e83",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 985
        },
        "outputId": "3ed84631-c408-4274-8282-4fbeec82551e"
      },
      "source": [
        "#Load random image and mask.\n",
        "image_id = random.choice(dataset.image_ids)\n",
        "image = dataset.load_image(image_id)\n",
        "mask, class_ids = dataset.load_mask(image_id)\n",
        "# Compute Bounding box\n",
        "bbox = utils.extract_bboxes(mask)\n",
        "\n",
        "# Display image and additional stats\n",
        "print(\"image_id \", image_id, dataset.image_reference(image_id))\n",
        "log(\"image\", image)\n",
        "log(\"mask\", mask)\n",
        "log(\"class_ids\", class_ids)\n",
        "log(\"bbox\", bbox)\n",
        "# Display image and instances\n",
        "visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPEcYgn4Mhr-",
        "colab_type": "text"
      },
      "source": [
        "### Train the mask R-CNN. I have already trained it and the weights are saved in the folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i7CIyWFvSRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "def train(model):\n",
        "    \"\"\"Train the model.\"\"\"\n",
        "    # Training dataset.\n",
        "    dataset_train = NewtsDataset()\n",
        "    dataset_train.load_newts(NEWTS_DIR, \"train\")\n",
        "    dataset_train.prepare()\n",
        "\n",
        "    # Validation dataset\n",
        "    dataset_val = NewtsDataset()\n",
        "    dataset_val.load_newts(NEWTS_DIR, \"val\")\n",
        "    dataset_val.prepare()\n",
        "\n",
        "    # *** This training schedule is an example. Update to your needs ***\n",
        "    # Since we're using a very small dataset, and starting from\n",
        "    # COCO trained weights, we don't need to train too long. Also,\n",
        "    # no need to train all layers, just the heads should do it.\n",
        "    print(\"Training network heads\")\n",
        "    #model.metrics_tensors = []\n",
        "    model.train(dataset_train, dataset_val,\n",
        "                learning_rate=config.LEARNING_RATE,\n",
        "                epochs=60,\n",
        "                layers='heads')\n",
        "\n",
        "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
        "                                  model_dir=DEFAULT_LOGS_DIR)\n",
        "#weights_path = '/content/Mask_RCNN/logs/newt_pattern20200602T1046/mask_rcnn_newt_pattern_0040.h5'\n",
        "#model.load_weights(weights_path, by_name=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDyC1FtSO1Do",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sx1e6YY_Mwxh",
        "colab_type": "text"
      },
      "source": [
        "### Inference part. I load the weights resulting from the training phase.\n",
        "\n",
        "I have to run the cell twice to correctly be in inference mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUeHiBHVerwW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InferenceConfig(NewtsConfig):\n",
        "  \"\"\" Config to be used for the inferences \"\"\"\n",
        "            # Set batch size to 1 since we'll be running inference on\n",
        "            # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
        "  GPU_COUNT = 1\n",
        "  IMAGES_PER_GPU = 1\n",
        "\n",
        "\n",
        "config = InferenceConfig()\n",
        "model = modellib.MaskRCNN(mode=\"inference\", config=config,\n",
        "                                  model_dir=DEFAULT_LOGS_DIR)\n",
        "weights_path = '/content/mask_rcnn_newt_pattern_0060.h5'\n",
        "model.load_weights(weights_path, by_name=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-IUBioeQLuI",
        "colab_type": "text"
      },
      "source": [
        "methods used to show results of segmentation on images of the dataset pre-augmented"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efcuNbIBvZ3_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def color_splash(image, mask):\n",
        "    \"\"\"Apply color splash effect.\n",
        "    image: RGB image [height, width, 3]\n",
        "    mask: instance segmentation mask [height, width, instance count]\n",
        "    Returns result image.\n",
        "    \"\"\"\n",
        "    # Make a grayscale copy of the image. The grayscale copy still\n",
        "    # has 3 RGB channels, though.\n",
        "    gray = skimage.color.gray2rgb(skimage.color.rgb2gray(image)) * 255\n",
        "    # Copy color pixels from the original color image where mask is set\n",
        "    if mask.shape[-1] > 0:\n",
        "        # We're treating all instances as one, so collapse the mask into one layer\n",
        "        mask = (np.sum(mask, -1, keepdims=True) >= 1)\n",
        "        splash = np.where(mask, image, gray).astype(np.uint8)\n",
        "    else:\n",
        "        splash = gray.astype(np.uint8)\n",
        "    return splash\n",
        "\n",
        "def detect_and_color_splash(model, image_path=None, video_path=None):\n",
        "    assert image_path or video_path\n",
        "\n",
        "    # Image or video?\n",
        "    if image_path:\n",
        "        # Run model detection and generate the color splash effect\n",
        "        print(\"Running on {}\".format(img_path))\n",
        "        # Read image\n",
        "        image = skimage.io.imread(img_path)\n",
        "        # Detect objects\n",
        "        r = model.detect([image], verbose=1)[0]\n",
        "        # Color splash\n",
        "        splash = color_splash(image, r['masks'])\n",
        "        # Save output\n",
        "        file_name = \"splash_{:%Y%m%dT%H%M%S}.png\".format(datetime.datetime.now())\n",
        "        skimage.io.imsave(file_name, splash)\n",
        "        plt.imshow(splash)\n",
        "    elif video_path:\n",
        "        import cv2\n",
        "        # Video capture\n",
        "        vcapture = cv2.VideoCapture(video_path)\n",
        "        width = int(vcapture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(vcapture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps = vcapture.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "        # Define codec and create video writer\n",
        "        file_name = \"splash_{:%Y%m%dT%H%M%S}.avi\".format(datetime.datetime.now())\n",
        "        vwriter = cv2.VideoWriter(file_name,\n",
        "                                  cv2.VideoWriter_fourcc(*'MJPG'),\n",
        "                                  fps, (width, height))\n",
        "\n",
        "        count = 0\n",
        "        success = True\n",
        "        while success:\n",
        "            print(\"frame: \", count)\n",
        "            # Read next image\n",
        "            success, image = vcapture.read()\n",
        "            if success:\n",
        "                # OpenCV returns images as BGR, convert to RGB\n",
        "                image = image[..., ::-1]\n",
        "                # Detect objects\n",
        "                r = model.detect([image], verbose=0)[0]\n",
        "                # Color splash\n",
        "                splash = color_splash(image, r['masks'])\n",
        "                # RGB -> BGR to save image to video\n",
        "                splash = splash[..., ::-1]\n",
        "                # Add image to video writer\n",
        "                vwriter.write(splash)\n",
        "                count += 1\n",
        "        vwriter.release()\n",
        "    print(\"Saved to \", file_name)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvLKggXN-O4v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "0f5ae095-0190-4f1a-e13c-3624373da5d2"
      },
      "source": [
        "img_path = '/content/aug_database_for_seg/aug_database_for_seg/Bascha_P01_T06_K17_U_Juvenile_6664_20190628041159.jpg'\n",
        "detect_and_color_splash(model, image_path=img_path, video_path=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FA_RlHSUHQzI",
        "colab_type": "text"
      },
      "source": [
        "## Segmentation of newts using a UNet network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqA-hSO1J0aC",
        "colab_type": "text"
      },
      "source": [
        "### Import necessary modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Zw7cE4cJ4Gc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "outputId": "570be0b8-4317-4707-80d2-c81f44093325"
      },
      "source": [
        "!pip install git+https://github.com/tensorflow/examples.git\n",
        "!pip install -U tfds-nightly\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow_examples.models.pix2pix import pix2pix\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from os import path                      # os level path manipulation\n",
        "from glob import glob                    # Unix style pathname pattern expansion\n",
        "import numpy as np                       # array goodnes\n",
        "from matplotlib import pyplot as plt     # plotting library\n",
        "import nibabel as nib                    # handlie NIFTI files\n",
        "from tqdm import tqdm, trange            # progress bars\n",
        "from tensorflow.keras.utils import get_file  # handy function to download data\n",
        "\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.dpi'] = 150\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import datetime\n",
        "import numpy as np\n",
        "import skimage.io\n",
        "import skimage.draw\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import itertools\n",
        "import math\n",
        "import logging\n",
        "import json\n",
        "import re\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.lines as lines\n",
        "from matplotlib.patches import Polygon\n",
        "\n",
        "from skimage.transform import resize             # resize images\n",
        "from skimage.exposure import equalize_adapthist  # CLAHE\n",
        "from skimage.exposure import rescale_intensity   # used to normalize the image data\n",
        "from sklearn.model_selection import train_test_split    # helper function to split the data\n",
        "from skimage.morphology import area_closing, area_opening, binary_closing, binary_opening, black_tophat, closing, opening, skeletonize\n",
        "import skimage\n",
        "from skimage import measure\n",
        "import numpy as np\n",
        "from skimage.io import imread, imsave\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import transform\n",
        "from skimage.transform import rotate, AffineTransform, swirl, resize\n",
        "from skimage.util import random_noise\n",
        "from skimage.filters import gaussian\n",
        "from skimage import io, img_as_float, img_as_float64\n",
        "from scipy import ndimage\n",
        "from pathlib import Path\n",
        "from skimage import data, img_as_float\n",
        "from skimage import exposure\n",
        "from scipy.ndimage import shift\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSnNzT-ucjwF",
        "colab_type": "text"
      },
      "source": [
        "### Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mn8NjHRhdWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_dataset(dataset_dir, subset, target_shape):\n",
        "        \"\"\"Load a subset of the newts dataset.\n",
        "        dataset_dir: Root directory of the dataset.\n",
        "        subset: Subset to load: train or val\n",
        "\n",
        "        then \n",
        "\n",
        "        Generate instance masks for an image.\n",
        "       Returns:\n",
        "        masks: A bool array of shape [height, width, instance count] with\n",
        "            one mask per instance.\n",
        "        class_ids: a 1D array of class IDs of the instance masks.\n",
        "        \"\"\"\n",
        "        \n",
        "        X, Y = [], []\n",
        "\n",
        "        image_ids = []\n",
        "        image_info = []\n",
        "        # Background is always the first class\n",
        "        class_info = [{\"source\": \"\", \"id\": 0, \"name\": \"BG\"}]\n",
        "        source_class_ids = {}\n",
        "        # Add classes. We have only one class to add.\n",
        "        #self.add_class(\"newt_pattern\", 1, \"newt_pattern\")\n",
        "        class_info.append({\"newt_pattern\", 1, \"newt_pattern\"})\n",
        "\n",
        "        # Train or validation dataset?\n",
        "        #assert subset in [\"train\", \"test\"]\n",
        "        #dataset_dir = os.path.join(dataset_dir, subset)\n",
        "\n",
        "        # Load annotations\n",
        "        # VGG Image Annotator (up to version 1.6) saves each image in the form:\n",
        "        # { 'filename': '28503151_5b5b7ec140_b.jpg',\n",
        "        #   'regions': {\n",
        "        #       '0': {\n",
        "        #           'region_attributes': {},\n",
        "        #           'shape_attributes': {\n",
        "        #               'all_points_x': [...],\n",
        "        #               'all_points_y': [...],\n",
        "        #               'name': 'polygon'}},\n",
        "        #       ... more regions ...\n",
        "        #   },\n",
        "        #   'size': 100202\n",
        "        # }\n",
        "        # We mostly care about the x and y coordinates of each region\n",
        "        # Note: In VIA 2.0, regions was changed from a dict to a list.\n",
        "        #/content/images_annotated/via_export_newts.json\n",
        "        annotations = json.load(open(os.path.join(dataset_dir, \"via_export_json.json\")))\n",
        "        annotations = list(annotations.values())  # don't need the dict keys\n",
        "\n",
        "        # The VIA tool saves images in the JSON even if they don't have any\n",
        "        # annotations. Skip unannotated images.\n",
        "        annotations = [a for a in annotations if a['regions']]\n",
        "        #print(annotations)\n",
        "        # Add images\n",
        "        for a in annotations:\n",
        "            # Get the x, y coordinaets of points of the polygons that make up\n",
        "            # the outline of each object instance. These are stores in the\n",
        "            # shape_attributes (see json format above)\n",
        "            # The if condition is needed to support VIA versions 1.x and 2.x.\n",
        "            if type(a['regions']) is dict:\n",
        "                polygons = [r['shape_attributes'] for r in a['regions'].values()]\n",
        "            else:\n",
        "                polygons = [r['shape_attributes'] for r in a['regions']] \n",
        "\n",
        "            # load_mask() needs the image size to convert polygons to masks.\n",
        "            # Unfortunately, VIA doesn't include it in JSON, so we must read\n",
        "            # the image. This is only managable since the dataset is tiny.\n",
        "            image_path = os.path.join(dataset_dir, a['filename'])\n",
        "            image = skimage.io.imread(image_path)\n",
        "            #print(image.shape)\n",
        "            height, width = image.shape[:2]\n",
        "\n",
        "            image_info.append(\n",
        "                {\"source\":\"newt_pattern\",\n",
        "                \"image_id\":a['filename'],  # use file name as a unique image id\n",
        "                \"path\":image_path,\n",
        "                \"width\":width, \"height\":height,\n",
        "                \"polygons\":polygons})\n",
        "            \n",
        "\n",
        "            image = resize(image, target_shape, preserve_range=True)\n",
        "            image = rescale_intensity(image, 'image', (0, 1.0))\n",
        "\n",
        "            X.append(image)\n",
        "            #image = np.expand_dims(image, -1)\n",
        "       \n",
        "        # If not a newt dataset image, delegate to parent class.\n",
        "        #image_info = self.image_info[image_id]\n",
        "        #if image_info[\"source\"] != \"newt_pattern\":\n",
        "        #    return super(self.__class__, self).load_mask(image_id)\n",
        "\n",
        "        # Convert polygons to a bitmap mask of shape\n",
        "        # [height, width, instance_count]\n",
        "\n",
        "        for info in image_info:\n",
        "\n",
        "          mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
        "                        dtype=np.uint8)\n",
        "        \n",
        "          for i, p in enumerate(info[\"polygons\"]):\n",
        "            # Get indexes of pixels inside the polygon and set them to 1\n",
        "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
        "            mask[rr, cc] = i+1\n",
        "            \n",
        "          mask = mask[:,:,0]\n",
        "          mask[mask == 1] = 255\n",
        "          mask = resize(mask, (target_shape[0], target_shape[1], 1), preserve_range=True,)\n",
        "          mask[mask > 0] = 1\n",
        "         # print(np.max(mask))\n",
        "          \n",
        "          #print(np.max(mask[:,:,0]))\n",
        "          #print(np.max(mask[:,:,1]))\n",
        "          #print(np.max(mask[:,:,2]))\n",
        "\n",
        "          #plt.imshow(mask[:,:,0])\n",
        "          #plt.show()\n",
        "          #plt.imshow(mask[:,:,1])\n",
        "          #plt.show()\n",
        "          #plt.imshow(mask[:,:,2])\n",
        "          #plt.show()\n",
        "         \n",
        "         # ma_onehot = []\n",
        "          #for cls in [0, 1]:\n",
        "           # ma_onehot.append(mask == cls)\n",
        "          #ma_onehot = np.stack(ma_onehot, axis=-1)\n",
        "          #print(ma_onehot)\n",
        "          Y.append(mask)\n",
        "        #mask[mask == 0] = -1\n",
        "        # Return mask, and array of class IDs of each instance. Since we have\n",
        "        # one class ID only, we return an array of 1s\n",
        "        X, Y = np.array(X, dtype=np.float32), np.array(Y, dtype=np.float32)\n",
        "        return X,Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8xfONUW6242",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "9974687c-b105-4edd-a65d-e9e471be7759"
      },
      "source": [
        "target_shape = (128, 128, 3)\n",
        "X,Y = prepare_dataset('/content/new_picture_for_database', 'train', target_shape)\n",
        "#plt.imshow(X[0])\n",
        "#print(np.min(X[0]))\n",
        "#print(Y)\n",
        "#X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
        "X_train = X\n",
        "Y_train = Y\n",
        "X_val = X\n",
        "Y_val = Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCHYEXSS3MHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imsave()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USqaRPtIZmdu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "d6844023-42b6-4286-8062-8f65018fccb8"
      },
      "source": [
        "plt.imshow(np.squeeze(Y[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyA2ikf51x7q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "c86e8816-cc1f-404f-9cea-c11c7116938f"
      },
      "source": [
        "plt.imshow(X[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xa3gMAE_9qNa"
      },
      "source": [
        "Let's take a look at an image example and it's correponding mask from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3N2RPAAW9q4W",
        "colab": {}
      },
      "source": [
        "def display(display_list):\n",
        "  plt.figure(figsize=(15, 15))\n",
        "\n",
        "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "  for i in range(len(display_list)):\n",
        "    plt.subplot(1, len(display_list), i+1)\n",
        "    plt.title(title[i])\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FAOe93FRMk3w"
      },
      "source": [
        "### Define the model\n",
        "The model being used here is a modified U-Net. A U-Net consists of an encoder (downsampler) and decoder (upsampler). In-order to learn robust features, and reduce the number of trainable parameters, a pretrained model can be used as the encoder. Thus, the encoder for this task will be a pretrained MobileNetV2 model, whose intermediate outputs will be used, and the decoder will be the upsample block already implemented in TensorFlow Examples in the [Pix2pix tutorial](https://github.com/tensorflow/examples/blob/master/tensorflow_examples/models/pix2pix/pix2pix.py). \n",
        "\n",
        "The reason to output three channels is because there are three possible labels for each pixel. Think of this as multi-classification where each pixel is being classified into three classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c6iB4iMvMkX9",
        "colab": {}
      },
      "source": [
        "OUTPUT_CHANNELS = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W4mQle3lthit"
      },
      "source": [
        "As mentioned, the encoder will be a pretrained MobileNetV2 model which is prepared and ready to use in [tf.keras.applications](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/applications). The encoder consists of specific outputs from intermediate layers in the model. Note that the encoder will not be trained during the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "liCeLH0ctjq7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "09a40e7e-343a-43ab-b136-3e24fa648f43"
      },
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)\n",
        "base_model.summary()\n",
        "# Use the activations of these layers\n",
        "layer_names = [\n",
        "    'block_1_expand_relu',   # 64x64\n",
        "    'block_3_expand_relu',   # 32x32\n",
        "    'block_6_expand_relu',   # 16x16\n",
        "    'block_13_expand_relu',  # 8x8\n",
        "    'block_16_project',      # 4x4\n",
        "]\n",
        "layers = [base_model.get_layer(name).output for name in layer_names]\n",
        "\n",
        "# Create the feature extraction model\n",
        "down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
        "\n",
        "down_stack.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KPw8Lzra5_T9"
      },
      "source": [
        "The decoder/upsampler is simply a series of upsample blocks implemented in TensorFlow examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p0ZbfywEbZpJ",
        "colab": {}
      },
      "source": [
        "up_stack = [\n",
        "    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n",
        "    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n",
        "    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n",
        "    pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "45HByxpVtrPF",
        "colab": {}
      },
      "source": [
        "def unet_model(output_channels):\n",
        "  inputs = tf.keras.layers.Input(shape=[128, 128, 3])\n",
        "  x = inputs\n",
        "\n",
        "  # Downsampling through the model\n",
        "  skips = down_stack(x)\n",
        "  x = skips[-1]\n",
        "  skips = reversed(skips[:-1])\n",
        "\n",
        "  # Upsampling and establishing the skip connections\n",
        "  for up, skip in zip(up_stack, skips):\n",
        "    x = up(x)\n",
        "    concat = tf.keras.layers.Concatenate()\n",
        "    x = concat([x, skip])\n",
        "\n",
        "  # This is the last layer of the model\n",
        "  last = tf.keras.layers.Conv2DTranspose(\n",
        "      output_channels, 3, strides=2,\n",
        "      padding='same')  #64x64 -> 128x128\n",
        "\n",
        "  x = last(x)\n",
        "\n",
        "  return tf.keras.Model(inputs=inputs, outputs=x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j0DGH_4T0VYn"
      },
      "source": [
        "### Train the model\n",
        "Now, all that is left to do is to compile and train the model. The loss being used here is `losses.SparseCategoricalCrossentropy(from_logits=True)`. The reason to use this loss function is because the network is trying to assign each pixel a label, just like multi-class prediction. In the true segmentation mask, each pixel has either a {0,1}. The network here is outputting two channels. Essentially, each channel is trying to learn to predict a class, and `losses.SparseCategoricalCrossentropy(from_logits=True)` is the recommended loss for \n",
        "such a scenario. Using the output of the network, the label assigned to the pixel is the channel with the highest value. This is what the create_mask function is doing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6he36HK5uKAc",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model = unet_model(OUTPUT_CHANNELS)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xVMzbIZLcyEF"
      },
      "source": [
        "Have a quick look at the resulting model architecture:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sw82qF1Gcovr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9f7af6cf-1336-4074-857d-67d748d54c9d"
      },
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G3HkTQ-OI_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mask(pred_mask):\n",
        "  pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "  pred_mask = pred_mask[..., tf.newaxis]\n",
        "  \n",
        "\n",
        "  #pred_mask = area_closing(pred_mask, area_threshold=4, connectivity=1, parent=None, tree_traverser=None)tf.keras.preprocessing.image.img_to_array\n",
        "\n",
        "  return pred_mask[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiBalMojMR1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_predictions(X = X_val[0], Y = Y_val[0], num=1):\n",
        "  \n",
        "  if len(X.shape) > 3:\n",
        "    for image, mask in zip(X,Y):\n",
        "      pred_mask = model.predict(image[tf.newaxis, ...])\n",
        "      display([image, mask, create_mask(pred_mask)])\n",
        "  else:\n",
        "    display([X, Y,\n",
        "             create_mask(model.predict(X[tf.newaxis, ...]))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "22AyVYWQdkgk"
      },
      "source": [
        "Let's observe how the model improves while it is training. To accomplish this task, a callback function is defined below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wHrHsqijdmL6",
        "colab": {}
      },
      "source": [
        "class DisplayCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    clear_output(wait=True)\n",
        "    show_predictions()\n",
        "    print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuNZRoWKqibr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "0eaf4082-71af-4565-b483-0972d14ae988"
      },
      "source": [
        "EPOCHS = 20\n",
        "\"\"\" train only the upscaling layers first\"\"\"\n",
        "model_history = model.fit(X, Y, epochs=EPOCHS,\n",
        "                          validation_data=[X_val,Y_val],\n",
        "                          callbacks=[DisplayCallback()],\n",
        "                          batch_size=1)\n",
        "\n",
        "\"\"\" fine-tune the model \"\"\"\n",
        "model.trainable = True\n",
        "EPOCHS = 8\n",
        "\n",
        "model_history = model.fit(X, Y, epochs=EPOCHS,\n",
        "                          validation_data=[X_val,Y_val],\n",
        "                          callbacks=[DisplayCallback()],\n",
        "                          batch_size=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYioIESwVCgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9WbzNcLI22N",
        "colab_type": "text"
      },
      "source": [
        "### Show predictions on the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdhJbsQ0SjE0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4aefc5c3-2148-476b-dfa6-bf5c63812f6a"
      },
      "source": [
        "show_predictions(X_val, Y_val, 6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLUphcczWnVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "img_path = '/content/new_picture_for_database'\n",
        "\n",
        "X_test = []\n",
        "for img_name in os.listdir(img_path):\n",
        "    \n",
        "  imagePath = img_path + '/' + img_name\n",
        "\n",
        "  if os.path.isfile(imagePath) and imagePath.endswith(\".jpg\"):\n",
        "\n",
        "    image = plt.imread(imagePath)\n",
        "    image = resize(image, target_shape, preserve_range=True)\n",
        "    X_test.append(image)\n",
        "\n",
        "X_test = np.stack(X_test, axis=0)\n",
        "#print(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVXa2Uhj5pGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage import data\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "from skimage.color import rgb2gray\n",
        "from skimage import filters\n",
        "import skimage.data as data\n",
        "import skimage.segmentation as seg\n",
        "import skimage.filters as filters\n",
        "import skimage.draw as draw\n",
        "import skimage.color as color\n",
        "from cv2 import saliency\n",
        "from collections import Counter\n",
        "from skimage.color import rgb2lab, deltaE_cie76\n",
        "\n",
        "import numpy as np\n",
        "from skimage.io import imread, imsave\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import transform\n",
        "from skimage.transform import rotate, AffineTransform, swirl\n",
        "from skimage.util import random_noise\n",
        "from skimage.filters import gaussian\n",
        "from scipy import ndimage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpmBFYGx5uDx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7dd8c486-0f24-4455-f3ae-e1eb511b2d53"
      },
      "source": [
        "\n",
        "img_path = '/content/content/Stage/database/Bascha_P01_T01_K04_F_Adult_4173_20190330031615.jpg'\n",
        "#img_path = '/content/content/Stage/database/Bascha_P01_T01_K03_M_Adult_4342_20190320161800.jpg'\n",
        "img_path = '/content/content/Stage/database/Bascha_P01_T01_K03_M_Adult_4363_20190320183318.jpg'\n",
        "img_path = '/content/new_picture_for_database/Bascha_P01_T01_K06_F_20190410234048-10.jpg'\n",
        "#img_path = '/content/content/Stage/database/Bascha_P01_T01_K03_M_Adult_5242_20190321032200.jpg'\n",
        "#img_path = '/content/content/Stage/database/Bascha_P01_T01_K03_F_Adult_4274_20190319211855.jpg'\n",
        "#img_path = '/content/content/Stage/database/Bascha_P01_T01_K14_M_Adult_1039_20190607040030.jpg'\n",
        "#img_path = '/content/content/Stage/database/Bascha_P01_T01_K14_M_Adult_1039_20190607040030.jpg'\n",
        "#img_path = '/content/content/Stage/database/Bascha_P01_T05_K20_U_Larva_8359_20190717223645.jpg'\n",
        "#img_path = '/content/content/Stage/database/Bascha_P01_T05_K18_M_Adult_6164_20190703234211.jpg'\n",
        "#img_path = '/content/content/Stage/database/Bascha_P01_T01_K03_F_Adult_4331_20190320100505.jpg'\n",
        "#img_path = '/content/content/Stage/database/Bascha_P01_T01_K03_M_Adult_4293_20190320005553.jpg'\n",
        "#img_path = '/content/content/Stage/database/Bascha_P01_T02_K19_U_Juvenile_8829_20190717033259.jpg'\n",
        "#img_path = '/content/content/Stage/database/Bascha_P01_T04_K16_U_Juvenile_1976_20190620100845.jpg'\n",
        "\n",
        "\n",
        "img = cv2.imread(img_path)\n",
        "\n",
        "img0 = cv2.equalizeHist(img[:,:,0])\n",
        "img1 = cv2.equalizeHist(img[:,:,1])\n",
        "img2 = cv2.equalizeHist(img[:,:,2])\n",
        "img[:,:,0] = img0\n",
        "img[:,:,1] = img1\n",
        "img[:,:,2] = img2\n",
        "\n",
        "\n",
        "cv2_imshow(img)\n",
        "\n",
        "h,w=img.shape[0:2]\n",
        "\n",
        "base_size=h+20,w+20,3\n",
        "# make a 3 channel image for base which is slightly larger than target img\n",
        "base=np.zeros(base_size,dtype=np.uint8)\n",
        "cv2.rectangle(base,(0,0),(w+20,h+20),(255,255,255),30) # really thick white rectangle\n",
        "base[10:h+10,10:w+10]=img # this works\n",
        "img = base\n",
        "\n",
        "\n",
        "hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS) \n",
        "lower_yellow = np.array([5,15,45]) \n",
        "upper_yellow = np.array([90,240,255]) \n",
        "\n",
        "lower_yellow2 = np.array([160,15,45]) \n",
        "upper_yellow2 = np.array([180,240,255]) \n",
        "#hsl(63, 20%, 81%)\n",
        "lower_black = np.array([0,0,75]) \n",
        "upper_black = np.array([35,50,255]) \n",
        "\n",
        "lower_black2 = np.array([155,0,75]) \n",
        "upper_black2 = np.array([180,50,255]) \n",
        "# Here we are defining range of yellow color in HSL \n",
        "# This creates a mask of yellow coloured  \n",
        "# objects found in the frame. \n",
        "mask = cv2.inRange(hls, lower_yellow, upper_yellow)\n",
        "mask2 = cv2.inRange(hls, lower_yellow2, upper_yellow2)\n",
        "mask_b = cv2.inRange(hls, lower_black, upper_black) \n",
        "mask_b2 = cv2.inRange(hls, lower_black2, upper_black2)\n",
        "\n",
        "mask = mask_b2+mask_b+mask+mask2\n",
        "# The bitwise and of the frame and mask is done so  \n",
        "# that only the blue coloured objects are highlighted  \n",
        "# and stored in res \n",
        "#res = cv2.bitwise_or()\n",
        "res = cv2.bitwise_and(img,img, mask= mask) \n",
        "#cv2_imshow(img) \n",
        "cv2_imshow(mask)\n",
        "cv2_imshow(res) \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opHAeXs86R22",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "13540851-4c92-416c-ecf7-ca236f74702b"
      },
      "source": [
        "mask_blur = cv2.GaussianBlur(mask,(5,5),cv2.BORDER_DEFAULT)\n",
        "\n",
        "threshMap = cv2.threshold(mask_blur.astype(\"uint8\"), 0, 255,\n",
        "\tcv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
        "\n",
        "kernel = np.ones((7,7),np.uint8)\n",
        "threshMap = cv2.dilate(threshMap, kernel)\n",
        "threshMap = cv2.erode(threshMap, kernel)\n",
        "\n",
        "print(threshMap.shape)\n",
        "\n",
        "cv2_imshow(mask_blur)\n",
        "cv2_imshow(threshMap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qsc_Mi4-6cco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def auto_canny(image, sigma=0.33):\n",
        "    # compute the median of the single channel pixel intensities\n",
        "    v = np.median(image)\n",
        "\n",
        "    # apply automatic Canny edge detection using the computed median\n",
        "    lower = int(max(0, (1.0 - sigma) * v))\n",
        "    upper = int(min(255, (1.0 + sigma) * v))\n",
        "    edged = cv2.Canny(image, lower, upper)\n",
        "\n",
        "    # return the edged image\n",
        "    return edged"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlJwWeyXFYsy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3ea1b8f9-723d-4fae-8a6b-35ea34dbee10"
      },
      "source": [
        "canny_output = auto_canny(threshMap, sigma = 0.3)\n",
        "#canny_output = cv2.convertScaleAbs(canny_output)\n",
        "kernel = np.ones((5,5),np.uint8)\n",
        "threshed = cv2.dilate(canny_output,kernel)\n",
        "\n",
        "print(np.max(threshed))\n",
        "\n",
        "#print(canny_output[1])\n",
        "plt.imshow(canny_output)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "## findContours(查找轮廓)\n",
        "cnts = cv2.findContours(threshed, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
        "\n",
        "#print(cnts[0])\n",
        "plt.imshow(threshed)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "#print(cnts.shape)\n",
        "\n",
        "#new,contours, hierarchy = cv2.findContours(threshed, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "#contours= sorted(contours, key = cv2.contourArea, reverse = True)[:4]\n",
        "#c=contours[0]\n",
        "#print(cv2.contourArea(c))\n",
        "#final = cv2.drawContours(img, [c], -1, (255,0, 0), 3)\n",
        "\n",
        "\n",
        "#cnts = canny_output\n",
        "#cnts = sorted(canny_output, key=cv2.contourArea)\n",
        "## sorted by area(按照面积排序)\n",
        "cnts = sorted(cnts, key=cv2.contourArea)\n",
        "\n",
        "## get the maximum's boundinRect(获取最大边缘的外接矩形)\n",
        "cnt = cnts[-1]\n",
        "\n",
        "## create mask(创建掩模)\n",
        "mask = np.ones_like(threshMap, np.uint8)*cv2.GC_PR_BGD\n",
        "cv2.drawContours(mask, cnt, -1, cv2.GC_FGD, -1)\n",
        "\n",
        "print(\"shape of cnt: {}\".format(cnt.shape))\n",
        "\n",
        "plt.imshow(mask)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "#new_image = cv2.bitwise_and(img,img,mask=mask)\n",
        "#print(mask)\n",
        "new_image = threshMap.copy()\n",
        "new_image[mask == 2] = 0  # Set values not masked to be 0\n",
        "\n",
        "#plt.imshow(new_image)\n",
        "#plt.colorbar()\n",
        "#plt.show()\n",
        "\n",
        "retval = cv2.contourArea(cnt)\n",
        "print(retval)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt46dKzQ6opH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "outputId": "e524f121-f4c1-4cfc-cd51-4abc1053d7e7"
      },
      "source": [
        "\n",
        "rect = cv2.minAreaRect(cnt)\n",
        "print(\"rect: {}\".format(rect))\n",
        "\n",
        "box = cv2.boxPoints(rect)\n",
        "box = np.int0(box)\n",
        "\n",
        "width = int(rect[1][0])\n",
        "height = int(rect[1][1])\n",
        "\n",
        "src_pts = box.astype(\"float32\")\n",
        "dst_pts = np.array([[0, height-1],\n",
        "                    [0, 0],\n",
        "                    [width-1, 0],\n",
        "                    [width-1, height-1]], dtype=\"float32\")\n",
        "M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
        "warped = cv2.warpPerspective(img, M, (width, height))\n",
        "\n",
        "cv2_imshow(warped)\n",
        "\n",
        "if (warped.shape[0] < warped.shape[1]):\n",
        "    #image = tf.image.resize(image, [width, height])\n",
        "    warped = resize(warped, (height, width),\n",
        "                       anti_aliasing=False, preserve_range=True)\n",
        "      \n",
        "    #print(\"height < width\")\n",
        "    warped = np.transpose(warped,(1,0,2))\n",
        "\n",
        "       \n",
        "else:\n",
        "        #image = tf.image.resize(image, [height, width])\n",
        "    warped = resize(warped, (height, width),\n",
        "                       anti_aliasing=False,preserve_range=True)\n",
        "    \n",
        "cv2_imshow(warped)                     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEu1Zr2hAjEA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "92ae2d2b-27a9-40c5-ebb1-f36ccd3063eb"
      },
      "source": [
        "#Bascha_P01_T03_K07_M_20190418003350-21.jpg\n",
        "target_shape = (128, 128, 3)\n",
        "imagePath = '/content/new_picture_for_database/Bascha_P01_T03_K07_M_20190418003350-21.jpg'\n",
        "image = plt.imread(imagePath)\n",
        "image = resize(image, target_shape, preserve_range=True)\n",
        "\n",
        "pred_mask = create_mask(model.predict(image[tf.newaxis, ...]/255))\n",
        "    #pred_mask = img_as_float(pred_mask)\n",
        "    #print(pred_mask)\n",
        "    #print(np.max(pred_mask))\n",
        "    #print(tf.keras.preprocessing.image.img_to_array(pred_mask).shape)\n",
        "    #print(np.max(pred_mask[0]))\n",
        "    \n",
        "pred_mask = tf.keras.preprocessing.image.img_to_array(pred_mask)\n",
        "    #print(np.max(pred_mask))\n",
        "   \n",
        "selem = skimage.morphology.disk(6)\n",
        "pred_mask = closing(np.squeeze(pred_mask*255), selem)\n",
        "pred_mask = opening(np.squeeze(pred_mask), selem)\n",
        "\n",
        "pred_mask = resize(pred_mask, (150,30), preserve_range=True)\n",
        "image = resize(image, (150,30,3), preserve_range=True)\n",
        "    ## findContours(查找轮廓)\n",
        "cnts = cv2.findContours(pred_mask.astype('uint8'), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE,)[-2]\n",
        "\n",
        "    ## sorted by area(按照面积排序)\n",
        "cnts = sorted(cnts, key=cv2.contourArea)\n",
        "\n",
        "    ## get the maximum's boundinRect(获取最大边缘的外接矩形)\n",
        "cnt = cnts[-1]\n",
        "\n",
        "rect = cv2.minAreaRect(cnt)\n",
        "    #print(\"rect: {}\".format(rect))\n",
        "\n",
        "box = cv2.boxPoints(rect)\n",
        "box = np.int0(box)\n",
        "\n",
        "width = int(rect[1][0])\n",
        "height = int(rect[1][1])\n",
        "\n",
        "src_pts = box.astype(\"float32\")\n",
        "dst_pts = np.array([[0, height-1],\n",
        "                    [0, 0],\n",
        "                    [width-1, 0],\n",
        "                    [width-1, height-1]], dtype=\"float32\")\n",
        "M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
        "image_warped = cv2.warpPerspective(image, M, (width, height))\n",
        "cv2_imshow(image_warped)\n",
        "warped_pred_mask = cv2.warpPerspective(pred_mask, M, (width, height))\n",
        "cv2_imshow(warped_pred_mask)\n",
        "\n",
        "input_shape = (75,30,3)\n",
        "height = input_shape[0]\n",
        "width = input_shape[1]\n",
        "    #print(np.max(image))\n",
        "    #print(np.min(image))\n",
        "reversed = False\n",
        "if (image_warped.shape[0] < image_warped.shape[1]):\n",
        "        #print(image_warped.shape[0])\n",
        "        #print(image_warped.shape[1])\n",
        "    #image = tf.image.resize(image, [width, height])\n",
        "    image_warped = resize(image_warped, (width, height),\n",
        "                       anti_aliasing=False, preserve_range=True)\n",
        "    warped_pred_mask = resize(warped_pred_mask, (width, height),\n",
        "                       anti_aliasing=False, preserve_range=True)      \n",
        "    #print(\"height < width\")\n",
        "    image_warped = np.transpose(image_warped,(1,0,2))\n",
        "    cv2_imshow(image_warped)\n",
        "    warped_pred_mask = np.transpose(warped_pred_mask,(1,0))\n",
        "    cv2_imshow(warped_pred_mask)\n",
        "    print('height < width')\n",
        "    reversed = True\n",
        "else:\n",
        "        #print(image_warped.shape[0])\n",
        "        #print(image_warped.shape[1])\n",
        "        #image = tf.image.resize(image, [height, width])\n",
        "    image_warped = resize(image_warped, (height, width),\n",
        "                       anti_aliasing=False,preserve_range=True)\n",
        "    cv2_imshow(image_warped)\n",
        "    warped_pred_mask = resize(warped_pred_mask, (height, width),\n",
        "                       anti_aliasing=False, preserve_range=True)\n",
        "    cv2_imshow(warped_pred_mask)\n",
        "       \n",
        "    \n",
        "        \n",
        "warped_pred_mask = resize(warped_pred_mask, (500,30, 1), preserve_range=True)\n",
        "\n",
        "skeleton = skeletonize(rescale_intensity(tf.keras.preprocessing.image.img_to_array(warped_pred_mask),in_range=(-1,1)))\n",
        "\n",
        "skeleton = resize(skeleton, (75,30,3), preserve_range=True)\n",
        "cv2_imshow(skeleton)\n",
        "\n",
        "display([resize(image_warped, (75,30,3), preserve_range=True), resize(warped_pred_mask, (75,30, 3), preserve_range=True), resize(skeleton, (75,30, 3), preserve_range=True)])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzzygjTvZIPS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d47eec7a-fb92-48fa-8c65-295861dae007"
      },
      "source": [
        "from skimage.util import img_as_float\n",
        "num = 500\n",
        "k = 0\n",
        "for image in X_test:\n",
        "  if k < num:\n",
        "    pred_mask = create_mask(model.predict(image[tf.newaxis, ...]/255))\n",
        "    #pred_mask = img_as_float(pred_mask)\n",
        "    #print(pred_mask)\n",
        "    #print(np.max(pred_mask))\n",
        "    #print(tf.keras.preprocessing.image.img_to_array(pred_mask).shape)\n",
        "    #print(np.max(pred_mask[0]))\n",
        "    \n",
        "    pred_mask = tf.keras.preprocessing.image.img_to_array(pred_mask)\n",
        "    #print(np.max(pred_mask))\n",
        "   \n",
        "    selem = skimage.morphology.disk(6)\n",
        "    pred_mask = closing(np.squeeze(pred_mask*255), selem)\n",
        "    pred_mask = opening(np.squeeze(pred_mask), selem)\n",
        "\n",
        "    pred_mask = resize(pred_mask, (150,30), preserve_range=True)\n",
        "    image = resize(image, (150,30,3), preserve_range=True)\n",
        "    ## findContours(查找轮廓)\n",
        "    cnts = cv2.findContours(pred_mask.astype('uint8'), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE,)[-2]\n",
        "\n",
        "    ## sorted by area(按照面积排序)\n",
        "    cnts = sorted(cnts, key=cv2.contourArea)\n",
        "\n",
        "    ## get the maximum's boundinRect(获取最大边缘的外接矩形)\n",
        "    cnt = cnts[-1]\n",
        "\n",
        "    rect = cv2.minAreaRect(cnt)\n",
        "    #print(\"rect: {}\".format(rect))\n",
        "\n",
        "    box = cv2.boxPoints(rect)\n",
        "    box = np.int0(box)\n",
        "\n",
        "    width = int(rect[1][0])\n",
        "    height = int(rect[1][1])\n",
        "\n",
        "    src_pts = box.astype(\"float32\")\n",
        "    dst_pts = np.array([[0, height-1],\n",
        "                    [0, 0],\n",
        "                    [width-1, 0],\n",
        "                    [width-1, height-1]], dtype=\"float32\")\n",
        "    M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
        "    image_warped = cv2.warpPerspective(image, M, (width, height))\n",
        "    cv2_imshow(image_warped)\n",
        "    warped_pred_mask = cv2.warpPerspective(pred_mask, M, (width, height))\n",
        "    cv2_imshow(warped_pred_mask)\n",
        "\n",
        "    input_shape = (75,30,3)\n",
        "    height = input_shape[0]\n",
        "    width = input_shape[1]\n",
        "    #print(np.max(image))\n",
        "    #print(np.min(image))\n",
        "    reversed = False\n",
        "    if (image_warped.shape[0] < image_warped.shape[1]):\n",
        "        #print(image_warped.shape[0])\n",
        "        #print(image_warped.shape[1])\n",
        "    #image = tf.image.resize(image, [width, height])\n",
        "        image_warped = resize(image_warped, (width, height),\n",
        "                       anti_aliasing=False, preserve_range=True)\n",
        "        warped_pred_mask = resize(warped_pred_mask, (width, height),\n",
        "                       anti_aliasing=False, preserve_range=True)      \n",
        "    #print(\"height < width\")\n",
        "        image_warped = np.transpose(image_warped,(1,0,2))\n",
        "        cv2_imshow(image_warped)\n",
        "        warped_pred_mask = np.transpose(warped_pred_mask,(1,0))\n",
        "        cv2_imshow(warped_pred_mask)\n",
        "        print('height < width')\n",
        "        reversed = True\n",
        "    else:\n",
        "        #print(image_warped.shape[0])\n",
        "        #print(image_warped.shape[1])\n",
        "        #image = tf.image.resize(image, [height, width])\n",
        "        image_warped = resize(image_warped, (height, width),\n",
        "                       anti_aliasing=False,preserve_range=True)\n",
        "        cv2_imshow(image_warped)\n",
        "        warped_pred_mask = resize(warped_pred_mask, (height, width),\n",
        "                       anti_aliasing=False, preserve_range=True)\n",
        "        cv2_imshow(warped_pred_mask)\n",
        "       \n",
        "    \n",
        "        \n",
        "    warped_pred_mask = resize(warped_pred_mask, (500,30, 1), preserve_range=True)\n",
        "\n",
        "    skeleton = skeletonize(rescale_intensity(tf.keras.preprocessing.image.img_to_array(warped_pred_mask),in_range=(-1,1)))\n",
        "\n",
        "    skeleton = resize(skeleton, (75,30,3), preserve_range=True)\n",
        "    cv2_imshow(skeleton)\n",
        "    #pred_mask = binary_closing(pred_mask[0], selem=skimage.morphology.disk(3))\n",
        "    #pred_mask = black_tophat(pred_mask, selem=None, out=None)\n",
        "    #pred_mask = area_closing(tf.keras.preprocessing.image.img_to_array(pred_mask), area_threshold=64, connectivity=1, parent=None, tree_traverser=None)\n",
        "    #pred_mask = area_closing(np.squeeze(tf.keras.preprocessing.image.img_to_array(pred_mask)), area_threshold=128, connectivity=2, parent=None, tree_traverser=None)\n",
        "    #pred_mask = area_opening(pred_mask, area_threshold=128,, connectivity=2, parent=None, tree_traverser=None)\n",
        "    #tf.expand_dims(pred_mask, axis = -1)\n",
        "    print(k)\n",
        "    #display([resize(image_warped/255, (75,30, 3), preserve_range=True), resize(warped_pred_mask, (75,30, 3), preserve_range=True), resize(skeleton, (75,30, 3), preserve_range=True)])\n",
        "    #display([warped/255,warped_pred_mask,skeleton])\n",
        "    k += 1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PHkZnz-FpeK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "outputId": "75a41bfa-b9bf-4f75-973c-40525d481f25"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3BofE_ivpNV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "ae2da251-3d31-4a0f-f16b-ce25db1fe87a"
      },
      "source": [
        "from tensorflow.keras.models import load_model, save_model\n",
        "# Save the entire model as a SavedModel.\n",
        "!rm -rf /content/saved_model\n",
        "!mkdir -p saved_model\n",
        "#model.save_model('saved_model/my_model') \n",
        "save_model(model, 'saved_model/Unet_base')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "karVf097_6wS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8c092c53-99a6-4edf-f8ea-46b66e91c0b4"
      },
      "source": [
        "import shutil\n",
        "shutil.make_archive('unet_new_base', 'zip', '/content/saved_model')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkXuRhkHCfft",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "94d9a70f-7005-4ff2-d7b4-e82c7570a7d3"
      },
      "source": [
        "shutil.move('/content/unet_new_base.zip', '/content/drive/My Drive/Stage/lite_ds')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xWA-csmbT1C",
        "colab_type": "text"
      },
      "source": [
        "## Newt Straightening"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMzTs3DrXqE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def extract_image_unet(img_path):\n",
        "  \"\"\" method used to extract the greatest region in the mask output of the \n",
        "  Unet. \n",
        "  \"\"\"\n",
        "  image = plt.imread(img_path)\n",
        "  image = resize(image, (128,128,3), preserve_range=True)\n",
        "  pred_mask = create_mask(model.predict(image[tf.newaxis, ...]/255))\n",
        "  image = resize(image, (200,50,3), preserve_range=True)\n",
        "    \n",
        "  pred_mask = tf.keras.preprocessing.image.img_to_array(pred_mask)\n",
        "\n",
        "   \n",
        "  selem = skimage.morphology.disk(6)\n",
        "  pred_mask = closing(np.squeeze(pred_mask*255), selem)\n",
        "  pred_mask = opening(np.squeeze(pred_mask), selem)\n",
        "\n",
        "  pred_mask = resize(pred_mask, (200,50, 1), preserve_range=True)\n",
        "  \n",
        "\n",
        "  try:\n",
        "    labels_mask = measure.label(pred_mask) \n",
        "  except ValueError:  #raised if `y` is empty.\n",
        "    print('no region found.')\n",
        "    return image\n",
        "   \n",
        "\n",
        "  try:\n",
        "    regions = measure.regionprops(labels_mask)\n",
        "  except ValueError:  #raised if `y` is empty.\n",
        "    print(\"no region found.\")\n",
        "    return image\n",
        "  regions.sort(key=lambda x: x.area, reverse=True)\n",
        "\n",
        "  if len(regions) > 1:\n",
        "    for rg in regions[1:]:\n",
        "        labels_mask[rg.coords[:,0], rg.coords[:,1]] = 0\n",
        "\n",
        "\n",
        "  labels_mask[labels_mask!=0] = 1\n",
        "  mask = labels_mask\n",
        "\n",
        "  skeleton = skeletonize(rescale_intensity(tf.keras.preprocessing.image.img_to_array(mask),in_range=(-1,1)))\n",
        "\n",
        "\n",
        "  if mask.shape[-1] > 0:\n",
        "    # We're treating all instances as one, so collapse the mask into one layer\n",
        "    mask = (np.sum(mask, -1, keepdims=True) >= 1)\n",
        "    img_extracted = np.where(mask, image, 255).astype(np.uint8)\n",
        "    image = img_extracted/255\n",
        "\n",
        "\n",
        "  skeleton = np.where(np.squeeze(skeleton) > 0)\n",
        "  skeleton = np.array(skeleton)\n",
        "\n",
        "  a = skeleton[0]\n",
        "  b = skeleton[1]\n",
        " \n",
        "  s = pd.Series(np.squeeze(a))\n",
        "#print(s.values)\n",
        "#print(s[s.duplicated()].index)\n",
        "  duplicates = s[s.duplicated()].index\n",
        " \n",
        "  duplicate = 0\n",
        "  skel_size = skeleton[0].shape[0]\n",
        "  \n",
        "  shifts = []\n",
        "  center = int(pred_mask.shape[1]/2)\n",
        "  i = 0\n",
        "  dups = []\n",
        "  while (i < skel_size):\n",
        "  \n",
        "\n",
        "    if (i in duplicates and not i in dups):\n",
        "     \n",
        "      dups.append(i)\n",
        "      \n",
        "      d = skeleton[1][skeleton[0] == s[i]]\n",
        "     \n",
        "      mid = int(np.mean(d))\n",
        "    \n",
        "      \n",
        "   \n",
        "      diff = mid-center\n",
        "      shifts[-1] = -diff\n",
        "    \n",
        "      i += 1\n",
        "      \n",
        "    elif (i in duplicates and i in dups):\n",
        "      continue\n",
        "    else:\n",
        "      diff = skeleton[1][i]-center\n",
        "      \n",
        "      shifts.append(-diff)\n",
        "      i += 1\n",
        "  \n",
        "  \n",
        "  k = 0\n",
        "  img = image.copy()\n",
        "\n",
        "  for diff in shifts:\n",
        "    \n",
        "    image[s.unique()[k],:,0] = shift(image[s.unique()[k],:,0], diff , output=None, order=3, mode='wrap', prefilter=False)\n",
        "    image[s.unique()[k],:,1] = shift(image[s.unique()[k],:,1], diff , output=None, order=3, mode='wrap', prefilter=False)\n",
        "    image[s.unique()[k],:,2] = shift(image[s.unique()[k],:,2], diff , output=None, order=3, mode='wrap', prefilter=False)\n",
        "    \n",
        "    k += 1\n",
        "\n",
        "\n",
        "  for i in range (image.shape[0]):\n",
        "    if (not i in skeleton[0]):\n",
        "      image[i,:] = 1\n",
        "\n",
        "  white = np.array([1, 1, 1])\n",
        "  mask = np.abs(image - white).sum(axis=2) < 0.05\n",
        "\n",
        "  # Find the bounding box of those pixels\n",
        "  try:\n",
        "    coords = np.array(np.nonzero(~mask))\n",
        "    top_left = np.min(coords, axis=1)\n",
        "    bottom_right = np.max(coords, axis=1)\n",
        "  \n",
        "    out = image[top_left[0]:bottom_right[0],\n",
        "            top_left[1]:bottom_right[1]]\n",
        "    \n",
        "  except:\n",
        "    return None\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qy8qSPUA7HC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3fc0c743-d871-4ba3-cf77-680e19236f53"
      },
      "source": [
        "img_path = '/content/aug_database_for_seg/aug_database_for_seg/Bascha_P01_T01_K03_F_Adult_4343_20190320163610.jpg'\n",
        "image = skimage.io.imread(img_path, plugin='matplotlib')\n",
        "plt.imshow(image)\n",
        "plt.show()\n",
        "\n",
        "img_path = '/content/aug_database_for_seg/aug_database_for_seg/Bascha_P01_T01_K03_F_Adult_4343_20190320163610.jpg'\n",
        "image_extracted = extract_image_unet(img_path)\n",
        "plt.imshow(image_extracted)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AaLRChhpSkt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "ff2a97e4-e474-4d3e-a2df-c99ae403f69e"
      },
      "source": [
        "\n",
        "def preprocess_images(image_path, input_shape):\n",
        "  \"\"\" apply all augmentation methods defined above on the image \"\"\"\n",
        "\n",
        "  image = img_as_float(io.imread(image_path))\n",
        "  image = exposure.equalize_adapthist(image, clip_limit=0.03)\n",
        "  image = random_saturation(image, show_result=False)\n",
        "  image = random_brightness(image, show_result=False)\n",
        "     \n",
        "      \n",
        "  image = image*255\n",
        "      \n",
        "  shear = uniform(-.1, .1)\n",
        "  tfr = AffineTransform(shear=shear)\n",
        "  sheared = transform.warp(image, tfr, order=1, preserve_range=True,mode='constant', cval=255)\n",
        "  \n",
        "  strength = uniform(-1, 1)\n",
        "  image = swirl(sheared, rotation=0, strength=strength, radius=500,mode='constant', cval=255)\n",
        "\n",
        "\n",
        "  return image\n",
        "\n",
        "input_shape = (56,56,3)\n",
        "img_path = '/content/Stage_cropped/database/Bascha_P01_T01_K03_F_Adult_4413_20190321004956.jpg'\n",
        "img = preprocess_images(img_path, input_shape)\n",
        "plt.imshow(img/255)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yfsk6E8o-Ne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape = (75,30,3)\n",
        "\n",
        "\n",
        "def augmentationImageUnet(img_path,img_aug_path, input_shape):\n",
        "\n",
        "  \"\"\" Create a proper dataset where each folder contains the images of one \n",
        "  specimen, randomly augmented 20 times for each \"real\" image present in the \n",
        "  original dataset \"\"\"\n",
        "\n",
        "  !rm -rf /content/databaseAug #useful when running the method again for makedirs\n",
        "  data = pd.read_csv('/content/Stage_Tritons/training.csv')\n",
        "\n",
        "  labels = data.iloc[:,4]\n",
        "\n",
        "  names = data.iloc[:,0]\n",
        "\n",
        "  labels_uniques, counts = np.unique(labels, return_counts=True)\n",
        "  \n",
        "\n",
        "  for label in labels_uniques:\n",
        "    os.makedirs(img_aug_path+'/train/'+label)\n",
        "    os.makedirs(img_aug_path+'/test/'+label)\n",
        "\n",
        "\n",
        "  print(\"Création de la base de données augmentées en cours...\")\n",
        "  # List all files in a directory using scandir()\n",
        "  basepath = img_path\n",
        "  with os.scandir(basepath) as images:\n",
        "    for im in images:\n",
        "\n",
        "      if(im.name in names.values):\n",
        "        \n",
        "        id = names[names == im.name].index[0]\n",
        "  \n",
        "        label = labels.iloc[id]\n",
        "\n",
        "        id_label = np.where(labels_uniques == label)\n",
        "\n",
        "        imagePath = basepath + '/' + im.name\n",
        "\n",
        "        count = counts[id_label]\n",
        "        \n",
        "        k = 0\n",
        "        while (k < 20):  \n",
        "          image = preprocess_images(imagePath, input_shape)\n",
        "          \n",
        "          augPath = img_aug_path+'/train/'+label+'/' + im.name[:-4] + str(k) + '.jpg'\n",
        "          image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "          plt.imsave(augPath, image/255)\n",
        "          k += 1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYMtmHYcqxm8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0b9be193-5a12-47af-8985-17debd566d59"
      },
      "source": [
        "img_path = '/content/Stage_cropped/database'\n",
        "img_aug_path = '/content/databaseAug'\n",
        "augmentationImageUnet(img_path,img_aug_path,input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrdK7ZkhzVX-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8409a49f-f4ac-4819-fd06-bf217db1d538"
      },
      "source": [
        "\"\"\" Train/Test split \"\"\"\n",
        "\n",
        "train_path = '/content/databaseAug/train'\n",
        "test_path = '/content/databaseAug/test'\n",
        "dest1 =  pathlib.Path(test_path)\n",
        "source1 = pathlib.Path(train_path)\n",
        "\n",
        "for label in os.listdir(train_path):\n",
        "  if len(os.listdir(train_path + '/' + label)) == 0: # Check if empty..\n",
        "    shutil.rmtree(train_path + '/' + label) # Delete..\n",
        "\n",
        "import fnmatch\n",
        "\n",
        "\n",
        "\n",
        "for class_name in os.listdir(train_path):\n",
        "      \n",
        "\n",
        "      class_path = os.path.join(source1, class_name)\n",
        "      class_path_test = os.path.join(dest1, class_name)\n",
        "      #os.mkdir(class_path_test)\n",
        "      #label_map_dict[class_name]=count_label\n",
        "      imgs = fnmatch.filter(os.listdir(class_path), '*.jpg')\n",
        "      nbr_img = len(imgs)\n",
        "\n",
        "      idx = np.arange(nbr_img)\n",
        "      idx_test = np.random.choice(idx, size=5, replace=False)\n",
        "      print(len(os.listdir(class_path)))\n",
        "\n",
        "      #Copie de certains éléments dans le test set\n",
        "      for i in range (len(os.listdir(class_path))):\n",
        "        if i in idx_test:\n",
        "          print(str(class_path) + '/'+ str(os.listdir(class_path)[i]))\n",
        "          shutil.copy(str(class_path) + '/'+ str(os.listdir(class_path)[i]), str(class_path_test) + '/'+ str(os.listdir(class_path)[i]))\n",
        "      #Suppression des éléments copiés dans le train set\n",
        "      files = os.listdir(class_path)\n",
        "      for i in range (len(files)):\n",
        "        if i in idx_test:\n",
        "          print(str(class_path) + '/'+ str(files[i]))\n",
        "          file_path = pathlib.Path(str(class_path) + '/'+ str(files[i]))\n",
        "          os.remove(file_path)\n",
        "          #print(\"removed\")\n",
        "\n",
        "\n",
        "for label in os.listdir(test_path):\n",
        "  if len(os.listdir(test_path + '/' + label)) == 0: # Check if empty..\n",
        "    shutil.rmtree(test_path + '/' + label) # Delete.."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUOOPZRvg_0z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e012899a-6188-4b4b-e5d8-e4ac08382c40"
      },
      "source": [
        "train_size = sum(len(files) for _, _, files in os.walk(r'/content/datasetFinalUnet/content/ds_final/train'))\n",
        "print(train_size)\n",
        "test_size = sum(len(files) for _, _, files in os.walk(r'/content/datasetFinalUnet/content/ds_final/test'))\n",
        "print(test_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoHk85HI1DMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_crop(ds_types_path, ds_final_path, input_shape):\n",
        "  \"\"\" take the proper dataset created by augmentationImage and extract the newts\n",
        "  by segmenting and cropping \"\"\"\n",
        "   \n",
        "  !rm -rf /content/ds_final\n",
        "\n",
        "  for ds_type in os.listdir(ds_types_path):\n",
        "    \n",
        "    print(ds_type)\n",
        "    ds_path = ds_types_path + '/' + ds_type\n",
        "    final_path = ds_final_path + '/' + ds_type\n",
        "\n",
        "    \n",
        "\n",
        "    for class_name in os.listdir(ds_path):\n",
        "      \n",
        "      #print(class_name)\n",
        "      dsPath = ds_path + '/' + class_name\n",
        "      #print(dsPath)\n",
        "      dsFinalPath = final_path + '/' + class_name\n",
        "\n",
        "      for img_name in os.listdir(dsPath):\n",
        "\n",
        "        #if os.path.isfile(img_name):\n",
        "        \n",
        "          #print(img_name)\n",
        "          imagePath = dsPath + '/' + img_name\n",
        "          print(imagePath)\n",
        "          augPath = dsFinalPath + '/' + img_name\n",
        "          if not (os.path.isdir(dsFinalPath)):\n",
        "            os.makedirs(dsFinalPath)\n",
        "          \n",
        "          image = extract_image_unet(imagePath)\n",
        "          try:\n",
        "          #plt.imshow(image)\n",
        "          #plt.show()\n",
        "\n",
        "            height = input_shape[0]\n",
        "            width = input_shape[1]\n",
        "          #print(np.max(image))\n",
        "          #print(np.min(image))\n",
        "  \n",
        "            if (image.shape[0] < image.shape[1]):\n",
        "            #image = tf.image.resize(image, [width, height])\n",
        "              image = resize(image, (width, height),\n",
        "                       anti_aliasing=False)\n",
        "            #print(\"height < width\")\n",
        "              image = np.transpose(image,(1,0,2))\n",
        "            else:\n",
        "            #image = tf.image.resize(image, [height, width])\n",
        "              image = resize(image, (height, width),\n",
        "                       anti_aliasing=False)\n",
        "        \n",
        "          #image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "         \n",
        "          #plt.imshow(image)\n",
        "          #plt.show()\n",
        "            plt.imsave(augPath, image)\n",
        "          \n",
        "          except:\n",
        "            pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVtbGzGC2H28",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "outputId": "9701d233-b0cd-419c-dacb-f3ac1ec47372"
      },
      "source": [
        "\n",
        "img = plt.imread('/content/databaseAug/test/KM00875/Bascha_P01_T06_K13_U_Juvenile_1009_2019060122283015.jpg')\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yE6Yt-D1mE5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "558ad961-78e2-4df6-d598-16bbb345dab2"
      },
      "source": [
        "input_shapes = (75,30,3)\n",
        "img_aug_path = '/content/databaseAug'\n",
        "img_final_path = '/content/ds_final'\n",
        "extract_crop(img_aug_path, img_final_path, input_shapes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxiu9g6TL8Gn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a041b9b8-cb0d-4450-ca82-6ce18776b714"
      },
      "source": [
        "path_train = '/content/ds_final/train'\n",
        "path_test = '/content/ds_final/test'\n",
        "\n",
        "print(len(os.listdir(path_train)))\n",
        "\n",
        "print(len(os.listdir(path_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHfqhXWGLiPf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ea9587ef-46a3-4d2c-ec67-288d299abf59"
      },
      "source": [
        "!zip -r /content/ds_final_unet /content/ds_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ia2Nj2R7zmu0",
        "colab_type": "text"
      },
      "source": [
        "# Import Tensorflow 2 and scikit-image modules.\n",
        "Do not run this cell if you already imported Tensorflow 1 to use de Mask RCNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBAlye9Q4If4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import datasets\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.preprocessing.image import save_img\n",
        "#import hdbscan\n",
        "import umap\n",
        "from numpy import linalg as LA\n",
        "\n",
        "import urllib\n",
        "\n",
        "#import tensorflow_docs as tfdocs\n",
        "#import tensorflow_docs.plots\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import PIL.Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.figsize'] = (12, 5)\n",
        "\n",
        "import skimage\n",
        "from skimage import measure\n",
        "import numpy as np\n",
        "from skimage.io import imread, imsave\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import transform\n",
        "from skimage.transform import rotate, AffineTransform, swirl, resize\n",
        "from skimage.util import random_noise\n",
        "from skimage.filters import gaussian\n",
        "from skimage import io, img_as_float, img_as_float64\n",
        "from scipy import ndimage\n",
        "from pathlib import Path\n",
        "from skimage import data, img_as_float\n",
        "from skimage import exposure\n",
        "\n",
        "from random import random, uniform\n",
        "\n",
        "import os\n",
        "import pathlib\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "import numba\n",
        "from numba import jit\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4omnMszWAKO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "965b6062-9f1d-4d38-fe93-474dc2e0034b"
      },
      "source": [
        "tf.config.experimental.list_physical_devices('GPU')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X97jCrOXwEGh",
        "colab_type": "text"
      },
      "source": [
        "# Utility methods for image augmentation, segmentation, cropping and proper datasets generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb8L_BAg9_vo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "#measure.label()\n",
        "def extract_image(img_path):\n",
        "  \"\"\" method used to extract the greatest region in the mask output of the \n",
        "  Mask RCNN. \n",
        "  \"\"\"\n",
        "  image = skimage.io.imread(img_path, plugin='matplotlib')\n",
        "  print(image.shape)\n",
        "  # Detect objects\n",
        "  r = model.detect([image], verbose=1)[0]\n",
        "\n",
        "  \n",
        "\n",
        "  # Extract the greatest region \n",
        "  try:\n",
        "    labels_mask = measure.label(r['masks']) \n",
        "  except ValueError:  #raised if `y` is empty.\n",
        "    print('no region found.')\n",
        "    return image\n",
        "   \n",
        "  #print(labels_mask)                 \n",
        "  #print(labels_mask.astype(np.uint8))\n",
        "  #plt.imshow(np.squeeze(labels_mask.astype(np.uint8)))\n",
        "  #regions = measure.regionprops(np.squeeze(labels_mask.astype(np.uint8)))\n",
        "  try:\n",
        "    regions = measure.regionprops(labels_mask)\n",
        "  except ValueError:  #raised if `y` is empty.\n",
        "    print(\"no region found.\")\n",
        "    return image\n",
        "  regions.sort(key=lambda x: x.area, reverse=True)\n",
        "  #print(regions)\n",
        "  #print(len(regions))\n",
        "  #if (len(regions) == 0):\n",
        "    #return image\n",
        "  if len(regions) > 1:\n",
        "    for rg in regions[1:]:\n",
        "        labels_mask[rg.coords[:,0], rg.coords[:,1]] = 0\n",
        "\n",
        "\n",
        "  labels_mask[labels_mask!=0] = 1\n",
        "  mask = labels_mask\n",
        "  #plt.imshow(np.squeeze(mask))\n",
        "\n",
        "  if mask.shape[-1] > 0:\n",
        "    # We're treating all instances as one, so collapse the mask into one layer\n",
        "    mask = (np.sum(mask, -1, keepdims=True) >= 1)\n",
        "    img_extracted = np.where(mask, image, 255).astype(np.uint8)\n",
        "    image = img_extracted/255\n",
        "  \n",
        "  white = np.array([1, 1, 1])\n",
        "  mask = np.abs(image - white).sum(axis=2) < 0.05\n",
        "\n",
        "  # Find the bounding box of those pixels\n",
        "  coords = np.array(np.nonzero(~mask))\n",
        "  top_left = np.min(coords, axis=1)\n",
        "  bottom_right = np.max(coords, axis=1)\n",
        "\n",
        "  out = image[top_left[0]:bottom_right[0],\n",
        "            top_left[1]:bottom_right[1]]\n",
        "\n",
        "\n",
        "  # Save output\n",
        "  #file_name = \"newt_{:%Y%m%dT%H%M%S}.png\".format(datetime.datetime.now())\n",
        "  #skimage.io.imsave(file_name, img_extracted)\n",
        "  \n",
        "\n",
        "  return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BdKZXFi3gPg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "3b320285-9f84-4eab-8f6c-fc8151b7b27e"
      },
      "source": [
        "\"\"\" Here is an example of what extract_image can do \"\"\"\n",
        "\n",
        "img_path = '/content/aug_database_for_seg/aug_database_for_seg/Bascha_P01_T01_K03_F_Adult_4307_20190320020338.jpg'\n",
        "image = skimage.io.imread(img_path, plugin='matplotlib')\n",
        "plt.imshow(image)\n",
        "plt.show()\n",
        "\n",
        "image_extracted = extract_image(img_path)\n",
        "plt.imshow(image_extracted)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEgR-g9L6O2M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "4fbffaca-e948-4820-aa4f-283b2d2063b9"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from skimage import data, img_as_float\n",
        "from skimage import exposure\n",
        "\n",
        "\n",
        "matplotlib.rcParams['font.size'] = 8\n",
        "\n",
        "\n",
        "def plot_img_and_hist(image, axes, bins=256):\n",
        "    \"\"\"Plot an image along with its histogram and cumulative histogram.\n",
        "\n",
        "    \"\"\"\n",
        "    image = img_as_float(image)\n",
        "    ax_img, ax_hist = axes\n",
        "    ax_cdf = ax_hist.twinx()\n",
        "\n",
        "    # Display image\n",
        "    ax_img.imshow(image, cmap=plt.cm.gray)\n",
        "    ax_img.set_axis_off()\n",
        "\n",
        "    # Display histogram\n",
        "    ax_hist.hist(image.ravel(), bins=bins, histtype='step', color='black')\n",
        "    ax_hist.ticklabel_format(axis='y', style='scientific', scilimits=(0, 0))\n",
        "    ax_hist.set_xlabel('Pixel intensity')\n",
        "    ax_hist.set_xlim(0, 1)\n",
        "    ax_hist.set_yticks([])\n",
        "\n",
        "    # Display cumulative distribution\n",
        "    img_cdf, bins = exposure.cumulative_distribution(image, bins)\n",
        "    ax_cdf.plot(bins, img_cdf, 'r')\n",
        "    ax_cdf.set_yticks([])\n",
        "\n",
        "    return ax_img, ax_hist, ax_cdf\n",
        "\n",
        "\"\"\" the purpose of this code is to compare different contrast enhancing methods\n",
        "\"\"\"\n",
        "# Load an example image\n",
        "img = data.moon()\n",
        "img = image\n",
        "# Contrast stretching\n",
        "p2, p98 = np.percentile(img, (2, 98))\n",
        "img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
        "\n",
        "# Equalization\n",
        "img_eq = exposure.equalize_hist(img)\n",
        "\n",
        "# Adaptive Equalization\n",
        "#img_adapteq[:,:,0] = exposure.equalize_adapthist(img[:,:,0], clip_limit=0.03)\n",
        "#img_adapteq[:,:,1] = exposure.equalize_adapthist(img[:,:,1], clip_limit=0.03)\n",
        "#img_adapteq[:,:,2] = exposure.equalize_adapthist(img[:,:,2], clip_limit=0.03)\n",
        "img_adapteq = exposure.equalize_adapthist(img, clip_limit=0.03)\n",
        "\n",
        "# Display results\n",
        "fig = plt.figure(figsize=(8, 5))\n",
        "axes = np.zeros((2, 4), dtype=np.object)\n",
        "axes[0, 0] = fig.add_subplot(2, 4, 1)\n",
        "for i in range(1, 4):\n",
        "    axes[0, i] = fig.add_subplot(2, 4, 1+i, sharex=axes[0,0], sharey=axes[0,0])\n",
        "for i in range(0, 4):\n",
        "    axes[1, i] = fig.add_subplot(2, 4, 5+i)\n",
        "\n",
        "ax_img, ax_hist, ax_cdf = plot_img_and_hist(img, axes[:, 0])\n",
        "ax_img.set_title('Low contrast image')\n",
        "\n",
        "y_min, y_max = ax_hist.get_ylim()\n",
        "ax_hist.set_ylabel('Number of pixels')\n",
        "ax_hist.set_yticks(np.linspace(0, y_max, 5))\n",
        "\n",
        "ax_img, ax_hist, ax_cdf = plot_img_and_hist(img_rescale, axes[:, 1])\n",
        "ax_img.set_title('Contrast stretching')\n",
        "\n",
        "ax_img, ax_hist, ax_cdf = plot_img_and_hist(img_eq, axes[:, 2])\n",
        "ax_img.set_title('Histogram equalization')\n",
        "\n",
        "ax_img, ax_hist, ax_cdf = plot_img_and_hist(img_adapteq, axes[:, 3])\n",
        "ax_img.set_title('Adaptive equalization')\n",
        "\n",
        "ax_cdf.set_ylabel('Fraction of total intensity')\n",
        "ax_cdf.set_yticks(np.linspace(0, 1, 5))\n",
        "\n",
        "# prevent overlap of y-axis labels\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spRSPekXqDCO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "outputId": "3a9d4a5d-090f-461d-9702-34c759a84281"
      },
      "source": [
        "def random_brightness(rgb, show_result = False):\n",
        "  \"\"\" Modify randomly the brightness of the input image \"\"\"\n",
        "  lab = skimage.color.rgb2lab(rgb)\n",
        "\n",
        "  #plt.imshow(lab)\n",
        "  brightness = uniform(-20, 20)\n",
        "  \n",
        "  #print(lab[:,:,0])\n",
        "  lab[:,:,0] = lab[:,:,0] + brightness\n",
        "  #print(np.max(lab[:,:,0]))\n",
        "  #print(lab[:,:,0])\n",
        "  rgb = skimage.color.lab2rgb(lab)\n",
        "  if show_result:\n",
        "    plt.imshow(rgb)\n",
        "    plt.show()\n",
        "\n",
        "  return rgb\n",
        "\n",
        "imagePath = '/content/Stage_cropped/database/Bascha_P01_T06_K20_U_Adult_8012_20190719220609.jpg'\n",
        "image = img_as_float(io.imread(imagePath))\n",
        "#image = image/255\n",
        "image = img_adapteq\n",
        "lab = random_brightness(image, show_result=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_xmgrb0tnKH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "outputId": "5a65edd5-3e07-4a5e-c09a-10bdee09c4f1"
      },
      "source": [
        "def random_saturation(rgb, show_result = False):\n",
        "  \"\"\" Modify randomly the saturation of the input image \"\"\"\n",
        "  hsv = skimage.color.rgb2hsv(rgb)\n",
        "\n",
        "  #plt.imshow(hsv)\n",
        "  saturation = uniform(-0.35, 0.35)\n",
        "  \n",
        "  #print(hsv[:,:,1])\n",
        "  hsv[:,:,1] = hsv[:,:,1] + saturation\n",
        "  #print(np.max(lab[:,:,0]))\n",
        "  #print(hsv[:,:,1])\n",
        "  rgb = skimage.color.hsv2rgb(hsv)\n",
        "\n",
        "  if show_result:\n",
        "    plt.imshow(rgb)\n",
        "    plt.show()\n",
        "\n",
        "  return rgb\n",
        "\n",
        "imagePath = '/content/Stage_cropped/database/Bascha_P01_T06_K20_U_Adult_8012_20190719220609.jpg'\n",
        "image = img_as_float(io.imread(imagePath))\n",
        "#image = image/255\n",
        "#image = img_adapteq\n",
        "rgb = random_saturation(image, show_result=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSdKQH8_-atO",
        "colab_type": "text"
      },
      "source": [
        "this method was used for the segmentation algorithm, another method called augmentationImage is used to **generate a proper augmented dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXv1rojtjV1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "def pre_augmentation(img_path, preAug_path):\n",
        "  \"\"\" augment each image from the base dataset so that the segmentation algorithm\n",
        "  have to learn more robust features, to be able to accuratly extract newts in \n",
        "  low-quality images \"\"\"\n",
        "\n",
        "  path = Path(preAug_path)\n",
        "\n",
        "  !rm -rf /content/databaseAug\n",
        "\n",
        "  os.makedirs(preAug_path)\n",
        "  for img_name in os.listdir(img_path):\n",
        "    \n",
        "    imagePath = img_path + '/' + img_name\n",
        "\n",
        "    if os.path.isfile(imagePath):\n",
        "\n",
        "      image = img_as_float(io.imread(imagePath))\n",
        "      image = exposure.equalize_adapthist(image, clip_limit=0.03)\n",
        "      image = random_saturation(image, show_result=False)\n",
        "      image = random_brightness(image, show_result=False)\n",
        "      #print(np.max(image))\n",
        "      #print(np.min(image))\n",
        "      image = image*255\n",
        "      #plt.imshow(image)\n",
        "      #plt.show()\n",
        "      \n",
        "      shear = uniform(-.1, .1)\n",
        "      #print(shear)\n",
        "      tfr = AffineTransform(shear=shear)\n",
        "      sheared = transform.warp(image, tfr, order=1, preserve_range=True,mode='constant', cval=255)\n",
        "      #sheared_fig = plot_side_by_side(img, sheared, 'Original', 'Sheared')\n",
        "      #plt.title('shear')\n",
        "      #plt.imshow(sheared)\n",
        "      #v2_imshow(sheared)\n",
        "      #sheared = tf.keras.preprocessing.image.img_to_array(sheared)\n",
        "      #plt.imshow(sheared)\n",
        "  \n",
        "      strength = uniform(-1, 1)\n",
        "      #print(strength)\n",
        "      image = swirl(sheared, rotation=0, strength=strength, radius=500,mode='constant', cval=255)\n",
        "      #print(image.shape)\n",
        "      #image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) \n",
        "      #print(\"Augmentation par couleurs\")\n",
        "      \n",
        "      #image = tf.image.random_brightness(image, max_delta=0.10) # Random brightness\n",
        "      \n",
        "      \n",
        "      #image = tf.image.random_contrast(image,0.5,2)\n",
        "      \n",
        "      #image = tf.image.random_saturation(image,0.5,2)\n",
        "      #image = tf.image.random_flip_left_right(image)\n",
        "      #image = tf.image.random_flip_up_down(image)\n",
        "      #print(image.shape)\n",
        "      augPath = preAug_path + '/' + img_name\n",
        "      #print(np.max(image))\n",
        "      #print(np.min(image))\n",
        "      #plt.imshow(image.astype('uint8'))\n",
        "      #plt.show()\n",
        "\n",
        "      #image[:,:,0] = preprocessing.normalize(image[:,:,0])\n",
        "      #image[:,:,1] = preprocessing.normalize(image[:,:,1])\n",
        "      #image[:,:,2] = preprocessing.normalize(image[:,:,2])\n",
        "      \n",
        "      #image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "      #image = img_as_float(image)\n",
        "      #image = image/255\n",
        "      #image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "      #print(image)\n",
        "      plt.imsave(augPath, image/255)\n",
        "\n",
        "img_path = '/content/Stage_cropped/database'\n",
        "preAug_path = '/content/databaseAug'\n",
        "pre_augmentation(img_path, preAug_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FFQAx8Km7wx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "804579a0-06de-435c-c5da-c75fdd5e9884"
      },
      "source": [
        "\"\"\" Example of augmented image \"\"\"\n",
        "img_path = '/content/databaseAug/Bascha_P01_T01_K04_M_Adult_4246_20190330215714.jpg'\n",
        "img = plt.imread(img_path)\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_0VVfxKhUh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r /content/aug_database_for_seg.zip /content/databaseAug"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d-OuFDlgHgm",
        "colab_type": "text"
      },
      "source": [
        "new augmentation with mask rcnn output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd6FG3n4LLkG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "23f620a1-882d-48fa-b372-92409c154e33"
      },
      "source": [
        "\n",
        "def preprocess_mask_rcnn(image_path, input_shape):\n",
        "  \"\"\" apply all augmentation methods defined above on the image \"\"\"\n",
        "  #img = skimage.io.imread(image_path, plugin='matplotlib')\n",
        "  #image = img_as_float64(io.imread(image_path))\n",
        "  \n",
        "  #plt.imshow(image)\n",
        "\n",
        "  #print(np.max(image))\n",
        "  #image = tf.keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "  #image = image/255\n",
        "  #print(np.max(image))\n",
        "\n",
        "  image = img_as_float(io.imread(image_path))\n",
        "  #plt.imshow(image)\n",
        "  #plt.show()\n",
        "  image = exposure.equalize_adapthist(image, clip_limit=0.03)\n",
        "  #plt.imshow(image)\n",
        "  #plt.show()\n",
        "  image = random_saturation(image, show_result=False)\n",
        "  #plt.imshow(image)\n",
        "  #plt.show()\n",
        "  image = random_brightness(image, show_result=False)\n",
        "  #plt.imshow(image)\n",
        "  #plt.show()\n",
        "     \n",
        "      \n",
        "  image = image*255\n",
        "      #plt.imshow(image)\n",
        "      #plt.show()\n",
        "      \n",
        "  shear = uniform(-.1, .1)\n",
        "      #print(shear)\n",
        "  tfr = AffineTransform(shear=shear)\n",
        "  sheared = transform.warp(image, tfr, order=1, preserve_range=True,mode='constant', cval=255)\n",
        "  #plt.imshow(sheared/255)\n",
        "  #plt.show()\n",
        "      #sheared_fig = plot_side_by_side(img, sheared, 'Original', 'Sheared')\n",
        "      #plt.title('shear')\n",
        "      #plt.imshow(sheared)\n",
        "      #v2_imshow(sheared)\n",
        "      #sheared = tf.keras.preprocessing.image.img_to_array(sheared)\n",
        "      #plt.imshow(sheared)\n",
        "  \n",
        "  strength = uniform(-1, 1)\n",
        "      #print(strength)\n",
        "  image = swirl(sheared, rotation=0, strength=strength, radius=500,mode='constant', cval=255)\n",
        "  #plt.imshow(image/255)\n",
        "  #plt.show()\n",
        "      #print(image.shape)\n",
        "\n",
        "  \n",
        "  #print(np.max(image))\n",
        "  #print(np.min(image))\n",
        "  #plt.imshow(image)\n",
        "  #plt.show()\n",
        "  \n",
        "  #img = plt.imread(image_path)\n",
        "  #img = tf.convert_to_tensor(img)\n",
        "  #plt.imshow(img)\n",
        "  ### Add borders around the image to have more room for wraping and swirling\n",
        " # h,w=img.shape[0:2]\n",
        "  #shift = 20\n",
        "  #base_size=h+2*shift,w+2*shift,3\n",
        "# make a 3 channel image for base which is slightly larger than target img\n",
        "  #base=np.zeros(base_size)\n",
        "  #cv2.rectangle(base,(0,0),(w+2*shift,h+2*shift),(255,255,255),40) # really thick white rectangle\n",
        "  #base[shift:h+shift,shift:w+shift]=img # this works\n",
        "  #img = base\n",
        "  #print(img)\n",
        "  #cv2_imshow(img)\n",
        "\n",
        "  #h,w=img.shape[0:2]\n",
        "\n",
        "\n",
        "  #print(np.max(image))\n",
        "  #image = image/255\n",
        "  #print(np.max(image))\n",
        "### image swirling using sklearn swirl\n",
        "# keep strength  between -1 and 1\n",
        "# maximum radius = 500\n",
        "# mode = constant because in case of \"wrap\" some parts of the newts go the other sides of the image. Bad for the training of the neural network\n",
        "  \n",
        "  #print(image)\n",
        "  \n",
        "  #plt.imshow(image)\n",
        "  #plt.show()\n",
        "\n",
        "  #white = np.array([1, 1, 1])\n",
        "  #mask = np.abs(image - white).sum(axis=2) < 0.05\n",
        "  \n",
        "  # Find the bounding box of those pixels\n",
        "  #coords = np.array(np.nonzero(~mask))\n",
        "  #top_left = np.min(coords, axis=1)\n",
        "  #print(top_left)\n",
        "  #bottom_right = np.max(coords, axis=1)\n",
        "  #print(bottom_right)\n",
        "\n",
        "  #image = image[top_left[0]:bottom_right[0],\n",
        "           #top_left[1]:bottom_right[1]]\n",
        "  #print(np.max(image))\n",
        "  #print(np.min(image))\n",
        "  #plt.imshow(image)\n",
        "  #plt.show()\n",
        "  #print(\"Augmentation par couleurs\")\n",
        "  #swirled[swirled != 255]\n",
        "  \n",
        "  #newt = tf.image.random_brightness(newt, max_delta=0.10) # Random brightness\n",
        "  #image = tf.image.random_flip_left_right(newt)\n",
        "  #image = tf.image.random_flip_up_down(image)\n",
        "  #image = tf.image.random_contrast(image,0.5,2)\n",
        "  #image = tf.image.random_saturation(image,0.5,2)\n",
        "\n",
        "  \n",
        "    #print(\"height > width\")\n",
        "    #print(\"height > width\")\n",
        "  #plt.imshow(image/255)\n",
        "  #print(image.shape)\n",
        "  #plt.imshow(tf.keras.preprocessing.image.img_to_array(image))\n",
        "  #print(type(image.))\n",
        "  #print(image)\n",
        "  \n",
        "\n",
        "  #plt.imshow(out)\n",
        "  #plt.show()\n",
        "  #augPath = '/content/augDatabase/test.jpg'\n",
        "  #image = image.astype(np.uint8)\n",
        "  #skimage.io.imsave(augPath, image)\n",
        "\n",
        "  return image\n",
        "\n",
        "input_shape = (56,56,3)\n",
        "img_path = '/content/Stage_cropped/database/Bascha_P01_T01_K03_F_Adult_4413_20190321004956.jpg'\n",
        "img = preprocess_mask_rcnn(img_path, input_shape)\n",
        "plt.imshow(img/255)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsvKhAwzSPx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape = (75,30,3)\n",
        "\n",
        "\n",
        "def augmentationImage(img_path,img_aug_path, input_shape):\n",
        "\n",
        "  \"\"\" Create a proper dataset where each folder contains the images of one \n",
        "  specimen, randomly augmented 20 times for each \"real\" image present in the \n",
        "  original dataset \"\"\"\n",
        "\n",
        "  !rm -rf /content/databaseAug #useful when running the method again for makedirs\n",
        "  data = pd.read_csv('/content/Stage_Tritons/training.csv')\n",
        "  #data = data.to_numpy()\n",
        "  labels = data.iloc[:,4]\n",
        "  #print(labels.head())\n",
        "  names = data.iloc[:,0]\n",
        "  #print(names.head())\n",
        "  #abels.head()\n",
        "  labels_uniques, counts = np.unique(labels, return_counts=True)\n",
        "  \n",
        "  #print(labels_uniques)\n",
        "  for label in labels_uniques:\n",
        "    os.makedirs(img_aug_path+'/train/'+label)\n",
        "    os.makedirs(img_aug_path+'/test/'+label)\n",
        "\n",
        "\n",
        "  print(\"Création de la base de données augmentées en cours...\")\n",
        "  # List all files in a directory using scandir()\n",
        "  basepath = img_path\n",
        "  with os.scandir(basepath) as images:\n",
        "    for im in images:\n",
        "      #print(im.name)\n",
        "      if(im.name in names.values):\n",
        "        \n",
        "        id = names[names == im.name].index[0]\n",
        "        #id = names.loc[im.name]\n",
        "        #print(id)\n",
        "        label = labels.iloc[id]\n",
        "        #print('label : '+label)\n",
        "        id_label = np.where(labels_uniques == label)\n",
        "        #print(id_label)\n",
        "        imagePath = basepath + '/' + im.name\n",
        "        #print(imagePath)\n",
        "        #print(imagePath)\n",
        "        count = counts[id_label]\n",
        "        #print(count)\n",
        "        #img_path = '/content/database/Bascha_P01_T01_K14_M_Adult_1024_20190605213228.jpg'\n",
        "        #img = prepare_img(input_shape,imagePath)\n",
        "        #image = cv2_imread(path + '/' + im.name)\n",
        "        \n",
        "        \n",
        "        k = 0\n",
        "        while (k < 20):  ######### DIVISER PAR COUNT QUAND BASE DE DONNEE COMPLETE\n",
        "          image = preprocess_mask_rcnn(imagePath, input_shape)\n",
        "          #image = tf.image.random_brightness(image, max_delta=0.15) # Random brightness\n",
        "          #image = tf.image.random_flip_left_right(image)\n",
        "          #image = tf.image.random_flip_up_down(image)\n",
        "          #image = tf.image.random_contrast(image,0.5,3)\n",
        "          #image = tf.image.random_saturation(image,0.5,3)\n",
        "          \n",
        "         \n",
        "          augPath = img_aug_path+'/train/'+label+'/' + im.name[:-4] + str(k) + '.jpg'\n",
        "          #augPath = img_aug_path+'/test/'+label+'/' + im.name + str(k)\n",
        "          #save_img(augPath, image)\n",
        "          image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "          #image = image*255\n",
        "          #cv2.imwrite(augPath,image)\n",
        "          #print(image.shape)\n",
        "          #plt.imshow(image/255)\n",
        "          #plt.show()\n",
        "          #skimage.io.imsave(augPath,image.astype('uint8'))\n",
        "          plt.imsave(augPath, image/255)\n",
        "          k += 1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEuHEmOhiIIe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "edd40b74-7c62-47db-cc06-19e507c8f2bd"
      },
      "source": [
        "img_path = '/content/Stage_cropped/database'\n",
        "img_aug_path = '/content/databaseAug'\n",
        "augmentationImage(img_path,img_aug_path,input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-2EsJ7SFgvKM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "41d74b1a-ba92-498a-be1f-c1cbf5b1911d"
      },
      "source": [
        "\"\"\" Train/Test split \"\"\"\n",
        "\n",
        "train_path = '/content/databaseAug/train'\n",
        "test_path = '/content/databaseAug/test'\n",
        "dest1 =  pathlib.Path(test_path)\n",
        "source1 = pathlib.Path(train_path)\n",
        "\n",
        "for label in os.listdir(train_path):\n",
        "  if len(os.listdir(train_path + '/' + label)) == 0: # Check if empty..\n",
        "    shutil.rmtree(train_path + '/' + label) # Delete..\n",
        "\n",
        "import fnmatch\n",
        "\n",
        "\n",
        "\n",
        "for class_name in os.listdir(train_path):\n",
        "      \n",
        "\n",
        "      class_path = os.path.join(source1, class_name)\n",
        "      class_path_test = os.path.join(dest1, class_name)\n",
        "      #os.mkdir(class_path_test)\n",
        "      #label_map_dict[class_name]=count_label\n",
        "      imgs = fnmatch.filter(os.listdir(class_path), '*.jpg')\n",
        "      nbr_img = len(imgs)\n",
        "\n",
        "      idx = np.arange(nbr_img)\n",
        "      idx_test = np.random.choice(idx, size=10, replace=False)\n",
        "      print(len(os.listdir(class_path)))\n",
        "\n",
        "      #Copie de certains éléments dans le test set\n",
        "      for i in range (len(os.listdir(class_path))):\n",
        "        if i in idx_test:\n",
        "          print(str(class_path) + '/'+ str(os.listdir(class_path)[i]))\n",
        "          shutil.copy(str(class_path) + '/'+ str(os.listdir(class_path)[i]), str(class_path_test) + '/'+ str(os.listdir(class_path)[i]))\n",
        "      #Suppression des éléments copiés dans le train set\n",
        "      files = os.listdir(class_path)\n",
        "      for i in range (len(files)):\n",
        "        if i in idx_test:\n",
        "          print(str(class_path) + '/'+ str(files[i]))\n",
        "          file_path = pathlib.Path(str(class_path) + '/'+ str(files[i]))\n",
        "          os.remove(file_path)\n",
        "          #print(\"removed\")\n",
        "\n",
        "\n",
        "for label in os.listdir(test_path):\n",
        "  if len(os.listdir(test_path + '/' + label)) == 0: # Check if empty..\n",
        "    shutil.rmtree(test_path + '/' + label) # Delete.."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9sNkmpyGzyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r /content/databaseAug.zip /content/databaseAug"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6X-pUx5rssZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "755b81c9-48d3-4dbe-e334-7707917114df"
      },
      "source": [
        "\"\"\" Here is an example of an augmented image of a newt from the dataset\n",
        "generated by augmentationImage \"\"\"\n",
        "\n",
        "img_path = '/content/databaseAug/test/KM00029/Bascha_P01_T02_K05_F_Adult_4675_2019031619421416.jpg'\n",
        "img = plt.imread(img_path)\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTGIukOSQonj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def apply_mask(image, mask):\n",
        "    \"\"\"Apply mask on image. Pixels outside of the mask are turned white.\n",
        "    image: RGB image [height, width, 3]\n",
        "    mask: instance segmentation mask [height, width, instance count]\n",
        "    Returns result image.\n",
        "    \"\"\"\n",
        "    # Make a grayscale copy of the image. The grayscale copy still\n",
        "    # has 3 RGB channels, though.\n",
        "    gray = skimage.color.gray2rgb(skimage.color.rgb2gray(image)) * 255\n",
        "    # Copy color pixels from the original color image where mask is set\n",
        "    if mask.shape[-1] > 0:\n",
        "        # We're treating all instances as one, so collapse the mask into one layer\n",
        "        mask = (np.sum(mask, -1, keepdims=True) >= 1)\n",
        "        splash = np.where(mask, image, gray).astype(np.uint8)\n",
        "    else:\n",
        "        splash = gray.astype(np.uint8)\n",
        "    return splash"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1Ci-q3RfCsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_crop(ds_types_path, ds_final_path, input_shape):\n",
        "  \"\"\" take the proper dataset created by augmentationImage and extract the newts\n",
        "  by segmenting and cropping \"\"\"\n",
        "   \n",
        "  !rm -rf /content/ds_final\n",
        "\n",
        "  for ds_type in os.listdir(ds_types_path):\n",
        "    \n",
        "    print(ds_type)\n",
        "    ds_path = ds_types_path + '/' + ds_type\n",
        "    final_path = ds_final_path + '/' + ds_type\n",
        "\n",
        "    \n",
        "\n",
        "    for class_name in os.listdir(ds_path):\n",
        "      \n",
        "      #print(class_name)\n",
        "      dsPath = ds_path + '/' + class_name\n",
        "      #print(dsPath)\n",
        "      dsFinalPath = final_path + '/' + class_name\n",
        "\n",
        "      for img_name in os.listdir(dsPath):\n",
        "\n",
        "        #if os.path.isfile(img_name):\n",
        "        \n",
        "          print(img_name)\n",
        "          imagePath = dsPath + '/' + img_name\n",
        "          augPath = dsFinalPath + '/' + img_name\n",
        "          if not (os.path.isdir(dsFinalPath)):\n",
        "            os.makedirs(dsFinalPath)\n",
        "          \n",
        "          image = extract_image(imagePath)\n",
        "          #plt.imshow(image)\n",
        "          #plt.show()\n",
        "\n",
        "          height = input_shape[0]\n",
        "          width = input_shape[1]\n",
        "          #print(np.max(image))\n",
        "          #print(np.min(image))\n",
        "  \n",
        "          if (image.shape[0] < image.shape[1]):\n",
        "            #image = tf.image.resize(image, [width, height])\n",
        "            image = resize(image, (width, height),\n",
        "                       anti_aliasing=False)\n",
        "            #print(\"height < width\")\n",
        "            image = np.transpose(image,(1,0,2))\n",
        "          else:\n",
        "            #image = tf.image.resize(image, [height, width])\n",
        "            image = resize(image, (height, width),\n",
        "                       anti_aliasing=False)\n",
        "        \n",
        "          #image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "         \n",
        "          #plt.imshow(image)\n",
        "          #plt.show()\n",
        "          plt.imsave(augPath, image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJa1Al8hfa66",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dbc095af-1acf-42fc-83c3-0872369462c5"
      },
      "source": [
        "input_shape = (75,30,3)\n",
        "img_aug_path = '/content/databaseAug'\n",
        "img_final_path = '/content/ds_final'\n",
        "extract_crop(img_aug_path, img_final_path, input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpPN379xGEmn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "348c5537-1382-4081-9cdc-c01bd74d5010"
      },
      "source": [
        "\"\"\" here is an example of a pattern extracted, read from the dataset generated\n",
        "by extract_crop \"\"\"\n",
        "\n",
        "img_path = '/content/ds_final/test/KM00088/Bascha_P01_T03_K15_M_Adult_1247_2019061410444712.jpg'\n",
        "img = plt.imread(img_path)\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrsXV1SBy-50",
        "colab_type": "text"
      },
      "source": [
        "# All preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcRpxbQGzDRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def random_saturation(rgb, show_result = False):\n",
        "  \"\"\" Modify randomly the saturation of the input image \"\"\"\n",
        "  hsv = skimage.color.rgb2hsv(rgb)\n",
        "\n",
        "  #plt.imshow(hsv)\n",
        "  saturation = uniform(-0.35, 0.35)\n",
        "  \n",
        "  #print(hsv[:,:,1])\n",
        "  hsv[:,:,1] = hsv[:,:,1] + saturation\n",
        "  #print(np.max(lab[:,:,0]))\n",
        "  #print(hsv[:,:,1])\n",
        "  rgb = skimage.color.hsv2rgb(hsv)\n",
        "\n",
        "  if show_result:\n",
        "    plt.imshow(rgb)\n",
        "    plt.show()\n",
        "\n",
        "  return rgb\n",
        "\n",
        "def random_brightness(rgb, show_result = False):\n",
        "  \"\"\" Modify randomly the brightness of the input image \"\"\"\n",
        "  lab = skimage.color.rgb2lab(rgb)\n",
        "\n",
        "  #plt.imshow(lab)\n",
        "  brightness = uniform(-20, 20)\n",
        "  \n",
        "  #print(lab[:,:,0])\n",
        "  lab[:,:,0] = lab[:,:,0] + brightness\n",
        "  #print(np.max(lab[:,:,0]))\n",
        "  #print(lab[:,:,0])\n",
        "  rgb = skimage.color.lab2rgb(lab)\n",
        "  if show_result:\n",
        "    plt.imshow(rgb)\n",
        "    plt.show()\n",
        "\n",
        "  return rgb\n",
        "\n",
        "def preprocess_images(image_path):\n",
        "  \"\"\" apply all augmentation methods defined above on the image \"\"\"\n",
        "\n",
        "  image = img_as_float(io.imread(image_path))\n",
        "  image = exposure.equalize_adapthist(image, clip_limit=0.03)\n",
        "  image = random_saturation(image, show_result=False)\n",
        "  image = random_brightness(image, show_result=False)\n",
        "     \n",
        "      \n",
        "  image = image*255\n",
        "      \n",
        "  shear = uniform(-.1, .1)\n",
        "  tfr = AffineTransform(shear=shear)\n",
        "  sheared = transform.warp(image, tfr, order=1, preserve_range=True,mode='constant', cval=255)\n",
        "  \n",
        "  strength = uniform(-1, 1)\n",
        "  image = swirl(sheared, rotation=0, strength=strength, radius=500,mode='constant', cval=255)\n",
        "\n",
        "\n",
        "  return image\n",
        "\n",
        "def augmentationImageUnet(img_path,img_aug_path, input_shape):\n",
        "\n",
        "  \"\"\" Create a proper dataset where each folder contains the images of one \n",
        "  specimen, randomly augmented 20 times for each \"real\" image present in the \n",
        "  original dataset \"\"\"\n",
        "\n",
        "  !rm -rf /content/augDataset #useful when running the method again for makedirs\n",
        "  data = pd.read_csv('/content/Stage_Tritons/training.csv')\n",
        "\n",
        "  labels = data.iloc[:,4]\n",
        "\n",
        "  names = data.iloc[:,0]\n",
        "\n",
        "  labels_uniques, counts = np.unique(labels, return_counts=True)\n",
        "  \n",
        "\n",
        "  for label in labels_uniques:\n",
        "    if (not os.path.isdir(img_aug_path + '/' + str(label))):\n",
        "      os.makedirs(img_aug_path+'/'+label)\n",
        "\n",
        "  nbr_classes = 0\n",
        "  print(\"Création de la base de données augmentées en cours...\")\n",
        "  # List all files in a directory using scandir()\n",
        "  basepath = img_path\n",
        "  #nb_max = 50\n",
        "  with os.scandir(basepath) as images:\n",
        "    for im in images:\n",
        "\n",
        "      if(im.name in names.values and nbr_classes < 50):\n",
        "        \n",
        "        id = names[names == im.name].index[0]\n",
        "  \n",
        "        label = labels.iloc[id]\n",
        "\n",
        "        id_label = np.where(labels_uniques == label)\n",
        "\n",
        "        imagePath = basepath + '/' + im.name\n",
        "\n",
        "        count = counts[id_label]\n",
        "\n",
        "        augPath = img_aug_path+'/'+label+'/' + im.name[:-4]\n",
        "        \n",
        "\n",
        "        k = len(os.listdir(img_aug_path+'/'+label))\n",
        "        while (k < 1000):  \n",
        "          image = preprocess_images(imagePath)\n",
        "          \n",
        "          augPath = img_aug_path+'/'+label+'/' + im.name[:-4] + str(k) + '.jpg'\n",
        "          image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "          plt.imsave(augPath, image/255)\n",
        "          k += 1\n",
        "        \n",
        "        nbr_classes += 1\n",
        "\n",
        "def get_label_csv(file_path):\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "\n",
        "  name = parts[-1]\n",
        "\n",
        "  id = names[names == name].index[0]\n",
        "  \n",
        "  label = labels.iloc[id]\n",
        "\n",
        "  return label == CLASS_NAMES\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_mask(pred_mask):\n",
        "  pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "  pred_mask = pred_mask[..., tf.newaxis]\n",
        "  \n",
        "\n",
        "  #pred_mask = area_closing(pred_mask, area_threshold=4, connectivity=1, parent=None, tree_traverser=None)tf.keras.preprocessing.image.img_to_array\n",
        "\n",
        "  return pred_mask[0]\n",
        "\n",
        "def extract_image_unet(img_path, model):\n",
        "  \"\"\" method used to extract the greatest region in the mask output of the \n",
        "  Unet. \n",
        "  \"\"\"\n",
        "  image = plt.imread(img_path)\n",
        "  image = resize(image, (128,128,3), preserve_range=True)\n",
        "  pred_mask = create_mask(model.predict(image[tf.newaxis, ...]/255))\n",
        "  image = resize(image, (200,50,3), preserve_range=True)\n",
        "    \n",
        "  pred_mask = tf.keras.preprocessing.image.img_to_array(pred_mask)\n",
        "\n",
        "   \n",
        "  selem = skimage.morphology.disk(6)\n",
        "  pred_mask = closing(np.squeeze(pred_mask*255), selem)\n",
        "  pred_mask = opening(np.squeeze(pred_mask), selem)\n",
        "\n",
        "  pred_mask = resize(pred_mask, (200,50, 1), preserve_range=True)\n",
        "  \n",
        "\n",
        "  try:\n",
        "    labels_mask = measure.label(pred_mask) \n",
        "  except ValueError:  #raised if `y` is empty.\n",
        "    print('no region found.')\n",
        "    return image\n",
        "   \n",
        "\n",
        "  try:\n",
        "    regions = measure.regionprops(labels_mask)\n",
        "  except ValueError:  #raised if `y` is empty.\n",
        "    print(\"no region found.\")\n",
        "    return image\n",
        "  regions.sort(key=lambda x: x.area, reverse=True)\n",
        "\n",
        "  if len(regions) > 1:\n",
        "    for rg in regions[1:]:\n",
        "        labels_mask[rg.coords[:,0], rg.coords[:,1]] = 0\n",
        "\n",
        "\n",
        "  labels_mask[labels_mask!=0] = 1\n",
        "  mask = labels_mask\n",
        "\n",
        "  \n",
        "\n",
        "  skeleton = skeletonize(rescale_intensity(tf.keras.preprocessing.image.img_to_array(mask),in_range=(-1,1)))\n",
        "\n",
        "\n",
        "  if mask.shape[-1] > 0:\n",
        "    # We're treating all instances as one, so collapse the mask into one layer\n",
        "    mask = (np.sum(mask, -1, keepdims=True) >= 1)\n",
        "    img_extracted = np.where(mask, image, 255).astype(np.uint8)\n",
        "    image = img_extracted/255\n",
        "\n",
        "\n",
        "  skeleton = np.where(np.squeeze(skeleton) > 0)\n",
        "  skeleton = np.array(skeleton)\n",
        "\n",
        "  a = skeleton[0]\n",
        "  b = skeleton[1]\n",
        " \n",
        "  s = pd.Series(np.squeeze(a))\n",
        "  #print(s.values)\n",
        "  #print(s[s.duplicated()].index)\n",
        "  duplicates = s[s.duplicated()].index\n",
        " \n",
        "  #duplicate = 0\n",
        "  skel_size = skeleton[0].shape[0]\n",
        "  \n",
        "  shifts = []\n",
        "  center = int(pred_mask.shape[1]/2)\n",
        "  i = 0\n",
        "  dups = []\n",
        "  while (i < skel_size):\n",
        "  \n",
        "\n",
        "    if (i in duplicates and not i in dups):\n",
        "     \n",
        "      dups.append(i)\n",
        "      \n",
        "      d = skeleton[1][skeleton[0] == s[i]]\n",
        "     \n",
        "      mid = int(np.mean(d))\n",
        "    \n",
        "      \n",
        "   \n",
        "      diff = mid-center\n",
        "      shifts[-1] = -diff\n",
        "    \n",
        "      i += 1\n",
        "      \n",
        "    elif (i in duplicates and i in dups):\n",
        "      continue\n",
        "    else:\n",
        "      diff = skeleton[1][i]-center\n",
        "      \n",
        "      shifts.append(-diff)\n",
        "      i += 1\n",
        "  \n",
        "  \n",
        "  k = 0\n",
        "  img = image.copy()\n",
        "\n",
        "  for diff in shifts:\n",
        "    \n",
        "    image[s.unique()[k],:,0] = shift(image[s.unique()[k],:,0], diff , output=None, order=3, mode='wrap', prefilter=False)\n",
        "    image[s.unique()[k],:,1] = shift(image[s.unique()[k],:,1], diff , output=None, order=3, mode='wrap', prefilter=False)\n",
        "    image[s.unique()[k],:,2] = shift(image[s.unique()[k],:,2], diff , output=None, order=3, mode='wrap', prefilter=False)\n",
        "    \n",
        "    k += 1\n",
        "\n",
        "\n",
        "  for i in range (image.shape[0]):\n",
        "    if (not i in skeleton[0]):\n",
        "      image[i,:] = 1\n",
        "\n",
        "  white = np.array([1, 1, 1])\n",
        "  mask = np.abs(image - white).sum(axis=2) < 0.05\n",
        "\n",
        "  # Find the bounding box of those pixels\n",
        "  try:\n",
        "    coords = np.array(np.nonzero(~mask))\n",
        "    top_left = np.min(coords, axis=1)\n",
        "    bottom_right = np.max(coords, axis=1)\n",
        "  \n",
        "    out = image[top_left[0]:bottom_right[0],\n",
        "            top_left[1]:bottom_right[1]]\n",
        "    \n",
        "  except:\n",
        "    return None\n",
        "  \n",
        "  return out\n",
        "\n",
        "\n",
        "def extract_crop(ds_path, ds_final_path, input_shape, model):\n",
        "  \"\"\" take the proper dataset created by augmentationImages and extract the newts\n",
        "  by segmenting and cropping the pattern of interest \"\"\"\n",
        "   \n",
        "  #!rm -rf /content/ds_final\n",
        "\n",
        "    \n",
        "\n",
        "  for class_name in os.listdir(ds_path):\n",
        "      \n",
        "      #print(class_name)\n",
        "      dsPath = ds_path + '/' + class_name\n",
        "      #print(dsPath)\n",
        "      dsFinalPath = ds_final_path + '/' + class_name\n",
        "\n",
        "      for img_name in os.listdir(dsPath):\n",
        "\n",
        "        #if os.path.isfile(img_name):\n",
        "        \n",
        "          #print(img_name)\n",
        "          imagePath = dsPath + '/' + img_name\n",
        "          print(imagePath)\n",
        "          augPath = dsFinalPath + '/' + img_name\n",
        "          if not (os.path.isdir(dsFinalPath)):\n",
        "            os.makedirs(dsFinalPath)\n",
        "          \n",
        "          image = extract_image_unet(imagePath, model)\n",
        "          try:\n",
        "          #plt.imshow(image)\n",
        "          #plt.show()\n",
        "\n",
        "            height = input_shape[0]\n",
        "            width = input_shape[1]\n",
        "          #print(np.max(image))\n",
        "          #print(np.min(image))\n",
        "  \n",
        "            if (image.shape[0] < image.shape[1]):\n",
        "            #image = tf.image.resize(image, [width, height])\n",
        "              image = resize(image, (width, height),\n",
        "                       anti_aliasing=False)\n",
        "            #print(\"height < width\")\n",
        "              image = np.transpose(image,(1,0,2))\n",
        "            else:\n",
        "            #image = tf.image.resize(image, [height, width])\n",
        "              image = resize(image, (height, width),\n",
        "                       anti_aliasing=False)\n",
        "        \n",
        "          #image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "         \n",
        "          #plt.imshow(image)\n",
        "          #plt.show()\n",
        "            plt.imsave(augPath, image)\n",
        "          \n",
        "          except:\n",
        "            pass  \n",
        "\n",
        "\n",
        "\n",
        "def preprocess_newts(dataset_path, img_aug_path, final_path, input_shape):\n",
        "  \"\"\" take as input a folder of images, augment the images,\n",
        "      extract the pattern of the newts, and straighten them automatically.\n",
        "      Create the resulting dataset \"\"\"\n",
        "  #Handle the augmentations for each image\n",
        "  augmentationImageUnet(dataset_path, img_aug_path, input_shape)\n",
        "  #Handle the pattern extraction and the straightening\n",
        "  Unet = tf.keras.models.load_model('/content/saved_model/my_model')\n",
        "  extract_crop(img_aug_path, final_path, input_shape, Unet)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v12oMNZXpx8y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "21b168e1-38ed-41eb-dcc3-e5cb20937ce8"
      },
      "source": [
        "\n",
        "def random_saturation(rgb, show_result = False):\n",
        "  \"\"\" Modify randomly the saturation of the input image \"\"\"\n",
        "  hsv = skimage.color.rgb2hsv(rgb)\n",
        "\n",
        "  #plt.imshow(hsv)\n",
        "  saturation = uniform(-0.35, 0.35)\n",
        "  \n",
        "  #print(hsv[:,:,1])\n",
        "  hsv[:,:,1] = hsv[:,:,1] + saturation\n",
        "  #print(np.max(lab[:,:,0]))\n",
        "  #print(hsv[:,:,1])\n",
        "  rgb = skimage.color.hsv2rgb(hsv)\n",
        "\n",
        "  if show_result:\n",
        "    plt.imshow(rgb)\n",
        "    plt.show()\n",
        "\n",
        "  return rgb\n",
        "\n",
        "def random_brightness(rgb, show_result = False):\n",
        "  \"\"\" Modify randomly the brightness of the input image \"\"\"\n",
        "  lab = skimage.color.rgb2lab(rgb)\n",
        "\n",
        "  #plt.imshow(lab)\n",
        "  brightness = uniform(-20, 20)\n",
        "  \n",
        "  #print(lab[:,:,0])\n",
        "  lab[:,:,0] = lab[:,:,0] + brightness\n",
        "  #print(np.max(lab[:,:,0]))\n",
        "  #print(lab[:,:,0])\n",
        "  rgb = skimage.color.lab2rgb(lab)\n",
        "  if show_result:\n",
        "    plt.imshow(rgb)\n",
        "    plt.show()\n",
        "\n",
        "  return rgb\n",
        "\n",
        "def preprocess_images(image_path):\n",
        "  \"\"\" apply all augmentation methods defined above on the image \"\"\"\n",
        "\n",
        "  image = img_as_float(io.imread(image_path))\n",
        "  image = exposure.equalize_adapthist(image, clip_limit=0.03)\n",
        "  image = random_saturation(image, show_result=False)\n",
        "  image = random_brightness(image, show_result=False)\n",
        "     \n",
        "      \n",
        "  image = image*255\n",
        "      \n",
        "  shear = uniform(-.1, .1)\n",
        "  tfr = AffineTransform(shear=shear)\n",
        "  sheared = transform.warp(image, tfr, order=1, preserve_range=True,mode='constant', cval=255)\n",
        "  \n",
        "  strength = uniform(-1, 1)\n",
        "  image = swirl(sheared, rotation=0, strength=strength, radius=500,mode='constant', cval=255)\n",
        "\n",
        "\n",
        "  return image\n",
        "\n",
        "\n",
        "def augmentationImages(img_path,img_aug_path):\n",
        "\n",
        "  \"\"\" Create a proper dataset where each folder contains the images of one \n",
        "  specimen, randomly augmented 20 times for each \"real\" image present in the \n",
        "  original dataset \"\"\"\n",
        "\n",
        "  #!rm -rf /content/databaseAug #useful when running the method again for makedirs\n",
        "\n",
        "  img_list = os.listdir(img_path)\n",
        "\n",
        "  for img_name in img_list:\n",
        "      os.makedirs(img_aug_path + '/' + str(img_name[:-4]))\n",
        "\n",
        "\n",
        "  print(\"Creating the augmented dataset...\")\n",
        "  # List all files in a directory using scandir()\n",
        "  basepath = img_path\n",
        "  with os.scandir(basepath) as images:\n",
        "    for im in images:\n",
        "\n",
        "        imagePath = basepath + '/' + im.name\n",
        "        print(imagePath)\n",
        "        k = 0\n",
        "\n",
        "        while (k < 20):  \n",
        "          image = preprocess_images(imagePath)\n",
        "          \n",
        "          augPath = img_aug_path+'/'+ im.name[:-4] +'/' + im.name[:-4] + str(k) + '.jpg'\n",
        "          image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "          plt.imsave(augPath, image/255)\n",
        "          k += 1\n",
        "\n",
        "img_path = '/content/new_picture_for_database'\n",
        "aug_path = 'augDatasetNew'\n",
        "augmentationImages(img_path,aug_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaRuWjD-0TXF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d3a61126-75ec-4ad7-97ab-253b73c411a3"
      },
      "source": [
        "!zip -r /content/drive/\"My Drive\"/Stage/lite_ds/augDatasetNew.zip /content/augDatasetNew"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeYKWAhr4177",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model, save_model\n",
        "\n",
        "#unet = load_model('my_model_Unet')\n",
        "img_path = '/content/Stage_cropped/database'\n",
        "aug_path = 'augDataset'\n",
        "final_path = 'finalDataset'\n",
        "input_shape = (75,30,3)\n",
        "\n",
        "preprocess_newts(img_path, aug_path, final_path, input_shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxs5x2o3FZTb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ac732f54-c45f-485f-e222-38b3f16cae6d"
      },
      "source": [
        "!zip -r /content/drive/\"My Drive\"/Stage/lite_ds/self_supervised_dataset_50.zip /content/finalDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQT36Y9ku3Ou",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fb4db8d9-672b-45cc-d77a-b2dae2e05929"
      },
      "source": [
        "train_path = '/content/content/finalDataset'\n",
        "dest_path = '/content/newtDataset/train'\n",
        "os.mkdir('newtDataset')\n",
        "os.mkdir('newtDataset/train')\n",
        "\n",
        "dest1 =  pathlib.Path('newtDataset/train')\n",
        "source1 = pathlib.Path(train_path)\n",
        "\n",
        "#os.mkdir('finalDataset/train')\n",
        "\n",
        "for label in os.listdir(train_path):\n",
        "  os.mkdir('newtDataset/train' + '/' +  str(label))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for class_name in os.listdir(train_path):\n",
        "      \n",
        "\n",
        "      class_path = os.path.join(source1, class_name)\n",
        "      class_path_test = os.path.join(dest1, class_name)\n",
        "      #os.mkdir(class_path_test)\n",
        "      #label_map_dict[class_name]=count_label\n",
        "      imgs = fnmatch.filter(os.listdir(class_path), '*.jpg')\n",
        "      nbr_img = len(imgs)\n",
        "\n",
        "      idx = np.arange(nbr_img)\n",
        "      idx_test = np.random.choice(idx, size=nbr_img, replace=False)\n",
        "      print(len(os.listdir(class_path)))\n",
        "\n",
        "      #Copie de certains éléments dans le test set\n",
        "      for i in range (len(os.listdir(class_path))):\n",
        "        if i in idx_test:\n",
        "          print(str(class_path) + '/'+ str(os.listdir(class_path)[i]))\n",
        "          shutil.copy(str(class_path) + '/'+ str(os.listdir(class_path)[i]), str(class_path_test) + '/'+ str(os.listdir(class_path)[i]))\n",
        "      #Suppression des éléments copiés dans le train set\n",
        "      files = os.listdir(class_path)\n",
        "      for i in range (len(files)):\n",
        "        if i in idx_test:\n",
        "          print(str(class_path) + '/'+ str(files[i]))\n",
        "          file_path = pathlib.Path(str(class_path) + '/'+ str(files[i]))\n",
        "          os.remove(file_path)\n",
        "          #print(\"removed\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaOShkUGtQ4P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3679c131-dfa3-44eb-f5ee-0ff68d4d5996"
      },
      "source": [
        "\"\"\" Train/Test split \"\"\"\n",
        "\n",
        "train_path = '/content/newtDataset/train'\n",
        "test_path = '/content/newtDataset/test'\n",
        "os.mkdir(test_path)\n",
        "dest1 =  pathlib.Path(test_path)\n",
        "source1 = pathlib.Path(train_path)\n",
        "\n",
        "for label in os.listdir(train_path):\n",
        "  if len(os.listdir(train_path + '/' + label)) == 0: # Check if empty..\n",
        "    shutil.rmtree(train_path + '/' + label) # Delete..\n",
        "  else:\n",
        "    os.mkdir(test_path + '/' + label)\n",
        "import fnmatch\n",
        "\n",
        "\n",
        "\n",
        "for class_name in os.listdir(train_path):\n",
        "      \n",
        "\n",
        "      class_path = os.path.join(source1, class_name)\n",
        "      class_path_test = os.path.join(dest1, class_name)\n",
        "      #os.mkdir(class_path_test)\n",
        "      #label_map_dict[class_name]=count_label\n",
        "      imgs = fnmatch.filter(os.listdir(class_path), '*.jpg')\n",
        "      nbr_img = len(imgs)\n",
        "\n",
        "      idx = np.arange(nbr_img)\n",
        "      idx_test = np.random.choice(idx, size=100, replace=False)\n",
        "      print(len(os.listdir(class_path)))\n",
        "\n",
        "      #Copie de certains éléments dans le test set\n",
        "      for i in range (len(os.listdir(class_path))):\n",
        "        if i in idx_test:\n",
        "          print(str(class_path) + '/'+ str(os.listdir(class_path)[i]))\n",
        "          shutil.copy(str(class_path) + '/'+ str(os.listdir(class_path)[i]), str(class_path_test) + '/'+ str(os.listdir(class_path)[i]))\n",
        "      #Suppression des éléments copiés dans le train set\n",
        "      files = os.listdir(class_path)\n",
        "      for i in range (len(files)):\n",
        "        if i in idx_test:\n",
        "          print(str(class_path) + '/'+ str(files[i]))\n",
        "          file_path = pathlib.Path(str(class_path) + '/'+ str(files[i]))\n",
        "          os.remove(file_path)\n",
        "          #print(\"removed\")\n",
        "\n",
        "\n",
        "for label in os.listdir(test_path):\n",
        "  if len(os.listdir(test_path + '/' + label)) == 0: # Check if empty..\n",
        "    shutil.rmtree(test_path + '/' + label) # Delete.."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEu-SaP3z3p4",
        "colab_type": "text"
      },
      "source": [
        "# Old augmentation with color segmentation, canny contours, and rectangle extraction. (do not run)\n",
        "Issue : segmentation quality not consistant because of a big variability of lightness, saturation and contrast"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eP9biq6Xs_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def auto_canny(image, sigma=0.33):\n",
        "    # compute the median of the single channel pixel intensities\n",
        "    v = np.median(image)\n",
        "\n",
        "    # apply automatic Canny edge detection using the computed median\n",
        "    lower = int(max(0, (1.0 - sigma) * v))\n",
        "    upper = int(min(255, (1.0 + sigma) * v))\n",
        "    edged = cv2.Canny(image, lower, upper)\n",
        "\n",
        "    # return the edged image\n",
        "    return edged"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9db_8jDFoyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from random import random, uniform\n",
        "\n",
        "# load Image\n",
        "#img_path = '/content/database/Bascha_P01_T05_K20_U_Larva_8359_20190717223645.jpg'\n",
        "#img_path = '/content/database/Bascha_P01_T01_K14_M_Adult_1039_20190607040030.jpg'\n",
        "#img_path = '/content/database/Bascha_P01_T06_K13_M_Adult_1008_20190601154259.jpg'\n",
        "#img_path = '/content/database/Bascha_P01_T05_K18_M_Adult_6164_20190703234211.jpg'\n",
        "#img_path = '/content/database/Bascha_P01_T01_K14_M_Adult_1024_20190605213228.jpg'\n",
        "#img_path = '/content/database/Bascha_P01_T02_K13_M_Adult_750_20190531073133.jpg'\n",
        "\n",
        "def preprocess_newts(img_path, input_shape):\n",
        "  #img = imread(img_path)\n",
        "  img = cv2.imread(img_path)\n",
        "# plot original Image\n",
        "#plt.imshow(img)\n",
        "#plt.show()\n",
        "#cv2_imshow(img)\n",
        "\n",
        "\n",
        "  h,w=img.shape[0:2]\n",
        "\n",
        "### Add borders around the image to have more room for wraping and swirling\n",
        "  shift = 20\n",
        "  base_size=h+2*shift,w+2*shift,3\n",
        "# make a 3 channel image for base which is slightly larger than target img\n",
        "  base=np.zeros(base_size)\n",
        "  cv2.rectangle(base,(0,0),(w+2*shift,h+2*shift),(255,255,255),40) # really thick white rectangle\n",
        "  base[shift:h+shift,shift:w+shift]=img # this works\n",
        "  img = base\n",
        "#print(img)\n",
        "#cv2_imshow(img)\n",
        "\n",
        "  h,w=img.shape[0:2]\n",
        "\n",
        "  #print(\"Augmentation par déformation\")\n",
        "\n",
        "### image shearing using sklearn.transform.AffineTransform\n",
        "# try out with differnt values of shear \n",
        "\n",
        "  shear = uniform(-.3, .3)\n",
        "  #print(shear)\n",
        "  tfr = AffineTransform(shear=shear)\n",
        "  sheared = transform.warp(img, tfr, order=1, preserve_range=True,mode='constant', cval=255)\n",
        "#sheared_fig = plot_side_by_side(img, sheared, 'Original', 'Sheared')\n",
        "#plt.title('shear')\n",
        "#plt.imshow(sheared)\n",
        "#v2_imshow(sheared)\n",
        "\n",
        "### image swirling using sklearn swirl\n",
        "# keep strength  between -1 and 1\n",
        "# maximum radius = 500\n",
        "# mode = constant because in case of \"wrap\" some parts of the newts go the other sides of the image. Bad for the training of the neural network\n",
        "  strength = uniform(-1, 1)\n",
        "#print(strength)\n",
        "  swirled = swirl(sheared, rotation=0, strength=strength, radius=500,mode='constant', cval=255)\n",
        "#plt.imshow(swirled)\n",
        "#cv2_imshow(swirled)\n",
        "\n",
        "  img = swirled\n",
        "  #print(img.shape)\n",
        "  img = img.astype(np.uint8)\n",
        "\n",
        "  img0 = cv2.equalizeHist(img[:,:,0])\n",
        "  img1 = cv2.equalizeHist(img[:,:,1])\n",
        "  img2 = cv2.equalizeHist(img[:,:,2])\n",
        "  img[:,:,0] = img0\n",
        "  img[:,:,1] = img1\n",
        "  img[:,:,2] = img2\n",
        "\n",
        "\n",
        "#cv2_imshow(img)\n",
        "\n",
        "  h,w=img.shape[0:2]\n",
        "\n",
        "\n",
        "\n",
        "  hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS) \n",
        "  lower_yellow = np.array([5,15,25]) \n",
        "  upper_yellow = np.array([100,240,255]) \n",
        "\n",
        "  lower_yellow2 = np.array([160,15,25]) \n",
        "  upper_yellow2 = np.array([180,240,255]) \n",
        "#hsl(63, 20%, 81%)\n",
        "  lower_black = np.array([0,0,50]) \n",
        "  upper_black = np.array([35,75,255]) \n",
        "\n",
        "  lower_black2 = np.array([155,0,50]) \n",
        "  upper_black2 = np.array([180,75,255]) \n",
        "# Here we are defining range of yellow color in HSL \n",
        "# This creates a mask of yellow coloured  \n",
        "# objects found in the frame. \n",
        "  mask = cv2.inRange(hls, lower_yellow, upper_yellow)\n",
        "  mask2 = cv2.inRange(hls, lower_yellow2, upper_yellow2)\n",
        "  mask_b = cv2.inRange(hls, lower_black, upper_black) \n",
        "  mask_b2 = cv2.inRange(hls, lower_black2, upper_black2)\n",
        "\n",
        "  mask = mask_b2+mask_b+mask+mask2\n",
        "# The bitwise and of the frame and mask is done so  \n",
        "# that only the blue coloured objects are highlighted  \n",
        "# and stored in res \n",
        "#res = cv2.bitwise_or()\n",
        "  res = cv2.bitwise_and(img,img, mask= mask) \n",
        "#cv2_imshow(img) \n",
        "#cv2_imshow(mask)\n",
        "#cv2_imshow(res) \n",
        "\n",
        "\n",
        "  mask_blur = cv2.GaussianBlur(mask,(5,5),cv2.BORDER_DEFAULT)\n",
        "\n",
        "  threshMap = cv2.threshold(mask_blur.astype(\"uint8\"), 0, 255,\n",
        "\t  cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
        "\n",
        "  kernel = np.ones((7,7),np.uint8)\n",
        "  threshMap = cv2.dilate(threshMap, kernel)\n",
        "  threshMap = cv2.erode(threshMap, kernel)\n",
        "\n",
        "\n",
        "#cv2_imshow(mask_blur)\n",
        "#cv2_imshow(threshMap)\n",
        "\n",
        "  canny_output = auto_canny(threshMap, sigma = 0.3)\n",
        "#canny_output = cv2.convertScaleAbs(canny_output)\n",
        "  kernel = np.ones((9,9),np.uint8)\n",
        "  threshed = cv2.dilate(canny_output,kernel)\n",
        "\n",
        "\n",
        "#print(canny_output[1])\n",
        "#plt.imshow(canny_output)\n",
        "#plt.colorbar()\n",
        "#plt.show()\n",
        "\n",
        "\n",
        "## findContours(查找轮廓)\n",
        "  cnts = cv2.findContours(threshed, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
        "\n",
        "#print(cnts[0])\n",
        "#plt.imshow(threshed)\n",
        "#plt.colorbar()\n",
        "#plt.show()\n",
        "#print(cnts.shape)\n",
        "\n",
        "#new,contours, hierarchy = cv2.findContours(threshed, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "#contours= sorted(contours, key = cv2.contourArea, reverse = True)[:4]\n",
        "#c=contours[0]\n",
        "#print(cv2.contourArea(c))\n",
        "#final = cv2.drawContours(img, [c], -1, (255,0, 0), 3)\n",
        "\n",
        "\n",
        "#cnts = canny_output\n",
        "#cnts = sorted(canny_output, key=cv2.contourArea)\n",
        "## sorted by area(按照面积排序)\n",
        "  cnts = sorted(cnts, key=cv2.contourArea)\n",
        "\n",
        "## get the maximum's boundinRect(获取最大边缘的外接矩形)\n",
        "  cnt = cnts[-1]\n",
        "\n",
        "## create mask(创建掩模)\n",
        "  mask = np.ones_like(threshMap, np.uint8)*cv2.GC_PR_BGD\n",
        "  cv2.drawContours(mask, cnt, -1, cv2.GC_FGD, -1)\n",
        "\n",
        "#print(\"shape of cnt: {}\".format(cnt.shape))\n",
        "\n",
        "#plt.imshow(mask)\n",
        "#plt.colorbar()\n",
        "#plt.show()\n",
        "\n",
        "#new_image = cv2.bitwise_and(img,img,mask=mask)\n",
        "#print(mask)\n",
        "  new_image = threshMap.copy()\n",
        "  new_image[mask == 2] = 0  # Set values not masked to be 0\n",
        "\n",
        "#plt.imshow(new_image)\n",
        "#plt.colorbar()\n",
        "#plt.show()\n",
        "\n",
        "#retval = cv2.contourArea(cnt)\n",
        "#print(retval)\n",
        "\n",
        "  rect = cv2.minAreaRect(cnt)\n",
        "  #print(\"rect: {}\".format(rect))\n",
        "\n",
        "  box = cv2.boxPoints(rect)\n",
        "  box = np.int0(box)\n",
        "\n",
        "  width = int(rect[1][0])\n",
        "  height = int(rect[1][1])\n",
        "\n",
        "  src_pts = box.astype(\"float32\")\n",
        "  dst_pts = np.array([[0, height-1],\n",
        "                    [0, 0],\n",
        "                    [width-1, 0],\n",
        "                    [width-1, height-1]], dtype=\"float32\")\n",
        "  M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
        "  warped = cv2.warpPerspective(img, M, (width, height))\n",
        "\n",
        "#cv2_imshow(warped)\n",
        "\n",
        "  #print(\"Augmentation par couleurs\")\n",
        "  image = tf.image.random_brightness(warped, max_delta=0.10) # Random brightness\n",
        "  #image = tf.image.random_flip_left_right(image)\n",
        "  #image = tf.image.random_flip_up_down(image)\n",
        "  image = tf.image.random_contrast(image,0.5,2)\n",
        "  image = tf.image.random_saturation(image,0.5,2)\n",
        "\n",
        "  height = input_shape[0]\n",
        "  width = input_shape[1]\n",
        "  \n",
        "  if (image.shape[0] < image.shape[1]):\n",
        "    image = tf.image.resize(image, [width, height])\n",
        "    #print(\"height < width\")\n",
        "    image = tf.image.transpose(image)\n",
        "  else:\n",
        "    image = tf.image.resize(image, [height, width])\n",
        "    #print(\"height > width\")\n",
        "\n",
        "  return image\n",
        "\n",
        "#from keras.preprocessing.image import array_to_img, img_to_array\n",
        "#img = img_to_array(image)\n",
        "#cv2_imshow(img.astype('uint8'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgqhLvrXKIQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape = (56,56,3)\n",
        "\n",
        "\n",
        "def augmentationImage(img_path,img_aug_path, input_shape):\n",
        "\n",
        "  \n",
        "  !rm -rf /content/content/databaseAug\n",
        "  data = pd.read_csv('/content/content/Stage/training.csv',)\n",
        "  #data = data.to_numpy()\n",
        "  labels = data.iloc[:,4]\n",
        "  #print(labels.head())\n",
        "  names = data.iloc[:,0]\n",
        "  #print(names.head())\n",
        "  #abels.head()\n",
        "  labels_uniques, counts = np.unique(labels, return_counts=True)\n",
        "  \n",
        "  #print(labels_uniques)\n",
        "  for label in labels_uniques:\n",
        "    os.makedirs(img_aug_path+'/train/'+label)\n",
        "    os.makedirs(img_aug_path+'/test/'+label)\n",
        "\n",
        "\n",
        "  print(\"Création de la base de données augmentées en cours...\")\n",
        "  # List all files in a directory using scandir()\n",
        "  basepath = '/content/content/Stage/database'\n",
        "  with os.scandir(basepath) as images:\n",
        "    for im in images:\n",
        "      #print(im.name)\n",
        "      if(im.name in names.values):\n",
        "        \n",
        "        id = names[names == im.name].index[0]\n",
        "        #id = names.loc[im.name]\n",
        "        #print(id)\n",
        "        label = labels.iloc[id]\n",
        "        #print('label : '+label)\n",
        "        id_label = np.where(labels_uniques == label)\n",
        "        #print(id_label)\n",
        "        imagePath = basepath + '/' + im.name\n",
        "        #print(imagePath)\n",
        "        \n",
        "        count = counts[id_label]\n",
        "        #print(count)\n",
        "        #img_path = '/content/database/Bascha_P01_T01_K14_M_Adult_1024_20190605213228.jpg'\n",
        "        #img = prepare_img(input_shape,imagePath)\n",
        "        #image = cv2_imread(path + '/' + im.name)\n",
        "        \n",
        "        \n",
        "        k = 0\n",
        "        while (k < 20):  ######### DIVISER PAR COUNT QUAND BASE DE DONNEE COMPLETE\n",
        "          #image = tf.image.random_brightness(img, max_delta=0.15) # Random brightness\n",
        "          #image = tf.image.random_flip_left_right(image)\n",
        "          #image = tf.image.random_flip_up_down(image)\n",
        "          #image = tf.image.random_contrast(image,0.5,3)\n",
        "          #image = tf.image.random_saturation(image,0.5,3)\n",
        "          image = preprocess_newts(imagePath, input_shape)\n",
        "         \n",
        "          augPath = img_aug_path+'/train/'+label+'/' + im.name[:-4] + str(k) + '.jpg'\n",
        "          #augPath = img_aug_path+'/test/'+label+'/' + im.name + str(k)\n",
        "          #save_img(augPath, image)\n",
        "          image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "          #print(image.shape)\n",
        "          cv2.imwrite(augPath,image*255)\n",
        "          #plt.imsave(augPath, image/255)\n",
        "          k += 1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg58GZPqNerv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_path = '/content/Stage_cropped/database'\n",
        "img_aug_path = '/content/databaseAug'\n",
        "augmentationImage(img_path,img_aug_path,input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQib9u95v5y_",
        "colab_type": "text"
      },
      "source": [
        "# Import the augmented, cropped dataset to begin the training with the triplet loss embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVBpICWkNi4k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "294fade8-1168-4136-8f03-6f6008bea9c5"
      },
      "source": [
        "train_size = sum(len(files) for _, _, files in os.walk(r'/content/ds_final_unet_x2/content/ds_final/train'))\n",
        "print(train_size)\n",
        "test_size = sum(len(files) for _, _, files in os.walk(r'/content/ds_final_unet_x2/content/ds_final/test'))\n",
        "print(test_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unt19KTVHOkR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "#width = 56\n",
        "#height = 56\n",
        "\n",
        "train_path = '/content/ds_final_unet_lite/content/ds_final/train'\n",
        "test_path = '/content/ds_final_unet_lite/content/ds_final/test'\n",
        "\n",
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  print(parts[-2])\n",
        "  # The second to last is the class-directory\n",
        "  return parts[-2] == CLASS_NAMES\n",
        "\n",
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
        "  #img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  # resize the image to the desired size.\n",
        "  return img\n",
        "\n",
        "def process_path(file_path):\n",
        "  #print(file_path)\n",
        "  label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  try:\n",
        "    img = decode_img(img)\n",
        "    #print(np.max(img))\n",
        "    print(\"decoded\")\n",
        "    counter +=1\n",
        "  except:\n",
        "    print(\"erreur décodage\")\n",
        "\n",
        "  return img, label\n",
        "\n",
        "def format_image(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image = (image/127.5) - 1\n",
        "  image = tf.image.resize(image, (input_shape[0], input_shape[1]))\n",
        "  return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ztNT85nNf8pj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "e7c494c6-cfe5-4e98-d1cd-8e88665ffe2c"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "#train_path = '/content/ds_final/train'\n",
        "#test_path = '/content/ds_final/test'\n",
        "\n",
        "train_size = sum(len(files) for _, _, files in os.walk(train_path))\n",
        "print(train_size)\n",
        "test_size = sum(len(files) for _, _, files in os.walk(test_path))\n",
        "print(test_size)\n",
        "\n",
        "#BATCH_SIZE = 32\n",
        "#input_shape = (50,35,3)\n",
        "#data_dir = \"/content/male\"\n",
        "input_shape = (75,30,3)\n",
        "\n",
        "\n",
        "\n",
        "data_dir = pathlib.Path(train_path)\n",
        "test_dir = pathlib.Path(test_path)\n",
        "\n",
        "list_ds = tf.data.Dataset.list_files(str(data_dir)+'/*/*')\n",
        "list_ds_test = tf.data.Dataset.list_files(str(test_dir)+'/*/*')\n",
        "\n",
        "CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"])\n",
        "#print(type(CLASS_NAMES))\n",
        "print(CLASS_NAMES)\n",
        "#for f in list_ds.take(5):\n",
        "  #print(f.numpy())\n",
        "#counter = 0\n",
        "\n",
        "def show_batch(image_batch, label_batch):\n",
        "  plt.figure(figsize=(10,10))\n",
        "  for n in range(25):\n",
        "      ax = plt.subplot(5,5,n+1)\n",
        "      plt.imshow(image_batch[n])\n",
        "      plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n",
        "      plt.axis('off')\n",
        "\n",
        "def augment(image,label):\n",
        "  #image,label = convert(image, label)\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32) # Cast and normalize the image to [0,1]\n",
        "  #image = tf.image.rgb_to_grayscale(image)\n",
        "  #image = tf.image.resize_with_crop_or_pad(image, 34, 34) # Add 6 pixels of padding\n",
        "  #image = tf.image.random_crop(image, size=[28, 28, 1]) # Random crop back to 28x28\n",
        "  #image = tf.image.random_brightness(image, max_delta=0.5) # Random brightness\n",
        "  #image = tf.image.flip_left_right(image)\n",
        "\n",
        "  return image,label\n",
        "#Use Dataset.map to create a dataset of image, label pairs:\n",
        "\n",
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "labeled_ds_test = list_ds_test.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "#train_size = int(0.7 * nbr_element)\n",
        "\n",
        "#val_size = int(0.30 * nbr_element)\n",
        "#test_size = int(0.15 * DATASET_SIZE)\n",
        "\n",
        "\n",
        "#full_dataset = labeled_ds.shuffle()\n",
        "#train_dataset = labeled_ds.take(train_size)\n",
        "#test_dataset = labeled_ds.skip(train_size)\n",
        "#val_dataset = test_dataset.skip(test_size)\n",
        "#test_dataset = test_dataset.take(val_size)\n",
        "\n",
        "train_dataset = labeled_ds.map(format_image, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "test_dataset = labeled_ds_test.map(format_image, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "count_label = len(os.listdir(train_path))\n",
        "#print(count_label)\n",
        "\n",
        "x_train = np.zeros((train_size,input_shape[0],input_shape[1],input_shape[2]))\n",
        "y_train = np.zeros((train_size))\n",
        "x_test = np.zeros((test_size,input_shape[0],input_shape[1],input_shape[2]))\n",
        "y_test = np.zeros((test_size))\n",
        "\n",
        "k=0\n",
        "for image, label in train_dataset:\n",
        "  #print(label)\n",
        "  x_train[k,:,:,:] = image\n",
        "  y_train[k] = np.where(label)[0][0]\n",
        "  k += 1\n",
        "k=0\n",
        "for image, label in test_dataset:\n",
        "  x_test[k,:,:,:] = image\n",
        "  y_test[k] = np.where(label)[0][0]\n",
        "  k += 1\n",
        "  #print(np.where(label)[0])\n",
        "\n",
        "#tfds_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "#tfds_train = tfds_train.batch(32)\n",
        "#for i,j in tfds_train:\n",
        " # print(i)\n",
        "  #print(j)\n",
        "#tfds_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "#tfds_test = tfds_test.batch(32)\n",
        "  #print(\"Image shape: \", image.numpy().shape)\n",
        "  #print(\"Label: \", label.numpy())\n",
        "#print(y_train)\n",
        "dataset = []\n",
        "dataset_test = []\n",
        "    \n",
        "#Sorting images by classes and normalize values 0=>\n",
        "for n in range(count_label):\n",
        "    images_class_n_train = np.asarray([row for idx,row in enumerate(x_train) if y_train[idx]==n])\n",
        "    dataset.append(images_class_n_train)\n",
        "\n",
        "\n",
        "    images_class_n_test = np.asarray([row for idx,row in enumerate(x_test) if y_test[idx]==n])\n",
        "    dataset_test.append(images_class_n_test)\n",
        "\n",
        "  \n",
        "print(\"nombre de classes différentes : \"+ str(count_label))\n",
        "#for n in range(int(count_label*0.30)):\n",
        " #   images_class_n = np.asarray([row for idx,row in enumerate(x_test) if y_test[idx]==n])\n",
        "    #print(images_class_n.shape)\n",
        "  #  dataset_test.append(images_class_n/255)\n",
        "        \n",
        "    #images_class_n = np.asarray([row for idx,row in enumerate(x_test_origin) if y_test_origin[idx]==n])\n",
        "    #dataset_test.append(images_class_n/255)\n",
        "#input_shape = [width,height,3]\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R47bRikWU72Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_label(file_path):\n",
        " # convert the path to a list of path components\n",
        " parts = tf.strings.split(file_path, os.path.sep)\n",
        " print(parts[-2])\n",
        " # The second to last is the class-directory\n",
        " return parts[-2] == CLASS_NAMES\n",
        "\n",
        "def decode_img(img):\n",
        " # convert the compressed string to a 3D uint8 tensor\n",
        " img = tf.image.decode_jpeg(img, channels=3)\n",
        " # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
        " #img = tf.image.convert_image_dtype(img, tf.float32)\n",
        " # resize the image to the desired size.\n",
        " return img\n",
        "\n",
        "def process_path(file_path):\n",
        " #print(file_path)\n",
        " label = get_label(file_path)\n",
        " # load the raw data from the file as a string\n",
        " img = tf.io.read_file(file_path)\n",
        " try:\n",
        "  img = decode_img(img)\n",
        " #print(np.maimg))\n",
        "  print(\"decoded\")\n",
        "  counter +=1\n",
        " except:\n",
        "  print(\"erreur décodage\")\n",
        "\n",
        " return img, label\n",
        "\n",
        "def format_image(image, label):\n",
        " image = tf.cast(image, tf.float32)\n",
        " image = (image/127.5) - 1\n",
        " image = tf.image.resize(image, (input_shape[0], input_shape[1]))\n",
        " return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh0VOnzWVFiu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3be5cc59-ba5d-4853-f8ab-8f230256299f"
      },
      "source": [
        "def import_images(img_path, input_shape):\n",
        "\n",
        " AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "\n",
        " ds_size = sum(len(files) for _, _, files in os.walk(img_path))\n",
        " print(ds_size)\n",
        "\n",
        " data_dir = pathlib.Path(img_path)\n",
        "\n",
        " list_ds = tf.data.Dataset.list_files(str(data_dir)+'/*/*')\n",
        "\n",
        " global CLASS_NAMES \n",
        " CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"])\n",
        "\n",
        " \n",
        " #print(CLASS_NAMES)\n",
        " \n",
        "\n",
        " #Use Dataset.map to create a dataset of image, label pairs:\n",
        "\n",
        " # Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        " labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        " \n",
        "\n",
        " \n",
        "\n",
        " dataset = labeled_ds.map(format_image, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        " count_label = len(os.listdir(img_path))\n",
        " #print(count_label)\n",
        "\n",
        " x = np.zeros((ds_size,input_shape[0],input_shape[1],input_shape[2]))\n",
        " y = np.zeros((ds_size))\n",
        "\n",
        "\n",
        " k=0\n",
        " for image, label in dataset:\n",
        " #print(label)\n",
        "  x[k,:,:,:] = image\n",
        "  y[k] = np.where(label)[0][0]\n",
        "  #print(y[k])\n",
        "  k += 1\n",
        "\n",
        "\n",
        " dataset = []\n",
        "\n",
        " \n",
        " #Sorting images by classes and normalize values 0=>\n",
        " for n in range(count_label):\n",
        "  images_class_n = np.asarray([row for idx,row in enumerate(x) if y[idx]==n])\n",
        "  dataset.append(images_class_n)\n",
        "\n",
        " \n",
        " print(\"number of different newts : \"+ str(count_label))\n",
        "\n",
        " return dataset\n",
        "\n",
        "input_shape = (75,30,3)\n",
        "img_path = '/content/ds_final_merged'\n",
        "dataset = import_images(img_path,input_shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv-KvrgmEOTu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82d33c0c-d14c-4716-bb68-fe4e3b39e23a"
      },
      "source": [
        "np.max(dataset[0])\n",
        "np.min(dataset[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CMpnx7dxzAr",
        "colab_type": "text"
      },
      "source": [
        "# Only to compare the performances, import the AmphIdent outputs dataset. (do not run)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ3dkANMMvzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "width = 32\n",
        "height = 75\n",
        "\n",
        "\n",
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  #parts = str(file_path).split(\"/\")\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  #print(type(parts[-1]))\n",
        "  print(parts[-1].numpy().decode(\"utf-8\"))\n",
        "  #test = str(parts)\n",
        "  \n",
        "  #for part in parts:\n",
        "   # print(part)\n",
        "  #lab = parts[-2].numpy().decode(\"utf-8\")  + '/'+ parts[-1].numpy().decode(\"utf-8\")\n",
        "  #lab = parts[-1]\n",
        "  #print(lab)\n",
        "  #print(parts.  )\n",
        "\n",
        "  #for l in np.range(lab):\n",
        "    #print(l)\n",
        "\n",
        "  i = 0\n",
        "  while (parts[-1].numpy().decode(\"utf-8\")[i] != \"_\"):\n",
        "    i += 1\n",
        "  \n",
        "  #id = patterns[patterns == lab]\n",
        "  #if (id.empty):\n",
        "  #print(lab)\n",
        "\n",
        "  \n",
        "  # The second to last is the class-directory\n",
        "  #print( tf.convert_to_tensor(lab[:i]))\n",
        "  #print(CLASS_NAMES)\n",
        "  #print(type(tf.convert_to_tensor(parts[-1].numpy().decode(\"utf-8\")[:i])))\n",
        "  #print(CLASS_NAMES[0])\n",
        "  #print(type(CLASS_NAMES[0]))\n",
        "  return tf.convert_to_tensor(parts[-1].numpy().decode(\"utf-8\")[:i]) == CLASS_NAMES\n",
        "  #assert not id.empty \n",
        "  #print(id.index)\n",
        "\n",
        " # id = ids.iloc[id.index]\n",
        "  #print(id)\n",
        "  # The second to last is the class-directory\n",
        "  #print(type(tf.convert_to_tensor(id)))\n",
        "  #return tf.convert_to_tensor(id)[0]\n",
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  # resize the image to the desired size.\n",
        "  return tf.image.resize(img, [width, height])\n",
        "\n",
        "def process_path(file_path):\n",
        "  #print(file_path)\n",
        "  label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  #print(img)\n",
        "  try:\n",
        "    img = decode_img(img)\n",
        "    #print(\"decoded\")\n",
        "    counter +=1\n",
        "  except:\n",
        "   # print(\"erreur décodage\")\n",
        "    pass\n",
        "\n",
        "  return img, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XiVTt-Iy3xo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_size = sum(len(files) for _, _, files in os.walk(r'/content/train'))\n",
        "print(train_size)\n",
        "test_size = sum(len(files) for _, _, files in os.walk(r'/content/test'))\n",
        "print(test_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPnTS1TbIRFs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "6f55baa5-31f1-407f-eaf1-8d35841a09a0"
      },
      "source": [
        "#BATCH_SIZE = 32\n",
        "\n",
        "#data_dir = \"/content/male\"\n",
        "\n",
        "#base_path = \"/content/Stage/database\"\n",
        "\n",
        "\n",
        "#nathan_ds = tf.data.Dataset.list_files(str(nathan_dir)+'/*')\n",
        "\n",
        "#CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"])\n",
        "\n",
        "#for f in list_ds.take(5):\n",
        "  #print(f.numpy())\n",
        "#counter = 0\n",
        "\n",
        "\n",
        "ds_path = \"/content/dataset_amphident/dataset_amphident\"\n",
        "ds_path = pathlib.Path(ds_path)\n",
        "\n",
        "ds_dir = os.listdir(ds_path)\n",
        "\n",
        "CLASS_NAMES = []\n",
        "\n",
        "for pattern in ds_dir:\n",
        "  i = 0\n",
        "  while (pattern[i] != \"_\"):\n",
        "    i += 1\n",
        "  CLASS_NAMES.append(pattern[:i])\n",
        "  #print(pattern[:i])\n",
        "\n",
        "CLASS_NAMES = np.array(CLASS_NAMES)\n",
        "CLASS_NAMES = np.unique(CLASS_NAMES)\n",
        "\n",
        "def show_batch(image_batch, label_batch):\n",
        "  plt.figure(figsize=(10,10))\n",
        "  for n in range(25):\n",
        "      ax = plt.subplot(5,5,n+1)\n",
        "      plt.imshow(image_batch[n])\n",
        "      plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n",
        "      plt.axis('off')\n",
        "\n",
        "def augment(image,label):\n",
        "  #image,label = convert(image, label)\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32) # Cast and normalize the image to [0,1]\n",
        "  #image = tf.image.resize_with_crop_or_pad(image, 34, 34) # Add 6 pixels of padding\n",
        "  #image = tf.image.random_crop(image, size=[28, 28, 1]) # Random crop back to 28x28\n",
        "  image = tf.image.random_brightness(image, max_delta=0.5) # Random brightness\n",
        "  image = tf.image.flip_left_right(image)\n",
        "\n",
        "  return image,label\n",
        "#Use Dataset.map to create a dataset of image, label pairs:\n",
        "#nathands = tf.data.Dataset.list_files(str(nathan_ds)+'/*')\n",
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "#labeled_ds = ds.map(lambda x: tf.py_function(process_path, [x], [tf.float32, tf.bool]), num_parallel_calls = AUTOTUNE)\n",
        "#print(labeled_ds_nathan)\n",
        "#for image,label in labeled_ds:\n",
        "  #print(image)\n",
        "  #print(label)\n",
        "#labeled_ds_remy = remy_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "#train_size = int(0.7 * nbr_element)\n",
        "#train_size=nbr_element-count_label*4\n",
        "#test_size=count_label*4\n",
        "#val_size = int(0.30 * nbr_element)\n",
        "#test_size = int(0.15 * DATASET_SIZE)\n",
        "#print(patterns)\n",
        "train_size = patterns.size\n",
        "\n",
        "#full_dataset = labeled_ds.shuffle()\n",
        "#train_dataset = labeled_ds_nathan.take(len(nathan_ds))\n",
        "#train_dataset2 = labeled_ds_remy.take(len(remy_ds))\n",
        "#test_dataset = labeled_ds.skip(train_size)\n",
        "#val_dataset = test_dataset.skip(test_size)\n",
        "#test_dataset = test_dataset.take(val_size)\n",
        "train_dataset = ds.map(lambda x: tf.py_function(process_path, [x], [tf.float32, tf.bool]), num_parallel_calls = AUTOTUNE)\n",
        "#train_dataset2 = labeled_ds_remy.map(augment, num_parallel_calls=AUTOTUNE)\n",
        "test_dataset = ds.map(lambda x: tf.py_function(process_path, [x], [tf.float32, tf.bool]), num_parallel_calls = AUTOTUNE)\n",
        "\n",
        "x_train = np.zeros((train_size,width,height,3))\n",
        "y_train = np.zeros((train_size,1))\n",
        "x_test = np.zeros((test_size,width,height,3))\n",
        "y_test = np.zeros((test_size))\n",
        "\n",
        "k=0\n",
        "for image,label in train_dataset:\n",
        "  #print(label)\n",
        "  x_train[k,:,:,:] = image\n",
        "  y_train[k] = np.where(label)[0][0]\n",
        "  k += 1\n",
        "\n",
        "k=0\n",
        "for image, label in test_dataset:\n",
        " x_test[k,:,:,:] = image\n",
        " y_test[k] = np.where(label)[0][0]\n",
        " k += 1\n",
        " print(np.where(label)[0])\n",
        "\n",
        "\n",
        "print(y_train)\n",
        "dataset = []\n",
        "dataset_test = []\n",
        "    \n",
        "#Sorting images by classes and normalize values 0=>\n",
        "for n in range(len(labels)):\n",
        "    images_class_n_train = np.asarray([row for idx,row in enumerate(x_train) if y_train[idx]==n])\n",
        "    dataset.append(images_class_n_train/255)\n",
        "\n",
        "    images_class_n_test = np.asarray([row for idx,row in enumerate(x_test) if y_test[idx]==n])\n",
        "    dataset_test.append(images_class_n_test/255)\n",
        "\n",
        "  \n",
        "print(\"nombre de classes différentes : \"+ str(count_label))\n",
        "  \n",
        "input_shape = [width,height,3]\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRxv5s0OOsVP",
        "colab_type": "text"
      },
      "source": [
        "MNIST dataset that was used at the very beginning of the project, (do not run)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffTek-l3McKU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "4342428f-e8fc-4667-f4c9-a3675e503cef"
      },
      "source": [
        "\"\"\" build MNIST dataset \"\"\"\n",
        "\n",
        "nb_classes = 10\n",
        "count_label = nb_classes\n",
        "img_rows, img_cols = 28, 28\n",
        "input_shape = [img_rows, img_cols, 1]\n",
        "\n",
        "def buildDataSet():\n",
        "    \"\"\"Build dataset for train and test\n",
        "    \n",
        "    \n",
        "    returns:\n",
        "        dataset : list of lengh 10 containing images for each classes of shape (?,28,28,1)\n",
        "    \"\"\"\n",
        "\n",
        "    #fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "    #(x_train_origin, y_train_origin), (x_test_origin, y_test_origin) = fashion_mnist.load_data()\n",
        "    (x_train_origin, y_train_origin), (x_test_origin, y_test_origin) = datasets.mnist.load_data()\n",
        "\n",
        "    assert backend.image_data_format() == 'channels_last'\n",
        "    x_train_origin = x_train_origin.reshape(x_train_origin.shape[0], img_rows, img_cols, 1)\n",
        "    x_test_origin = x_test_origin.reshape(x_test_origin.shape[0], img_rows, img_cols, 1)\n",
        "    \n",
        "    dataset_train = []\n",
        "    dataset_test = []\n",
        "    \n",
        "    #Sorting images by classes and normalize values 0=>1\n",
        "    for n in range(nb_classes):\n",
        "        images_class_n = np.asarray([row for idx,row in enumerate(x_train_origin) if y_train_origin[idx]==n])\n",
        "        #print(images_class_n.shape)\n",
        "        dataset_train.append(images_class_n/255)\n",
        "        \n",
        "        images_class_n = np.asarray([row for idx,row in enumerate(x_test_origin) if y_test_origin[idx]==n])\n",
        "        dataset_test.append(images_class_n/255)\n",
        "    \n",
        "    return dataset_train,dataset_test,x_train_origin,y_train_origin,x_test_origin,y_test_origin\n",
        "\n",
        "dataset,dataset_test,x_train_origin,y_train_origin,x_test_origin,y_test_origin = buildDataSet()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f1Un3nuWlks",
        "colab_type": "text"
      },
      "source": [
        "# Triplet Loss Embedding implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wvOPPuIKhLJi"
      },
      "source": [
        "![fig2](https://user-images.githubusercontent.com/18154355/61485417-1cbb1f00-a96f-11e9-8d6a-94964ce8c4db.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIALib727ax7",
        "colab_type": "text"
      },
      "source": [
        "## Build different architectures of neural networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBbtHtPuVEh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Lambda, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.backend import l2_normalize\n",
        "from tensorflow.keras import Input, Model\n",
        "\n",
        "def build_network_feedforward(input_shape, embeddingsize):\n",
        "    '''\n",
        "    Define the neural network to learn image similarity\n",
        "    Input : \n",
        "            input_shape : shape of input images\n",
        "            embeddingsize : vectorsize used to encode our picture   \n",
        "    '''\n",
        "     # Convolutional Neural Network\n",
        "    network = Sequential()\n",
        "    network.add(Flatten(input_shape=input_shape))\n",
        "    #network.add(Dense(4096, activation='relu',\n",
        "     #              kernel_regularizer=l2(1e-3),\n",
        "      #             kernel_initializer='he_uniform'))\n",
        "    \n",
        "    \n",
        "    network.add(Dense(embeddingsize, activation=None,\n",
        "                   kernel_regularizer=l2(1e-3),\n",
        "                   kernel_initializer='he_uniform'))\n",
        "    \n",
        "    #Force the encoding to live on the d-dimentional hypershpere\n",
        "    #network.add(Lambda(lambda x: K.l2_normalize(x,axis=-1)))\n",
        "    \n",
        "    return network\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3htF-aTLhKvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Lambda, BatchNormalization, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.backend import l2_normalize\n",
        "from tensorflow.keras import Input, Model\n",
        "\n",
        "def build_network(input_shape, embeddingsize):\n",
        "    '''\n",
        "    Define the neural network to learn image similarity\n",
        "    Input : \n",
        "            input_shape : shape of input images\n",
        "            embeddingsize : vectorsize used to encode our picture   \n",
        "    '''\n",
        "     # Convolutional Neural Network\n",
        "    network = Sequential()\n",
        "    network.add(Conv2D(500, (9,9), activation='relu',\n",
        "                     input_shape=input_shape,\n",
        "                     kernel_initializer='he_uniform',\n",
        "                     ))\n",
        "    network.add(MaxPooling2D())\n",
        "    network.add(Dropout(0.5))\n",
        "    network.add(BatchNormalization())\n",
        "    network.add(Flatten())\n",
        "    #network.add(Dense(4096, activation='relu',\n",
        "     #              kernel_regularizer=l2(1e-3),\n",
        "      #             kernel_initializer='he_uniform'))\n",
        "    \n",
        "    \n",
        "    network.add(Dense(embeddingsize, activation=None,\n",
        "                   kernel_regularizer=l2(1e-3),\n",
        "                   kernel_initializer='he_uniform'))\n",
        "    \n",
        "    #Force the encoding to live on the d-dimentional hypershpere\n",
        "    network.add(Lambda(lambda x: l2_normalize(x,axis=-1)))\n",
        "    \n",
        "    return network\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Au6oik70DAKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_network(input_shape, embeddingsize):\n",
        "    '''\n",
        "    Define the neural network to learn image similarity\n",
        "    Input : \n",
        "            input_shape : shape of input images\n",
        "            embeddingsize : vectorsize used to encode our picture   \n",
        "    '''\n",
        "     # Convolutional Neural Network\n",
        "    network = Sequential()\n",
        "    network.add(Conv2D(128, (7,7), activation='relu',\n",
        "                     input_shape=input_shape,\n",
        "                     kernel_initializer='he_uniform',\n",
        "                     kernel_regularizer=l2(2e-4)))\n",
        "    network.add(MaxPooling2D())\n",
        "    network.add(Conv2D(128, (3,3), activation='relu', kernel_initializer='he_uniform',\n",
        "                     kernel_regularizer=l2(2e-4)))\n",
        "    network.add(MaxPooling2D())\n",
        "    network.add(Conv2D(256, (3,3), activation='relu', kernel_initializer='he_uniform',\n",
        "                     kernel_regularizer=l2(2e-4)))\n",
        "    network.add(Flatten())\n",
        "    network.add(Dense(4096, activation='relu',\n",
        "                   kernel_regularizer=l2(1e-3),\n",
        "                   kernel_initializer='he_uniform'))\n",
        "    \n",
        "    \n",
        "    network.add(Dense(embeddingsize, activation=None,\n",
        "                   kernel_regularizer=l2(1e-3),\n",
        "                   kernel_initializer='he_uniform'))\n",
        "    \n",
        "    #Force the encoding to live on the d-dimentional hypershpere\n",
        "    network.add(Lambda(lambda x: l2_normalize(x,axis=-1)))\n",
        "    \n",
        "    return network"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz1SpoWsOl0b",
        "colab_type": "text"
      },
      "source": [
        "This neural network is the best, do not run the others"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8zzNXNWMv3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Lambda, BatchNormalization, Dropout, LeakyReLU\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.backend import l2_normalize\n",
        "from tensorflow.keras import Input, Model\n",
        "\n",
        "\n",
        "def build_network(input_shape, embeddingsize):\n",
        "    '''\n",
        "    Define the neural network to learn image similarity\n",
        "    Input : \n",
        "            input_shape : shape of input images\n",
        "            embeddingsize : vectorsize used to encode our picture   \n",
        "    '''\n",
        "     # Convolutional Neural Network\n",
        "    network = Sequential()\n",
        "    network.add(Conv2D(512, (7,7), activation='relu',\n",
        "                     input_shape=input_shape,\n",
        "                     kernel_initializer='he_uniform',\n",
        "                     ))\n",
        "    network.add(MaxPooling2D())\n",
        "    network.add(Dropout(0.5))\n",
        "    network.add(BatchNormalization())\n",
        "    network.add(Conv2D(512, (5,5), activation='relu', kernel_initializer='he_uniform',\n",
        "                     ))\n",
        "    network.add(MaxPooling2D())\n",
        "    network.add(Dropout(0.5))\n",
        "    network.add(BatchNormalization())\n",
        "    network.add(Conv2D(512, (3,3), activation='relu', kernel_initializer='he_uniform',\n",
        "                     ))\n",
        "    network.add(MaxPooling2D())\n",
        "    #network.add(Dropout(0.5))\n",
        "    \n",
        "    network.add(Flatten())\n",
        "    #network.add(Dense(4096, activation='relu',\n",
        "     #              kernel_regularizer=l2(1e-3),\n",
        "      #             kernel_initializer='he_uniform'))\n",
        "    network.add(BatchNormalization())\n",
        "    \n",
        "    network.add(Dense(embeddingsize, activation=None,\n",
        "                   kernel_initializer='he_uniform'))\n",
        "    \n",
        "    #Force the encoding to live on the d-dimentional hypershpere\n",
        "    #network.add(Lambda(lambda x: l2_normalize(x,axis=-1)))\n",
        "    \n",
        "    return network\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Axb5xlJ0F7uh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Lambda, BatchNormalization, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.backend import l2_normalize\n",
        "from tensorflow.keras import Input, Model\n",
        "\n",
        "def build_network(input_shape, embeddingsize):\n",
        "    '''\n",
        "    Define the neural network to learn image similarity\n",
        "    Input : \n",
        "            input_shape : shape of input images\n",
        "            embeddingsize : vectorsize used to encode our picture   \n",
        "    '''\n",
        "     # Convolutional Neural Network\n",
        "    network = Sequential()\n",
        "    network.add(Conv2D(128, (5,5),\n",
        "                     input_shape=input_shape,\n",
        "                     kernel_initializer='he_uniform'))\n",
        "    network.add(tf.keras.layers.LeakyReLU(alpha=0.3))\n",
        "                     ##kernel_regularizer=l2(2e-4)))\n",
        "    network.add(MaxPooling2D())\n",
        "    network.add(Dropout(0.5))\n",
        "    \n",
        "    network.add(Flatten())\n",
        "    network.add(Dense(2048,\n",
        "                   kernel_regularizer=l2(1e-5),\n",
        "                   kernel_initializer='glorot_uniform'))\n",
        "    network.add(BatchNormalization())\n",
        "    network.add(tf.keras.layers.LeakyReLU(alpha=0.3))\n",
        "    network.add(Dense(512,\n",
        "                   kernel_regularizer=l2(1e-5),\n",
        "                   kernel_initializer='glorot_uniform'))\n",
        "    network.add(BatchNormalization())\n",
        "    network.add(tf.keras.layers.LeakyReLU(alpha=0.3))\n",
        "    network.add(Dense(embeddingsize, activation=None,\n",
        "                   kernel_regularizer=l2(1e-5),\n",
        "                   kernel_initializer='glorot_uniform'))\n",
        "    \n",
        "    #Force the encoding to live on the d-dimentional hypershpere\n",
        "    network.add(Lambda(lambda x: l2_normalize(x,axis=-1)))\n",
        "    \n",
        "    return network\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bQwBbFVAyHJ_"
      },
      "source": [
        "##Triplet Loss\n",
        "\n",
        "As first introduced in the FaceNet paper, TripletLoss is a loss function that trains a neural network to closely embed features of the same class while maximizing the distance between embeddings of different classes.  To do this an anchor  is chosen along with one negative and one positive sample.\n",
        "![fig3](https://user-images.githubusercontent.com/18154355/61485418-1cbb1f00-a96f-11e9-8de8-3c46eef5a7dc.png)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y_QGN987qWO",
        "colab_type": "text"
      },
      "source": [
        "## Handle the batching of images as in the paper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu4qVcRdn3vl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "9dbf3682-12b5-4c27-ff6b-f4153201bf44"
      },
      "source": [
        "@jit(nopython=True)\n",
        "def get_batch_moderate_random(batch_size,dataset, s=\"train\"):\n",
        "    \"\"\"\n",
        "    Create batch of APN triplets with a complete random strategy\n",
        "    \n",
        "    Arguments:\n",
        "    batch_size -- integer \n",
        "    Returns:\n",
        "    triplets -- list containing 3 tensors A,P,N of shape (batch_size,w,h,c), (batch_size,w,h,c,k), (batch_size,w,h,c,k,p)\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    m, w, h, c = dataset[0].shape\n",
        "   # print(m)\n",
        "    P = int(batch_size*3/4)\n",
        "    K = 4\n",
        "\n",
        "    k = 0\n",
        "    # initialize result\n",
        "    anchors =np.zeros((P*K, w, h, c))\n",
        "    positives = np.zeros((P*K, w, h, c, K))\n",
        "    negatives = np.zeros((P*K, w, h, c, K, P))\n",
        "    #negatives = np.zeros((P*K, P, K, h, w, c))\n",
        "    #print(\"PK =  \" + str(P*K))\n",
        "    \n",
        "    #Pick one random class for anchor\n",
        "    #print(\"nombre de classes : \" + str(count_label))\n",
        "    anchor_class = np.random.choice(count_label, size=P, replace=False)\n",
        "    #print(\"longueur anchoir_class : \"+str(len(anchor_class)))\n",
        "    for i in range(len(anchor_class)):\n",
        "\n",
        "      anchor = anchor_class[i]\n",
        "     # print(anchor)\n",
        "      nb_sample_available_for_class_A = dataset[anchor].shape[0]\n",
        "      \n",
        "      #Pick K different random pics for this class => A and P\n",
        "      idxAP = np.random.choice(nb_sample_available_for_class_A,size=K+1,replace=False)\n",
        "      #print(\"longueur idxAp : \"+str(len(idxAP)))\n",
        "\n",
        "\n",
        "      negative_class = [id for id in anchor_class if id != anchor]\n",
        "\n",
        "      for j in range(K):\n",
        "        idA = idxAP[j]\n",
        "        idPx = [id for id in idxAP if id != idA]\n",
        "        #print(i*K+j)\n",
        "        #print(\"valeur de i : \" + str(i))\n",
        "        #print(\"valeur de j : \" + str(j))\n",
        "        #print(\"longueur idPx \" + str(len(idPx)))\n",
        "        anchors[i*K+j,:,:,:] = dataset[anchor][idA,:,:,:]\n",
        "        \n",
        "        for k in range(len(idPx)):\n",
        "          idP = idPx[k]\n",
        "          #print(idP)\n",
        "          positives[i*K+j,:,:,:,k] = dataset[anchor][idP,:,:,:]\n",
        "\n",
        "        for l in range(len(negative_class)):\n",
        "            negative = negative_class[l]\n",
        "            nb_sample_available_for_class_N = dataset[negative].shape[0]\n",
        "            idxN = np.random.choice(nb_sample_available_for_class_N,size=K,replace=False)\n",
        "\n",
        "            for k in range(len(idxN)):\n",
        "              idN = idxN[k]\n",
        "              negatives[i*K+j,:,:,:,k,l] = dataset[negative][idN,:,:,:]\n",
        "          \n",
        "         # if(k>0):\n",
        "         #   print(positives[i*K+j,:,:,:,k]-positives[i*K+j,:,:,:,k-1])\n",
        "        \n",
        "        \n",
        "\n",
        "        #Pick K different random pics for this class => N\n",
        "          \n",
        "\n",
        "        #print(\"i : \" + str(i))\n",
        "        #print(\"l : \" + str(l))\n",
        "        #print(i*K+l)\n",
        "\n",
        "        #\n",
        "        \n",
        "          \n",
        "            #if(k>0):\n",
        "             # print(tf.subtract(negatives[i*K+l,:,:,:,k,j],negatives[i*K+l,:,:,:,k-1,j]))\n",
        "        \n",
        "        #Pick a random pic for this negative class => N\n",
        "    #print(\"affichage positives batch random moderate\")\n",
        "    #plt.figure()\n",
        "    #plt.imshow(positives[0,:,:,0,3])\n",
        "\n",
        "    \n",
        "\n",
        "    return anchors, positives, negatives\n",
        "\n",
        "tripletbatch = get_batch_moderate_random(batch_size=8, dataset = dataset)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6tISGvlgOHa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "be51aedf-ce20-4e0e-835b-2abfe039077f"
      },
      "source": [
        "\n",
        "\n",
        "model = build_network(input_shape,256)\n",
        "\n",
        "\n",
        "def get_batch_moderate(batch_size,network,dataset,s=\"train\"):\n",
        "    \"\"\"\n",
        "    Create batch of APN \"moderate\" triplets\n",
        "    \n",
        "    Arguments:\n",
        "    draw_batch_size -- integer : number of initial randomly taken samples   \n",
        "    hard_batchs_size -- interger : select the number of hardest samples to keep\n",
        "    norm_batchs_size -- interger : number of random samples to add\n",
        "    Returns:\n",
        "    \n",
        "    triplets -- list containing 3 tensors A,P,N of shape (hard_batchs_size+norm_batchs_size,w,h,c)\n",
        "    \"\"\"\n",
        "    if s == 'train':\n",
        "        X = dataset\n",
        "    else:\n",
        "        X = dataset\n",
        "\n",
        "    m, w, h,c = X[0].shape\n",
        "    \n",
        "    \n",
        "    #Step 1 : pick a random batch to study\n",
        "    studybatch = get_batch_moderate_random(batch_size,dataset,s)\n",
        "    \n",
        "    \n",
        "    #Compute embeddings for anchors, positive and negatives\n",
        "    A = network.predict(studybatch[0])\n",
        "    #print(A.shape)\n",
        "    P = np.zeros((A.shape[0], A.shape[1], studybatch[1].shape[4]))\n",
        "    N = np.zeros((A.shape[0], A.shape[1], studybatch[1].shape[4], studybatch[2].shape[5]))  \n",
        "\n",
        "\n",
        "    for i in range(studybatch[1].shape[4]):\n",
        "      P[:,:,i] = network.predict(studybatch[1][:,:,:,:,i])\n",
        "     # plt.figure()\n",
        "     # plt.imshow(np.squeeze(studybatch[1][0,:,:,:,i]))\n",
        "      #print(studybatch[1][:,:,:,:,i])\n",
        "      #if(i>0):\n",
        "       # print(\"Pi - Pi-1\")\n",
        "        #print(P[:,:,i] - P[:,:,i-1])\n",
        "      for j in range(studybatch[2].shape[5]):\n",
        "        N[:,:,i,j] = network.predict(studybatch[2][:,:,:,:,i,j])\n",
        "        #if(i>0):\n",
        "         # print(\"Ni,j - Ni-1,j\")\n",
        "          #print(N[:,:,i,j] - N[:,:,i-1,j])\n",
        "\n",
        "    \n",
        "    ### Extraction des indices des distances maximales\n",
        "    \n",
        "    A = tf.expand_dims(A, axis = -1)\n",
        "    #print(A)\n",
        "    #print(P)\n",
        "    dist_p = tf.math.subtract(A,P)\n",
        "    #print(dist_p)\n",
        "    dist_p = tf.norm(tf.math.subtract(A,P),axis = -2)\n",
        "    #print(dist_p)\n",
        "    selectionAP = tf.math.argmax(tf.norm(A - P,axis = -2), axis = -1)\n",
        "    #print(selectionAP)\n",
        "   # print(selectionAP.shape)\n",
        "    #dist_p = tf.dtypes.cast(dist_p, tf.double)\n",
        "\n",
        "    \n",
        "    sub = np.zeros((A.shape[0], A.shape[1], studybatch[1].shape[4], studybatch[2].shape[5]))    \n",
        "    for i in range(N.shape[3]):\n",
        "      #print(A.shape)\n",
        "      #print(tf.math.subtract(N[:,:,i+1,i],N[:,:,i,i]))\n",
        "      sub[:,:,:,i] = tf.math.subtract(A,N[:,:,:,i])\n",
        "      #print(sub[:,:,:,i])\n",
        "    #A = tf.expand_dims(A, axis = -1)\n",
        "    #print(sub)\n",
        "    n_dist = tf.norm(sub,axis = 1)\n",
        "    #print(n_dist)\n",
        "    n_dist = tf.reduce_min(n_dist, axis = -2)\n",
        "    #print(\"n_dist\")\n",
        "    #print(n_dist)\n",
        "    selectionN = np.argmin(n_dist, axis = -1)\n",
        "    #print(\"selectionN\")\n",
        "    #print(selectionN)\n",
        "   # print(selectionN.shape)\n",
        "    AN = tf.norm(sub,axis = -3)\n",
        "    #print(\"AN\")\n",
        "    #print(AN)\n",
        "\n",
        "    selectionPN = np.zeros((AN.shape[0]),dtype=np.int8)\n",
        "    for i in range(AN.shape[0]):\n",
        "      #print(AN[i,:,selectionN[i]])\n",
        "      selectionPN[i] = np.argmin(AN[i,:,selectionN[i]])\n",
        "      \n",
        "      #print(selectionPN[i])\n",
        "   # print(\"selectionPN\")\n",
        "    #print(selectionPN)\n",
        "    #n_dist = tf.dtypes.cast(n_dist, tf.double)\n",
        "    batch_size = studybatch[2][:,0,0,0,0,0].shape[0]\n",
        "   # print(batch_size)\n",
        "    width = studybatch[2][0,:,0,0,0,0].shape[0]\n",
        "   # print(width)\n",
        "    height = studybatch[2][0,0,:,0,0,0].shape[0]\n",
        "   # print(height)\n",
        "    channels = studybatch[2][0,0,0,:,0,0].shape[0]\n",
        "   # print(channels)\n",
        "    K = studybatch[2][0,0,0,0,:,0].shape[0]\n",
        "   # print(K)\n",
        "    N = studybatch[2][0,0,0,0,0,:].shape[0]\n",
        "   # print(N)\n",
        "\n",
        "    ### Création des tenseurs contenant les images sélectionnées de telles sortes à maximiser les distances AP et à minimiser les distances AN\n",
        "    positives = tf.zeros((batch_size,width,height,channels))\n",
        "    negatives = tf.zeros((batch_size,width,height,channels))\n",
        "\n",
        "    #print(selectionPN)\n",
        "    #print(selectionN)\n",
        "    \n",
        "    #print(P.shape)\n",
        "    #print(N.shape)\n",
        "\n",
        "    \n",
        "    for i in range(studybatch[2][:,0,0,0,0,0].shape[0]):\n",
        "      positives = studybatch[1][:,:,:,:,selectionAP[i]]\n",
        "      #positives = np.squeeze(positives)\n",
        "      #print(positives)\n",
        "      #print(positives.shape)\n",
        "      negatives = studybatch[2][:,:,:,:,selectionPN[i],selectionN[i]]\n",
        "      #negatives = np.squeeze(negatives)\n",
        "      #print(negatives.shape)\n",
        "\n",
        "    #print(positives[0,:,:,0])\n",
        "    #print(negatives[0,:,:,0])\n",
        "    #print(positives[0,:,:,:])\n",
        "    #print(negatives[0,:,:,:])\n",
        "    #plt.figure()\n",
        "    #plt.imshow(positives[0,:,:,0])\n",
        "    #plt.figure()\n",
        "    #plt.imshow(negatives[0,:,:,0])\n",
        "\n",
        "    #studybatchloss = tf.math.reduce_sum(tf.math.log1p(tf.math.subtract(p_dist,n_dist)))\n",
        "    #studybatchloss = tf.dtypes.cast(studybatchloss, tf.float32)\n",
        "\n",
        "    triplets = [studybatch[0][:,:,:,:], positives, negatives]\n",
        "\n",
        "    #print(NMin.shape)\n",
        "\n",
        "    #Compute d(A,P)-d(A,N)\n",
        "    #studybatchloss = np.sum(np.square(A-P),axis=1) - np.sum(np.square(A-N),axis=1)\n",
        "    \n",
        "    #Sort by distance (high distance first) and take the inverse\n",
        "    #selection = np.argsort(studybatchloss)[::-1][:hard_batchs_size]\n",
        "    \n",
        "    #Draw other random samples from the batch\n",
        "    #selection2 = np.random.choice(np.delete(np.arange(draw_batch_size),selection),norm_batchs_size,replace=False)\n",
        "    \n",
        "    #selection = np.append(selection,selection2)\n",
        "    \n",
        "    #triplets = [A,P,N]\n",
        "    #print(triplets.shape)\n",
        "    return triplets\n",
        "\n",
        "tripletbatch = get_batch_moderate(8, model, dataset)\n",
        "def drawTriplets(tripletbatch, nbmax=None):\n",
        "    \"\"\"display the three images for each triplets in the batch\n",
        "    \"\"\"\n",
        "    labels = [\"Anchor\", \"Positive\", \"Negative\"]\n",
        "\n",
        "    if (nbmax==None):\n",
        "        nbrows = tripletbatch[0].shape[0]\n",
        "    else:\n",
        "        nbrows = min(nbmax,tripletbatch[0].shape[0])\n",
        "                 \n",
        "    for row in range(nbrows):\n",
        "        fig=plt.figure(figsize=(16,2))\n",
        "    \n",
        "        for i in range(3):\n",
        "            subplot = fig.add_subplot(1,3,i+1)\n",
        "            plt.axis(\"off\")\n",
        "            triplet = tripletbatch[i][row,:,:,:]\n",
        "\n",
        "            plt.imshow(triplet)\n",
        "            subplot.title.set_text(labels[i])\n",
        "\n",
        "drawTriplets(tripletbatch=tripletbatch)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odl70AfJKYWm",
        "colab_type": "text"
      },
      "source": [
        "## Triplet loss layer computing the formula introduced in the paper\n",
        "\n",
        "**Euclidean distance is used**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHCim9oWNVGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class TripletLossLayerModerate(layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        #self.alpha = alpha\n",
        "        super(TripletLossLayerModerate, self).__init__(**kwargs)\n",
        "    \n",
        "    def triplet_loss(self, inputs):\n",
        "        A, P, N = inputs\n",
        "        \n",
        "        p_dist = tf.norm(A - P,axis = -1)\n",
        "        n_dist = tf.norm(A - N,axis = -1)\n",
        "        \n",
        "        #tripletLoss = tf.math.reduce_sum(tf.math.add(self.alpha,tf.math.subtract(p_dist,n_dist)))\n",
        "\n",
        "        #Utilisation de la formule de batch_hard du papier avec marge douce\n",
        "        tripletLoss = tf.math.reduce_sum(tf.math.log1p(tf.math.exp(tf.math.subtract(p_dist,n_dist))))\n",
        "        tripletLoss = tf.dtypes.cast(tripletLoss, tf.float32)\n",
        "        #tripletLoss = backend.sum(backend.maximum(p_dist - n_dist + self.alpha, 0), axis=0)\n",
        "        return(tripletLoss)\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        loss = self.triplet_loss(inputs)\n",
        "        self.add_loss(loss)\n",
        "        return loss\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcipcbbEFGm-",
        "colab_type": "text"
      },
      "source": [
        "## Concatenate three instances of the same neural network representing the anchors, the positives and the negatives necessary for the triplet loss embedding algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjOZEAhBVprX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model_moderate(input_shape, network, margin = 0.2):\n",
        "    '''\n",
        "    Define the Keras Model for training \n",
        "        Input : \n",
        "            input_shape : shape of input images\n",
        "            network : Neural network to train outputing embeddings\n",
        "            margin : minimal distance between Anchor-Positive and Anchor-Negative for the lossfunction (alpha)\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    \n",
        "     # Define the tensors for the three input images\n",
        "    anchor_input = Input(input_shape, name=\"anchor_input\")\n",
        "    positive_input = Input(input_shape, name=\"positive_input\")\n",
        "    negative_input = Input(input_shape, name=\"negative_input\") \n",
        "    \n",
        "    # Generate the encodings (feature vectors) for the three images\n",
        "    encoded_a = network(anchor_input)\n",
        "    encoded_p = network(positive_input)\n",
        "    encoded_n = network(negative_input)\n",
        "    \n",
        "    #TripletLoss Layer\n",
        "    #loss_layer = TripletLossLayerModerate(alpha = margin, name='triplet_loss_layer')([encoded_a,encoded_p,encoded_n])\n",
        "    loss_layer = TripletLossLayerModerate(name='triplet_loss_layer')([encoded_a,encoded_p,encoded_n])\n",
        "    \n",
        "    # Connect the inputs with the outputs\n",
        "    network_train = Model(inputs=[anchor_input,positive_input,negative_input],outputs=loss_layer)\n",
        "    \n",
        "    # return the model\n",
        "    return network_train\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxovgnSqGIc6",
        "colab_type": "text"
      },
      "source": [
        "## Define metrics to evaluate the performances of the neural networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiUi9E6C5uai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_dist(a,b):\n",
        "    return np.sum(np.square(a-b))\n",
        "#count_label = len(dataset)\n",
        "\n",
        "def mean_average_precision(X,Y,network,rank):\n",
        "    '''\n",
        "    Returns\n",
        "        MAP : the mean of the average precision of the model for each images of the dataset\n",
        "    '''\n",
        "    nb_classes = count_label\n",
        "    print(nb_classes)\n",
        "    m = X.shape[0]\n",
        "    #nbtrain = 10\n",
        "    nbevaluation = 30\n",
        "    probs = np.zeros((nbevaluation))\n",
        "    distances = np.zeros((nbevaluation,nb_classes))\n",
        "    ypreds = np.zeros((nbevaluation,nb_classes))\n",
        "    y = np.zeros((nbevaluation))\n",
        "\n",
        "    \n",
        "    #Compute all embeddings for all pics with current network\n",
        "    embeddings = network.predict(X)\n",
        "    \n",
        "    size_embedding = embeddings.shape[1]\n",
        "\n",
        "    ref_images = np.zeros((nb_classes,size_embedding))\n",
        "    \n",
        "    #generates embeddings for reference images\n",
        "    for i in range(nb_classes):\n",
        "          #print(dataset_train[i][:,0,0,1])\n",
        "          #idx_ref = np.random.choice(dataset_train[i][:,0,0,1],size=200,replace=False)\n",
        "          #print(idx_ref)\n",
        "          #print(len(dataset_train[i][0]))\n",
        "          #print(np.take(dataset_train[, idx_ref))\n",
        "          selected_ref = dataset[i][:,:,:,:]\n",
        "          #print(selected_ref.shape)\n",
        "          #print(np.max(selected_ref))\n",
        "          ref_images[i,:] = np.mean(network.predict(selected_ref),axis=0)\n",
        "          #print(ref_images[i,:].shape)\n",
        "    #print(np.mean(network.predict(selected_ref),axis=0).shape)\n",
        "    \n",
        "    test = compute_dist(ref_images[0,:],network.predict(np.expand_dims(dataset[15][0,:,:,:], axis=0)))\n",
        "    print(test)\n",
        "    for j in range(nbevaluation):\n",
        "          print(j)\n",
        "          for k in range(nb_classes):\n",
        "              #print(X[j,:,:,:].shape)\n",
        "              #print(np.max(ref_images[k,:]))\n",
        "              distances[j,k] = compute_dist(ref_images[k,:],network.predict(np.expand_dims(X[j,:,:,:], axis=0)))\n",
        "              #print(distances[j,k])\n",
        "          #print(distances[j,:])\n",
        "    #for i in range(nb_classes):\n",
        "     #for k in range(nb_classes):\n",
        "      #for j in range(nbevaluation):\n",
        "              #print(X[j,:,:,:].shape)\n",
        "       #       distances[j,k] = compute_dist(ref_images[i,:],network.predict(np.expand_dims(dataset[k][j,:,:,:], axis=0)))\n",
        "        #      print(distances[j,k])\n",
        "          #print(distances[j,:])\n",
        "    #print(\"affichage des distances triées selon l'axe des classes\")\n",
        "    ypreds = np.argsort(distances,axis=-1)\n",
        "    #print(ypreds[0])\n",
        "    #print(\"affichage des distances triées selon l'axe des classes\")\n",
        "    #ypreds = np.flip(ypreds,axis = -1)\n",
        "    #print(ypreds[0])\n",
        "    ytrue = Y[:nbevaluation]\n",
        "    #print(ytrue)\n",
        "\n",
        "    AP = 0\n",
        "    #print(len(ytrue))\n",
        "    \n",
        "    for i in range(len(ytrue)):\n",
        "      #print(ypreds[i,:rank])\n",
        "      #print(ytrue[i])\n",
        "      print(ytrue)\n",
        "      print(ypreds[i,0])\n",
        "      for k in range(rank):\n",
        "        \n",
        "        if(ytrue[i] == ypreds[i,k]):\n",
        "          AP += 1/(k+1)\n",
        "    \n",
        "    MAP = AP/len(ytrue)\n",
        "    print(MAP)\n",
        "    return MAP\n",
        "\n",
        "def cumulative_matching_curve(X,Y,network,rank):\n",
        "  \n",
        "    '''\n",
        "    Returns\n",
        "        CMC : \n",
        "    '''\n",
        "    nb_classes = count_label\n",
        "    m = X.shape[0]\n",
        "    nbtrain = 1000\n",
        "    nbevaluation = 50\n",
        "    probs = np.zeros((nbevaluation))\n",
        "    distances = np.zeros((nbevaluation,nb_classes))\n",
        "    ypreds = np.zeros((nbevaluation,nb_classes))\n",
        "    y = np.zeros((nbevaluation))\n",
        "\n",
        "    \n",
        "    #Compute all embeddings for all pics with current network\n",
        "    embeddings = network.predict(X)\n",
        "    \n",
        "    size_embedding = embeddings.shape[1]\n",
        "\n",
        "    ref_images = np.zeros((nb_classes,size_embedding))\n",
        "    \n",
        "    #generates embeddings for reference images\n",
        "    for i in range(nb_classes):\n",
        "          #print(dataset_train[i][:,0,0,1])\n",
        "          #idx_ref = np.random.choice(dataset_train[i][:,0,0,1],size=200,replace=False)\n",
        "          #print(idx_ref)\n",
        "          #print(len(dataset_train[i][0]))\n",
        "          #print(np.take(dataset_train[, idx_ref))\n",
        "          selected_ref = dataset[i][:nbtrain,:,:,:]\n",
        "          #print(selected_ref.shape)\n",
        "          ref_images[i,:] = np.mean(network.predict(selected_ref),axis=0)\n",
        "          #print(ref_images[i,:].shape)\n",
        "    #print(np.mean(network.predict(selected_ref),axis=0).shape)\n",
        "    \n",
        "    test = compute_dist(ref_images[0,:],network.predict(np.expand_dims(dataset[15][0,:,:,:], axis=0)))\n",
        "    print(test)\n",
        "    for j in range(nbevaluation):\n",
        "          print(j)\n",
        "          for k in range(nb_classes):\n",
        "              #print(X[j,:,:,:].shape)\n",
        "              distances[j,k] = compute_dist(ref_images[k,:],network.predict(np.expand_dims(X[j,:,:,:]/255, axis=0)))\n",
        "              #print(distances[j,k])\n",
        "          #print(distances[j,:])\n",
        "    #for i in range(nb_classes):\n",
        "     #for k in range(nb_classes):\n",
        "      #for j in range(nbevaluation):\n",
        "              #print(X[j,:,:,:].shape)\n",
        "       #       distances[j,k] = compute_dist(ref_images[i,:],network.predict(np.expand_dims(dataset[k][j,:,:,:], axis=0)))\n",
        "        #      print(distances[j,k])\n",
        "          #print(distances[j,:])\n",
        "    #print(\"affichage des distances triées selon l'axe des classes\")\n",
        "    ypreds = np.argsort(distances,axis=-1)\n",
        "    #print(ypreds[0])\n",
        "    #print(\"affichage des distances triées selon l'axe des classes\")\n",
        "    #ypreds = np.flip(ypreds,axis = -1)\n",
        "    #print(ypreds[0])\n",
        "    ytrue = Y[:nbevaluation]\n",
        "    #print(ytrue)\n",
        "\n",
        "    present = 0\n",
        "    #print(len(ytrue))\n",
        "    \n",
        "    for i in range(len(ytrue)):\n",
        "      #print(ypreds[i,:rank])\n",
        "      #print(ytrue[i])\n",
        "      for k in range(rank):\n",
        "        #print(ytrue)\n",
        "        #print(ypreds[i,k])\n",
        "        if(ytrue[i] == ypreds[i,k]):\n",
        "          present += 1\n",
        "    \n",
        "    CMC = present/len(ytrue)\n",
        "    print(CMC)\n",
        "    return CMC\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "def compute_interdist(network):\n",
        "    '''\n",
        "    Computes sum of distances between all classes embeddings on our reference test image: \n",
        "        d(0,1) + d(0,2) + ... + d(0,9) + d(1,2) + d(1,3) + ... d(8,9)\n",
        "        A good model should have a large distance between all theses embeddings\n",
        "        \n",
        "    Returns:\n",
        "        array of shape (nb_classes,nb_classes) \n",
        "    '''\n",
        "    nb_classes = count_label\n",
        "    res = np.zeros((nb_classes,nb_classes))\n",
        "    \n",
        "    ref_images = np.zeros((nb_classes,28,28,3))\n",
        "    \n",
        "    #generates embeddings for reference images\n",
        "    for i in range(nb_classes):\n",
        "        ref_images[i,:,:,:] = dataset[i][0,:,:,:]\n",
        "    ref_embeddings = network.predict(ref_images)\n",
        "    \n",
        "    for i in range(nb_classes):\n",
        "        for j in range(nb_classes):\n",
        "            res[i,j] = compute_dist(ref_embeddings[i],ref_embeddings[j])\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDE1FPHEBQBD",
        "colab_type": "text"
      },
      "source": [
        "# Training the network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZQfVqriKAus",
        "colab_type": "text"
      },
      "source": [
        "## Transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHSKIgCSGcAm",
        "colab_type": "text"
      },
      "source": [
        "### Use the ResNet50 architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgJ1IdY52Pgw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2f451bbe-a72b-411a-b9e8-db83508e85ff"
      },
      "source": [
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "\n",
        "base_model = tf.keras.applications.ResNet50(input_shape=input_shape,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw6wyqGc_Ljl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6aa901cd-58f8-4eb3-be87-a7fb8f58937c"
      },
      "source": [
        "feature = base_model(tf.expand_dims(image, 0))\n",
        "print(feature.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5qHh1DYBu9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrPzQa2zBxc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's take a look at the base model architecture\n",
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uII5yDNeCQMa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "fabe97c8-c5c6-4e79-c4cd-3a87ae071118"
      },
      "source": [
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "feature_averaged = global_average_layer(feature)\n",
        "print(feature_averaged.shape)\n",
        "\n",
        "embedding_layer = tf.keras.layers.Dense(512)\n",
        "normalization = tf.keras.layers.BatchNormalization()\n",
        "relu = tf.keras.layers.ReLU()\n",
        "embedding = embedding_layer(feature_averaged)\n",
        "print(embedding.shape)\n",
        "\n",
        "embedding_layer2 = tf.keras.layers.Dense(64)\n",
        "embedding2 = embedding_layer2(embedding)\n",
        "print(embedding2.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgFwooj3D0_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  global_average_layer,\n",
        "  embedding_layer,\n",
        "  normalization,\n",
        "  relu,\n",
        "  embedding_layer2\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fonCkzUINhG",
        "colab_type": "text"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB5Hh76QgZN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "#embedding_size = 256\n",
        "tf.keras.backend.clear_session()\n",
        "#model = build_network(input_shape,embedding_size)\n",
        "model_trained = build_model_moderate(input_shape, model)\n",
        "\n",
        "model_trained.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005))\n",
        "\n",
        "n_iter = 3000\n",
        "t_stop = 0\n",
        "iter_stop = 0\n",
        "#inter_dist = compute_interdist(model)\n",
        "#print(inter_dist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tN654cF5cIo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "adef6802-f3d2-47f6-882a-584b2875a672"
      },
      "source": [
        "\n",
        "\n",
        "#model_trained.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, amsgrad=False))\n",
        "\n",
        "\n",
        "if (iter_stop != 0):\n",
        "  n_iteration = iter_stop\n",
        "else:\n",
        "  n_iteration = 0\n",
        "\n",
        "evaluate_every = 10\n",
        "n_val = 1000\n",
        "print(\"Starting training process!\")\n",
        "print(\"-------------------------------------\")\n",
        "\n",
        "t_start = time.time()\n",
        "\n",
        "if (t_stop != 0):\n",
        "  t_start = t_stop\n",
        "\n",
        "distribution = np.zeros((10,3))\n",
        "\n",
        "plt.figure()\n",
        "for i in range(1, n_iter+1):\n",
        "    triplets = get_batch_moderate(50,model,dataset)\n",
        "    #triplets = get_batch_hard(32,16,16,model)\n",
        "    \n",
        "    #print(triplets.shape)\n",
        "    loss = model_trained.train_on_batch(triplets, None)\n",
        "    n_iteration += 1\n",
        "    t_stop = time.time()\n",
        "    iter_stop = n_iteration\n",
        "\n",
        "    if i % evaluate_every == 0:\n",
        "        print(\"\\n ------------- \\n\")\n",
        "        print(\"[{3}] Time for {0} iterations: {1:.1f} mins, Train Loss: {2}\".format(i, (time.time()-t_start)/60.0,np.nan_to_num(loss),n_iteration))\n",
        "        \n",
        "       # inter_dist = compute_interdist(model)\n",
        "       # print(inter_dist)\n",
        "\n",
        "        #MAP = mean_average_precision(x_train,y_train,model,1)\n",
        "        #CMC = cumulative_matching_curve(x_test_origin,y_test_origin,model,5)\n",
        "        #print(\"Mean Average Precision\" + str(MAP))\n",
        "        #print(\"Cumulative Matching Curve = \" + str(CMC))\n",
        "        #probs,yprob = compute_probs(model,x_test_origin[:n_val,:,:,:],y_test_origin[:n_val])\n",
        "        #fpr, tpr, thresholds,auc = compute_metrics(probs, yprob)\n",
        "        #model.predict(x_test_origin[:n_val,:,:,:])\n",
        "        #plt.plot(fpr,tpr)\n",
        "       # res = compute_interdist(model)\n",
        "       # print(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlT-F8wb77xJ",
        "colab_type": "text"
      },
      "source": [
        "### Fine-tune after training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gg8k2Prm77XX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFVW65-H7_t4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d5bef0e-2d28-4627-a185-36dba814b6d7"
      },
      "source": [
        "# Let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 100\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable =  False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAW8JSebKlvn",
        "colab_type": "text"
      },
      "source": [
        "### Continue to train the network "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g5HgtdAKK024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "adef6802-f3d2-47f6-882a-584b2875a672"
      },
      "source": [
        "\n",
        "\n",
        "#model_trained.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, amsgrad=False))\n",
        "\n",
        "\n",
        "if (iter_stop != 0):\n",
        "  n_iteration = iter_stop\n",
        "else:\n",
        "  n_iteration = 0\n",
        "\n",
        "evaluate_every = 10\n",
        "n_val = 1000\n",
        "print(\"Starting training process!\")\n",
        "print(\"-------------------------------------\")\n",
        "\n",
        "t_start = time.time()\n",
        "\n",
        "if (t_stop != 0):\n",
        "  t_start = t_stop\n",
        "\n",
        "distribution = np.zeros((10,3))\n",
        "\n",
        "plt.figure()\n",
        "for i in range(1, n_iter+1):\n",
        "    triplets = get_batch_moderate(50,model,dataset)\n",
        "    #triplets = get_batch_hard(32,16,16,model)\n",
        "    \n",
        "    #print(triplets.shape)\n",
        "    loss = model_trained.train_on_batch(triplets, None)\n",
        "    n_iteration += 1\n",
        "    t_stop = time.time()\n",
        "    iter_stop = n_iteration\n",
        "\n",
        "    if i % evaluate_every == 0:\n",
        "        print(\"\\n ------------- \\n\")\n",
        "        print(\"[{3}] Time for {0} iterations: {1:.1f} mins, Train Loss: {2}\".format(i, (time.time()-t_start)/60.0,np.nan_to_num(loss),n_iteration))\n",
        "        \n",
        "       # inter_dist = compute_interdist(model)\n",
        "       # print(inter_dist)\n",
        "\n",
        "        #MAP = mean_average_precision(x_train,y_train,model,1)\n",
        "        #CMC = cumulative_matching_curve(x_test_origin,y_test_origin,model,5)\n",
        "        #print(\"Mean Average Precision\" + str(MAP))\n",
        "        #print(\"Cumulative Matching Curve = \" + str(CMC))\n",
        "        #probs,yprob = compute_probs(model,x_test_origin[:n_val,:,:,:],y_test_origin[:n_val])\n",
        "        #fpr, tpr, thresholds,auc = compute_metrics(probs, yprob)\n",
        "        #model.predict(x_test_origin[:n_val,:,:,:])\n",
        "        #plt.plot(fpr,tpr)\n",
        "       # res = compute_interdist(model)\n",
        "       # print(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSclALPqCmFR",
        "colab_type": "text"
      },
      "source": [
        "## Training from scratch with a 3-layered CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuu-PKJrK3sd",
        "colab_type": "text"
      },
      "source": [
        "### Define the architecture and train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "plGXK4CXC0zB",
        "colab": {}
      },
      "source": [
        "import time\n",
        "embedding_size = 128\n",
        "tf.keras.backend.clear_session()\n",
        "model = build_network(input_shape,embedding_size)\n",
        "model_trained = build_model_moderate(input_shape, model)\n",
        "\n",
        "model_trained.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005))\n",
        "\n",
        "n_iter = 600\n",
        "t_stop = 0\n",
        "iter_stop = 0\n",
        "#inter_dist = compute_interdist(model)\n",
        "#print(inter_dist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oxRAzMwIC0zE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "803889c2-9eec-4a59-abab-66025d009b07"
      },
      "source": [
        "\n",
        "\n",
        "#model_trained.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, amsgrad=False))\n",
        "\n",
        "\n",
        "if (iter_stop != 0):\n",
        "  n_iteration = iter_stop\n",
        "else:\n",
        "  n_iteration = 0\n",
        "\n",
        "evaluate_every = 10\n",
        "n_val = 1000\n",
        "print(\"Starting training process!\")\n",
        "print(\"-------------------------------------\")\n",
        "\n",
        "t_start = time.time()\n",
        "\n",
        "if (t_stop != 0):\n",
        "  t_start = t_stop\n",
        "\n",
        "\n",
        "for i in range(1, n_iter+1):\n",
        "    triplets = get_batch_moderate(14,model,dataset)\n",
        "    #triplets = get_batch_hard(32,16,16,model)\n",
        "    \n",
        "    #print(triplets.shape)\n",
        "    loss = model_trained.train_on_batch(triplets, None)\n",
        "    n_iteration += 1\n",
        "    t_stop = time.time()\n",
        "    iter_stop = n_iteration\n",
        "\n",
        "    if i % evaluate_every == 0:\n",
        "        print(\"\\n ------------- \\n\")\n",
        "        print(\"[{3}] Time for {0} iterations: {1:.1f} mins, Train Loss: {2}\".format(i, (time.time()-t_start)/60.0,np.nan_to_num(loss),n_iteration))\n",
        "        \n",
        "       # inter_dist = compute_interdist(model)\n",
        "       # print(inter_dist)\n",
        "\n",
        "        #MAP = mean_average_precision(x_train,y_train,model,1)\n",
        "        #CMC = cumulative_matching_curve(x_test_origin,y_test_origin,model,5)\n",
        "        #print(\"Mean Average Precision\" + str(MAP))\n",
        "        #print(\"Cumulative Matching Curve = \" + str(CMC))\n",
        "        #probs,yprob = compute_probs(model,x_test_origin[:n_val,:,:,:],y_test_origin[:n_val])\n",
        "        #fpr, tpr, thresholds,auc = compute_metrics(probs, yprob)\n",
        "        #model.predict(x_test_origin[:n_val,:,:,:])\n",
        "        #plt.plot(fpr,tpr)\n",
        "       # res = compute_interdist(model)\n",
        "       # print(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KkUHPlb5yxp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4f0ff23-aa2b-437a-9d52-2e9e6a4b0d91"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('saved_cnn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx7pDTxk-mAC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "4226d49a-d793-4bc3-c1bd-5940e94c2d44"
      },
      "source": [
        "import io\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "results = model.predict(x_test)\n",
        "# Save test embeddings for visualization in projector\n",
        "np.savetxt(\"vecs.tsv\", results, delimiter='\\t')\n",
        "\n",
        "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
        "for labels in y_test:\n",
        "    out_m.write(str(labels) + \"\\n\")\n",
        "out_m.close()\n",
        "\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('vecs.tsv')\n",
        "  files.download('meta.tsv')\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-OYloogutdG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "44326d26-c837-437a-ecf3-a92d5e088577"
      },
      "source": [
        "!rm -rf /content/saved_cnn\n",
        "!rm -rf /content/saved_model_triplet\n",
        "# Save the entire model as a SavedModel.\n",
        "!mkdir -p saved_model_triplet\n",
        "!mkdir -p saved_cnn\n",
        "model_trained.save('saved_model_triplet') \n",
        "model.save('saved_cnn') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpivJRREkgZE",
        "colab_type": "text"
      },
      "source": [
        "# Clustering embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2UhhQectKGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import umap\n",
        "import hdbscan\n",
        "import sklearn.cluster as cluster\n",
        "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM3X5M18kjV4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "outputId": "9f4eda8e-1ee8-4e7d-8968-6ad523d4215b"
      },
      "source": [
        "from tensorflow.keras.models import load_model, save_model\n",
        "\n",
        "model = load_model('/content/saved_cnn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QkEMjQXBvoHx",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "#width = 56\n",
        "#height = 56\n",
        "\n",
        "train_path = '/content/ds_final_unet_lite/content/ds_final/train'\n",
        "test_path = '/content/ds_final_unet_lite/content/ds_final/test'\n",
        "\n",
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  print(parts[-2])\n",
        "  # The second to last is the class-directory\n",
        "  return parts[-2] == CLASS_NAMES\n",
        "\n",
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
        "  #img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  # resize the image to the desired size.\n",
        "  return img\n",
        "\n",
        "def process_path(file_path):\n",
        "  #print(file_path)\n",
        "  label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  try:\n",
        "    img = decode_img(img)\n",
        "    #print(np.max(img))\n",
        "    print(\"decoded\")\n",
        "    counter +=1\n",
        "  except:\n",
        "    print(\"erreur décodage\")\n",
        "\n",
        "  return img, label\n",
        "\n",
        "def format_image(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image = (image/127.5) - 1\n",
        "  image = tf.image.resize(image, (input_shape[0], input_shape[1]))\n",
        "  return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BCGXfAHhvoH5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "3674e957-dda3-44ee-db39-25641d2a0e73"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "#train_path = '/content/ds_final/train'\n",
        "#test_path = '/content/ds_final/test'\n",
        "\n",
        "train_size = sum(len(files) for _, _, files in os.walk(train_path))\n",
        "print(train_size)\n",
        "test_size = sum(len(files) for _, _, files in os.walk(test_path))\n",
        "print(test_size)\n",
        "\n",
        "#BATCH_SIZE = 32\n",
        "#input_shape = (50,35,3)\n",
        "#data_dir = \"/content/male\"\n",
        "input_shape = (75,30,3)\n",
        "\n",
        "\n",
        "\n",
        "data_dir = pathlib.Path(train_path)\n",
        "test_dir = pathlib.Path(test_path)\n",
        "\n",
        "list_ds = tf.data.Dataset.list_files(str(data_dir)+'/*/*')\n",
        "list_ds_test = tf.data.Dataset.list_files(str(test_dir)+'/*/*')\n",
        "\n",
        "CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"])\n",
        "#print(type(CLASS_NAMES))\n",
        "print(CLASS_NAMES)\n",
        "\n",
        "CLASS_NAMES = np.array([item.name for item in test_dir.glob('*') if item.name != \"LICENSE.txt\"])\n",
        "#print(type(CLASS_NAMES))\n",
        "print(CLASS_NAMES)\n",
        "#for f in list_ds.take(5):\n",
        "  #print(f.numpy())\n",
        "#counter = 0\n",
        "\n",
        "def show_batch(image_batch, label_batch):\n",
        "  plt.figure(figsize=(10,10))\n",
        "  for n in range(25):\n",
        "      ax = plt.subplot(5,5,n+1)\n",
        "      plt.imshow(image_batch[n])\n",
        "      plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n",
        "      plt.axis('off')\n",
        "\n",
        "def augment(image,label):\n",
        "  #image,label = convert(image, label)\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32) # Cast and normalize the image to [0,1]\n",
        "  #image = tf.image.rgb_to_grayscale(image)\n",
        "  #image = tf.image.resize_with_crop_or_pad(image, 34, 34) # Add 6 pixels of padding\n",
        "  #image = tf.image.random_crop(image, size=[28, 28, 1]) # Random crop back to 28x28\n",
        "  #image = tf.image.random_brightness(image, max_delta=0.5) # Random brightness\n",
        "  #image = tf.image.flip_left_right(image)\n",
        "\n",
        "  return image,label\n",
        "#Use Dataset.map to create a dataset of image, label pairs:\n",
        "\n",
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "labeled_ds_test = list_ds_test.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "#train_size = int(0.7 * nbr_element)\n",
        "\n",
        "#val_size = int(0.30 * nbr_element)\n",
        "#test_size = int(0.15 * DATASET_SIZE)\n",
        "\n",
        "\n",
        "#full_dataset = labeled_ds.shuffle()\n",
        "#train_dataset = labeled_ds.take(train_size)\n",
        "#test_dataset = labeled_ds.skip(train_size)\n",
        "#val_dataset = test_dataset.skip(test_size)\n",
        "#test_dataset = test_dataset.take(val_size)\n",
        "\n",
        "train_dataset = labeled_ds.map(format_image, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "test_dataset = labeled_ds_test.map(format_image, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "count_label = len(os.listdir(train_path))\n",
        "#print(count_label)\n",
        "\n",
        "x_train = np.zeros((train_size,input_shape[0],input_shape[1],input_shape[2]))\n",
        "y_train = np.zeros((train_size))\n",
        "x_test = np.zeros((test_size,input_shape[0],input_shape[1],input_shape[2]))\n",
        "y_test = np.zeros((test_size))\n",
        "\n",
        "k=0\n",
        "for image, label in train_dataset:\n",
        "  #print(label)\n",
        "  x_train[k,:,:,:] = image\n",
        "  y_train[k] = np.where(label)[0][0]\n",
        "  k += 1\n",
        "k=0\n",
        "for image, label in test_dataset:\n",
        "  x_test[k,:,:,:] = image\n",
        "  y_test[k] = np.where(label)[0][0]\n",
        "  k += 1\n",
        "  #print(np.where(label)[0])\n",
        "\n",
        "#tfds_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "#tfds_train = tfds_train.batch(32)\n",
        "#for i,j in tfds_train:\n",
        " # print(i)\n",
        "  #print(j)\n",
        "#tfds_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "#tfds_test = tfds_test.batch(32)\n",
        "  #print(\"Image shape: \", image.numpy().shape)\n",
        "  #print(\"Label: \", label.numpy())\n",
        "#print(y_train)\n",
        "dataset = []\n",
        "dataset_test = []\n",
        "    \n",
        "#Sorting images by classes and normalize values 0=>\n",
        "for n in range(count_label):\n",
        "    images_class_n_train = np.asarray([row for idx,row in enumerate(x_train) if y_train[idx]==n])\n",
        "    dataset.append(images_class_n_train)\n",
        "\n",
        "\n",
        "    images_class_n_test = np.asarray([row for idx,row in enumerate(x_test) if y_test[idx]==n])\n",
        "    dataset_test.append(images_class_n_test)\n",
        "\n",
        "  \n",
        "print(\"nombre de classes différentes : \"+ str(count_label))\n",
        "#for n in range(int(count_label*0.30)):\n",
        " #   images_class_n = np.asarray([row for idx,row in enumerate(x_test) if y_test[idx]==n])\n",
        "    #print(images_class_n.shape)\n",
        "  #  dataset_test.append(images_class_n/255)\n",
        "        \n",
        "    #images_class_n = np.asarray([row for idx,row in enumerate(x_test_origin) if y_test_origin[idx]==n])\n",
        "    #dataset_test.append(images_class_n/255)\n",
        "#input_shape = [width,height,3]\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aOiTTDurzX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding = model.predict(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfccaPVEr-9R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ade942c4-814d-4b58-c06d-eae58106fbb1"
      },
      "source": [
        "embedding.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYxhrkSYjDnr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "results = model.predict(x_test)\n",
        "# Save test embeddings for visualization in projector\n",
        "np.savetxt(\"vecs.tsv\", results, delimiter='\\t')\n",
        "\n",
        "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
        "for labels in y_test:\n",
        "    out_m.write(str(labels) + \"\\n\")\n",
        "out_m.close()\n",
        "\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('vecs.tsv')\n",
        "  files.download('meta.tsv')\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZulGp9ssMm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import umap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXN8UeNjsHqK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "543cd970-92b4-4df0-80b9-b95224e9519b"
      },
      "source": [
        "standard_embedding = umap.UMAP(random_state=42).fit_transform(embedding)\n",
        "plt.scatter(standard_embedding[:, 0], standard_embedding[:, 1], c=y_train, s=2, cmap='Spectral');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b6u7KXestrr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clusterable_embedding = umap.UMAP(\n",
        "    n_neighbors=15,\n",
        "    min_dist=0,\n",
        "    n_components=64,\n",
        "    random_state=42,\n",
        "\n",
        ").fit_transform(embedding)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9M4KHqqxK_q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c5cfa519-219c-4475-ec2e-c3ad66498463"
      },
      "source": [
        "np.sum(clusterable_embedding) / x_test.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6dP34Musy0H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "17485cee-5222-4ef1-c44b-46edfe41bcf9"
      },
      "source": [
        "plt.scatter(clusterable_embedding[:, 0], clusterable_embedding[:, 1],\n",
        "            c=y_train, s=2, cmap='Spectral');\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UClh7jns7QN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = hdbscan.HDBSCAN(\n",
        "    min_samples=5,\n",
        "    min_cluster_size=3,\n",
        ").fit_predict(clusterable_embedding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Rr0NFbTTIkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clusterer = hdbscan.HDBSCAN(\n",
        "    min_samples=2,\n",
        "    min_cluster_size=3,\n",
        "    ).fit(embedding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZRp8R-gTFkK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2586803f-ec6b-43c7-d7bd-503e22ce71f5"
      },
      "source": [
        "print(clusterer.outlier_scores_)\n",
        "print(clusterer.outlier_scores_.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn5HIEfATXRH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "265ef050-133d-4918-8590-2dd2c1649ef6"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.distplot(clusterer.outlier_scores_[np.isfinite(clusterer.outlier_scores_)], rug=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DAMSNyjTw4t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "d928894a-0a67-44b9-8b30-2afcc24a1498"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WufCG1rD2es",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "d324dd5a-51b9-4cc1-b507-f0ad12ce014e"
      },
      "source": [
        "np.unique(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j50339j9wXDY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44871fd5-b19c-432d-b6b4-ecfb7e4d0f5c"
      },
      "source": [
        "#labels = y_test\n",
        "total = len(labels)\n",
        "correct = 0\n",
        "for i in range(len(labels)):\n",
        "  if (labels[i] == y_test[i]):\n",
        "    correct += 1\n",
        "\n",
        "print(correct/total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1bIQeqptApM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c17997e-c2bf-4367-8fc1-415badd3c43d"
      },
      "source": [
        "adjusted_rand_score(y_test, labels), adjusted_mutual_info_score(y_test, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLQIj_-7trxo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bd56f2c5-9e44-42bf-8584-d8a11b65a8eb"
      },
      "source": [
        "clustered = (labels >= 0)\n",
        "(\n",
        "    adjusted_rand_score(y_test[clustered], labels[clustered]),\n",
        "    adjusted_mutual_info_score(y_test[clustered], labels[clustered])\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJhLnIL5xZo8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e2fa4d28-179b-41b8-8ff9-d04f53b4cd5b"
      },
      "source": [
        "np.sum(clustered) / x_test.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P00VkbjfsfgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(\n",
        "    adjusted_rand_score(y_train_lite, kmeans_labels),\n",
        "    adjusted_mutual_info_score(y_train_lite, kmeans_labels)\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pw6IqVLWqaxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  print(parts[-2])\n",
        "  # The second to last is the class-directory\n",
        "  return parts[-2] == CLASS_NAMES\n",
        "\n",
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  return img\n",
        "\n",
        "def process_path_new(file_path):\n",
        "  #print(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  try:\n",
        "    img = decode_img(img)\n",
        "    #print(np.max(img))\n",
        "    #print(\"decoded\")\n",
        "    counter +=1\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  return img, file_path\n",
        "\n",
        "def format_image_new(image, file_path):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image = (image/127.5) - 1\n",
        "  image = tf.image.resize(image, (input_shape[0], input_shape[1]))\n",
        "  return image, file_path\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLp5Y3BY-_Dt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "480dfe01-c79f-40b5-cc0b-1c24b8a1d347"
      },
      "source": [
        "import io\n",
        "\n",
        "\n",
        "def addToDataset(img_path, new_path, model, input_shape, saveEmbeddings = False):\n",
        "  AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "  !rm -rf /content/images\n",
        "  #data = pd.read_csv('dataset.csv')\n",
        "\n",
        "  #labels = data.iloc[:,1]\n",
        "\n",
        "  #names = data.iloc[:,0]\n",
        "  image_aug_path = 'images_aug_path'\n",
        "  image_cropped_path = 'images_cropped_path'\n",
        "\n",
        "  for img in os.listdir(new_path):\n",
        "    image_path = img_path + '/' + img\n",
        "    image = preprocess_images(image_path)\n",
        "    image_path_aug = image_aug_path + '/' + img \n",
        "    plt.imsave(image_path_aug, image)\n",
        "    imageCropped = extract_image_unet(image_path_aug, unet)\n",
        "    image_path_cropped = image_cropped_path + '/' + img \n",
        "    plt.imsave(image_path_cropped, imageCropped)\n",
        "\n",
        "  new_path = image_cropped_path\n",
        "\n",
        "  ds_size = sum(len(files) for _, _, files in os.walk(img_path))\n",
        "  new_ds_size = sum(len(files) for _, _, files in os.walk(new_path))\n",
        "  print(ds_size)\n",
        "  print(new_ds_size)\n",
        "\n",
        "  data_dir = pathlib.Path(img_path)\n",
        "  new_data_dir = pathlib.Path(new_path)\n",
        "\n",
        "  global CLASS_NAMES\n",
        "  CLASS_NAMES = np.array([folder for folder in os.listdir(img_path)])\n",
        "  print(CLASS_NAMES)\n",
        "\n",
        "  new_img_names = np.array([folder for folder in os.listdir(new_path)])\n",
        "  \n",
        "\n",
        "  list_ds = tf.data.Dataset.list_files(str(data_dir)+'/*/*', shuffle=False)\n",
        "  new_list_ds = tf.data.Dataset.list_files(str(new_data_dir)+'/*', shuffle=False)\n",
        "\n",
        "  for img in new_list_ds:\n",
        "    print(img)\n",
        "\n",
        "  labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "  dataset = labeled_ds.map(format_image, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "  new_ds = new_list_ds.map(process_path_new, num_parallel_calls=AUTOTUNE) \n",
        "\n",
        "  new_dataset = new_ds.map(format_image_new, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "  count_label = len(os.listdir(img_path))\n",
        "  #print(count_label)\n",
        "\n",
        "  x = np.zeros((ds_size,input_shape[0],input_shape[1],input_shape[2]))\n",
        "  y = np.zeros((ds_size))\n",
        "  x_new = np.zeros((new_ds_size,input_shape[0],input_shape[1],input_shape[2]))\n",
        "  file_paths = []\n",
        "\n",
        "  k = 0\n",
        "  for image, label in dataset:\n",
        "    #print(label)\n",
        "    x[k,:,:,:] = image\n",
        "    #print(image)\n",
        "    y[k] = np.where(label)[0][0]\n",
        "    k += 1\n",
        "\n",
        "  k = 0\n",
        "  for image, file_path in new_dataset:\n",
        "    x_new[k,:,:,:] = image\n",
        "    file_paths.append(file_path)\n",
        "    #print(file_path)\n",
        "    k += 1\n",
        "\n",
        "  dataset = []\n",
        "\n",
        "    \n",
        "  #Sorting images by classes and normalize values 0=>\n",
        "  for n in range(count_label):\n",
        "    images_class_n = np.asarray([row for idx,row in enumerate(x) if y[idx]==n])\n",
        "    dataset.append(images_class_n)\n",
        "\n",
        "\n",
        "  if(saveEmbeddings):\n",
        "\n",
        "    try:\n",
        "      from google.colab import files\n",
        "      files.download('vecs.tsv')\n",
        "      files.download('meta.tsv')\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  #Compute the center of each class in the embedding space\n",
        "  nb_classes = count_label\n",
        "  print(nb_classes)\n",
        "  probs = np.zeros((new_ds_size))\n",
        "  distances = np.zeros((new_ds_size,nb_classes))\n",
        "  ypreds = np.zeros((new_ds_size,nb_classes))\n",
        "  y = np.zeros((new_ds_size))\n",
        "\n",
        "    \n",
        "  #Compute the embedding of every image \n",
        "  embeddings = model.predict(x)\n",
        "    \n",
        "  size_embedding = embeddings.shape[1]\n",
        "\n",
        "  ref_images = np.zeros((nb_classes,size_embedding))\n",
        "    \n",
        "  #generates embeddings for reference images\n",
        "  for i in range(nb_classes):\n",
        "\n",
        "      selected_ref = dataset[i][:,:,:,:]\n",
        "      ref_images[i,:] = np.mean(model.predict(selected_ref),axis=0)\n",
        "\n",
        "  \n",
        "\n",
        "  for i in range(new_ds_size):\n",
        "\n",
        "    for k in range(nb_classes):\n",
        "\n",
        "      distances[i,k] = compute_dist(ref_images[k,:],model.predict(np.expand_dims(x_new[i,:,:,:], axis=0)))\n",
        "\n",
        "\n",
        "  ypreds = np.argsort(distances,axis=-1)\n",
        "  print(distances)\n",
        "  distances_sorted = np.sort(distances, axis=-1)\n",
        "\n",
        "  min_dist = distances_sorted[:,0]\n",
        "\n",
        "  print(min_dist)\n",
        "  \n",
        "  y_new = ypreds[:,0]\n",
        "\n",
        "  print(y_new)\n",
        "\n",
        "  #display embedding\n",
        "  results = model.predict(x_new)\n",
        "  # Save test embeddings for visualization in projector\n",
        "  np.savetxt(\"vecs.tsv\", results, delimiter='\\t')\n",
        "\n",
        "  out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
        "  for labels in y_new:\n",
        "    out_m.write(str(labels) + \"\\n\")\n",
        "  out_m.close()\n",
        "  \n",
        "  class_identified = CLASS_NAMES[y_new]\n",
        "\n",
        "  print(class_identified)\n",
        "\n",
        "  #dist_test = compute_dist(ref_images[13,:],model.predict(np.expand_dims(x_new[0,:,:,:], axis=0)))\n",
        "  #plt.imshow(x_new[0,:,:,:])\n",
        "  #plt.show()\n",
        "  #print(dist_test)\n",
        "  threshold = 300\n",
        "  ids = np.arange(new_ds_size)\n",
        "  ids_new = np.where(min_dist > threshold)[0]\n",
        "  ids_old = [id for id in ids if id not in ids_new]\n",
        "  print(ids)\n",
        "\n",
        "  threshold_new = 400\n",
        "\n",
        "  same_newts_ids = distinguishNewNewts(min_dist, ids_new, threshold_new, x_new)\n",
        "\n",
        "  ids_to_remove = []\n",
        "\n",
        "  for i in range(len(same_newts_ids)):\n",
        "    if (same_newts_ids[i][1] not in ids_to_remove):\n",
        "      ids_to_remove.append(same_newts_ids[i][1])\n",
        "  \n",
        "\n",
        "  print(ids_to_remove)\n",
        "\n",
        "  ids_to_keep = []\n",
        "\n",
        "  for i in range(len(same_newts_ids)):\n",
        "    if ((same_newts_ids[i][0] not in ids_to_remove) and (same_newts_ids[i][0] not in ids_to_keep)):\n",
        "      ids_to_keep.append(same_newts_ids[i][0])\n",
        "  \n",
        "  data = pd.read_csv('/content/data.csv')\n",
        "  labels_unique = np.unique(data.iloc[:,1])\n",
        "  if (labels_unique.size == 0):\n",
        "    labels_unique = 0\n",
        "  for i in range(len(ids_to_keep)):\n",
        "    y_new[ids_to_keep[i]] = np.max(labels_unique) + i + 1\n",
        "\n",
        "  \n",
        "  ids_to_keep = ids_to_keep + ids_old\n",
        "  y_new_kept = y_new[ids_to_keep]\n",
        "\n",
        "  print(ids_to_keep)\n",
        "\n",
        "  x_new_kept = x_new[ids_to_keep,:,:,:]\n",
        "\n",
        "  \n",
        "  \n",
        "  file_paths_kept = []\n",
        "\n",
        "  print(len(file_paths))\n",
        "  for i in range(new_ds_size):\n",
        "    if (i not in ids_to_remove):\n",
        "      \n",
        "      file_path = tf.strings.split(file_paths[i], os.path.sep)\n",
        "      file_name = file_path[-1].numpy().decode(\"utf-8\")\n",
        "      print(file_name)\n",
        "      file_paths_kept.append(file_name)\n",
        "  #print(f_kept)\n",
        "  print(file_paths_kept)\n",
        "  #for k in range(x_new_kept.shape[0]):\n",
        "  x_new_kept = ((x_new_kept+1)*127.5)/255\n",
        "\n",
        "  print(x_new_kept.shape)\n",
        "  print(np.min(x_new_kept))\n",
        "\n",
        "  \n",
        "  temp_folder = 'images'\n",
        "  os.mkdir(temp_folder)\n",
        "  \n",
        "  rows_list = []\n",
        "  #data.head()\n",
        "  for i in range(x_new_kept.shape[0]):\n",
        "    plt.imsave(temp_folder+ '/'+ str(file_paths_kept[i]), x_new_kept[i,:,:,:])\n",
        "    dict1 = {\n",
        "            \"file_name\": str(file_paths_kept[i]),\n",
        "             \"label\": y_new_kept[i]\n",
        "        }\n",
        "    rows_list.append(dict1)\n",
        "\n",
        "  df = pd.DataFrame(rows_list, columns=['file_name', 'label'])\n",
        "  print(data.shape)\n",
        "  data = data.append(df)\n",
        "  #data.tail()\n",
        "  print(data.shape)\n",
        "  data.to_csv (r'data.csv', index = False, header=True)\n",
        "\n",
        "  #os.remove(\"demofile.txt\") \n",
        "\n",
        "  #preprocess_newts(img_path,aug_path,final_path,input_shape)\n",
        "\n",
        "  print(\"number of different newts : \"+ str(count_label))\n",
        "\n",
        "  return x_new_kept,y_new_kept,file_paths_kept\n",
        "\n",
        "#model = load_model('saved_cnn')\n",
        "img_path = '/content/ds_final_unet_lite/content/ds_final/train'\n",
        "new_path = '/content/images_newts'\n",
        "input_shape = (75,30,3)\n",
        "\n",
        "dist = addToDataset(img_path, new_path, model, input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI8e3vAv4nEk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "c873ea7b-eaa5-4b8f-e806-3822e17ac9fc"
      },
      "source": [
        "data = pd.read_csv('/content/data.csv')\n",
        "\n",
        "print(data.iloc[:,0].shape)\n",
        "print(data.tail())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpPNnm2YB3lr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86fiCXM0CV5e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932
        },
        "outputId": "5b41f186-775e-4e26-c383-913f2b18635f"
      },
      "source": [
        "temp_dir = '/content/temp'\n",
        "\n",
        "for img in os.listdir(temp_dir):\n",
        "  img = plt.imread(temp_dir + '/' + img)\n",
        "  plt.imshow(img)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWxgBZ92uCIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def distinguishNewNewts(dist, ids, threshold_new, x_new):\n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "  distances = np.zeros((len(ids),len(ids)))\n",
        "\n",
        "  print(distances)\n",
        "\n",
        "  n = distances.shape[0]\n",
        "\n",
        "  for i in range(n):\n",
        "    for j in range(n):\n",
        "      distances[i,j] = compute_dist(model.predict(np.expand_dims(x_new[ids[i],:,:,:], axis=0)), \n",
        "                                    model.predict(np.expand_dims(x_new[ids[j],:,:,:], axis=0)))\n",
        "  \n",
        "  mask = [[1 if x>y else 0 for x in range(n)] for y in range(n)]\n",
        "\n",
        "  mask = np.array(mask)\n",
        "\n",
        "  print(mask)\n",
        "\n",
        "  distances = distances*mask\n",
        "\n",
        "  print(distances)\n",
        "\n",
        "  \n",
        "\n",
        "  distances = np.where((distances < threshold_new) & (distances > 0))\n",
        "\n",
        "  print(distances)\n",
        "\n",
        "  same_newts = []\n",
        "  for i in range(len(distances[0])):\n",
        "    same_newts.append((ids[distances[0][i]],ids[distances[1][i]]))\n",
        "\n",
        "  print(same_newts)\n",
        "\n",
        "\n",
        "  return same_newts\n",
        "\n",
        "  #id = names.loc[im.name]\n",
        "  #print(id)\n",
        "  #label = labels.iloc[id]\n",
        "  #print('label : '+label)\n",
        "  #id_label = np.where(labels_uniques == label)\n",
        "  #print(id_label)\n",
        "  #imagePath = basepath + '/' + im.name\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTyHsoieDCW2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "40031b0f-8110-41f3-c6c7-56868f884289"
      },
      "source": [
        "\n",
        "def random_saturation(rgb, show_result = False):\n",
        "  \"\"\" Modify randomly the saturation of the input image \"\"\"\n",
        "  hsv = skimage.color.rgb2hsv(rgb)\n",
        "\n",
        "  #plt.imshow(hsv)\n",
        "  saturation = uniform(-0.35, 0.35)\n",
        "  \n",
        "  #print(hsv[:,:,1])\n",
        "  hsv[:,:,1] = hsv[:,:,1] + saturation\n",
        "  #print(np.max(lab[:,:,0]))\n",
        "  #print(hsv[:,:,1])\n",
        "  rgb = skimage.color.hsv2rgb(hsv)\n",
        "\n",
        "  if show_result:\n",
        "    plt.imshow(rgb)\n",
        "    plt.show()\n",
        "\n",
        "  return rgb\n",
        "\n",
        "def random_brightness(rgb, show_result = False):\n",
        "  \"\"\" Modify randomly the brightness of the input image \"\"\"\n",
        "  lab = skimage.color.rgb2lab(rgb)\n",
        "\n",
        "  #plt.imshow(lab)\n",
        "  brightness = uniform(-20, 20)\n",
        "  \n",
        "  #print(lab[:,:,0])\n",
        "  lab[:,:,0] = lab[:,:,0] + brightness\n",
        "  #print(np.max(lab[:,:,0]))\n",
        "  #print(lab[:,:,0])\n",
        "  rgb = skimage.color.lab2rgb(lab)\n",
        "  if show_result:\n",
        "    plt.imshow(rgb)\n",
        "    plt.show()\n",
        "\n",
        "  return rgb\n",
        "\n",
        "def preprocess_images(image_path):\n",
        "  \"\"\" apply all augmentation methods defined above on the image \"\"\"\n",
        "\n",
        "  image = img_as_float(io.imread(image_path))\n",
        "  image = exposure.equalize_adapthist(image, clip_limit=0.03)\n",
        "  image = random_saturation(image, show_result=False)\n",
        "  image = random_brightness(image, show_result=False)\n",
        "     \n",
        "      \n",
        "  image = image*255\n",
        "      \n",
        "  shear = uniform(-.1, .1)\n",
        "  tfr = AffineTransform(shear=shear)\n",
        "  sheared = transform.warp(image, tfr, order=1, preserve_range=True,mode='constant', cval=255)\n",
        "  \n",
        "  strength = uniform(-1, 1)\n",
        "  image = swirl(sheared, rotation=0, strength=strength, radius=500,mode='constant', cval=255)\n",
        "\n",
        "\n",
        "  return image\n",
        "\n",
        "def augmentationImages(img_path, img_aug_path):\n",
        "\n",
        "  \"\"\" Create a proper dataset where each folder contains the images of one \n",
        "  specimen, randomly augmented 20 times for each \"real\" image present in the \n",
        "  original dataset \"\"\"\n",
        "\n",
        "  !rm -rf /content/imagesAug #useful when running the method again for makedirs\n",
        "  #if (len(os.listdir(img_aug_path)) == 0):\n",
        "  #with open('dataset.csv', 'rb') as f:\n",
        "   # data = f.read()\n",
        "\n",
        "  data = pd.read_csv('data.csv')\n",
        "\n",
        "  labels = data.iloc[:,1]\n",
        "\n",
        "  names = data.iloc[:,0]\n",
        "\n",
        "  labels_uniques, counts = np.unique(labels, return_counts=True)\n",
        "  print(labels_uniques)\n",
        "  #list_images = os.listdir(img_path)\n",
        "  #labels_uniques = len(list_images) #We assume newts from the first session are all different\n",
        "  \n",
        "\n",
        "  for label in labels_uniques:\n",
        "    if (not os.path.isdir(img_aug_path + '/' + str(label))):\n",
        "      os.makedirs(img_aug_path + '/' + str(label))\n",
        " \n",
        "\n",
        "  print(\"Creating the augmented dataset...\")\n",
        "  # List all files in a directory using scandir()\n",
        "  basepath = img_path\n",
        "  with os.scandir(basepath) as images:\n",
        "    for im in images:\n",
        "      print(im.name)\n",
        "      \n",
        "      if(im.name in names.values):\n",
        "        \n",
        "        id = names[names == im.name].index[0]\n",
        "  \n",
        "        label = labels.iloc[id]\n",
        "\n",
        "        id_label = np.where(labels_uniques == label)\n",
        "\n",
        "        imagePath = basepath + '/' + im.name\n",
        "\n",
        "        count = counts[id_label]\n",
        "\n",
        "        print(count)\n",
        "        \n",
        "        k = 0\n",
        "        while (k < 20 // count):  \n",
        "          image = preprocess_images(imagePath)\n",
        "          \n",
        "          augPath = img_aug_path+'/'+str(label)+'/' + im.name[:-4] + str(k) + '.jpg'\n",
        "          image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "          plt.imsave(augPath, image/255)\n",
        "          k += 1\n",
        "\n",
        "\n",
        "def create_mask(pred_mask):\n",
        "  pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "  pred_mask = pred_mask[..., tf.newaxis]\n",
        "  \n",
        "\n",
        "  #pred_mask = area_closing(pred_mask, area_threshold=4, connectivity=1, parent=None, tree_traverser=None)tf.keras.preprocessing.image.img_to_array\n",
        "\n",
        "  return pred_mask[0]\n",
        "\n",
        "def extract_image_unet(img_path, model):\n",
        "  \"\"\" method used to extract the greatest region in the mask output of the \n",
        "  Unet. \n",
        "  \"\"\"\n",
        "  image = plt.imread(img_path)\n",
        "  image = resize(image, (128,128,3), preserve_range=True)\n",
        "  pred_mask = create_mask(model.predict(image[tf.newaxis, ...]/255))\n",
        "  image = resize(image, (200,50,3), preserve_range=True)\n",
        "    \n",
        "  pred_mask = tf.keras.preprocessing.image.img_to_array(pred_mask)\n",
        "\n",
        "   \n",
        "  selem = skimage.morphology.disk(6)\n",
        "  pred_mask = closing(np.squeeze(pred_mask*255), selem)\n",
        "  pred_mask = opening(np.squeeze(pred_mask), selem)\n",
        "\n",
        "  pred_mask = resize(pred_mask, (200,50, 1), preserve_range=True)\n",
        "  \n",
        "\n",
        "  try:\n",
        "    labels_mask = measure.label(pred_mask) \n",
        "  except ValueError:  #raised if `y` is empty.\n",
        "    print('no region found.')\n",
        "    return image\n",
        "   \n",
        "\n",
        "  try:\n",
        "    regions = measure.regionprops(labels_mask)\n",
        "  except ValueError:  #raised if `y` is empty.\n",
        "    print(\"no region found.\")\n",
        "    return image\n",
        "  regions.sort(key=lambda x: x.area, reverse=True)\n",
        "\n",
        "  if len(regions) > 1:\n",
        "    for rg in regions[1:]:\n",
        "        labels_mask[rg.coords[:,0], rg.coords[:,1]] = 0\n",
        "\n",
        "\n",
        "  labels_mask[labels_mask!=0] = 1\n",
        "  mask = labels_mask\n",
        "\n",
        "  skeleton = skeletonize(rescale_intensity(tf.keras.preprocessing.image.img_to_array(mask),in_range=(-1,1)))\n",
        "\n",
        "\n",
        "  if mask.shape[-1] > 0:\n",
        "    # We're treating all instances as one, so collapse the mask into one layer\n",
        "    mask = (np.sum(mask, -1, keepdims=True) >= 1)\n",
        "    img_extracted = np.where(mask, image, 255).astype(np.uint8)\n",
        "    image = img_extracted/255\n",
        "\n",
        "\n",
        "  skeleton = np.where(np.squeeze(skeleton) > 0)\n",
        "  skeleton = np.array(skeleton)\n",
        "\n",
        "  a = skeleton[0]\n",
        "  b = skeleton[1]\n",
        " \n",
        "  s = pd.Series(np.squeeze(a))\n",
        "  #print(s.values)\n",
        "  #print(s[s.duplicated()].index)\n",
        "  duplicates = s[s.duplicated()].index\n",
        " \n",
        "  #duplicate = 0\n",
        "  skel_size = skeleton[0].shape[0]\n",
        "  \n",
        "  shifts = []\n",
        "  center = int(pred_mask.shape[1]/2)\n",
        "  i = 0\n",
        "  dups = []\n",
        "  while (i < skel_size):\n",
        "  \n",
        "\n",
        "    if (i in duplicates and not i in dups):\n",
        "     \n",
        "      dups.append(i)\n",
        "      \n",
        "      d = skeleton[1][skeleton[0] == s[i]]\n",
        "     \n",
        "      mid = int(np.mean(d))\n",
        "    \n",
        "      \n",
        "   \n",
        "      diff = mid-center\n",
        "      shifts[-1] = -diff\n",
        "    \n",
        "      i += 1\n",
        "      \n",
        "    elif (i in duplicates and i in dups):\n",
        "      continue\n",
        "    else:\n",
        "      diff = skeleton[1][i]-center\n",
        "      \n",
        "      shifts.append(-diff)\n",
        "      i += 1\n",
        "  \n",
        "  \n",
        "  k = 0\n",
        "  img = image.copy()\n",
        "\n",
        "  for diff in shifts:\n",
        "    \n",
        "    image[s.unique()[k],:,0] = shift(image[s.unique()[k],:,0], diff , output=None, order=3, mode='wrap', prefilter=False)\n",
        "    image[s.unique()[k],:,1] = shift(image[s.unique()[k],:,1], diff , output=None, order=3, mode='wrap', prefilter=False)\n",
        "    image[s.unique()[k],:,2] = shift(image[s.unique()[k],:,2], diff , output=None, order=3, mode='wrap', prefilter=False)\n",
        "    \n",
        "    k += 1\n",
        "\n",
        "\n",
        "  for i in range (image.shape[0]):\n",
        "    if (not i in skeleton[0]):\n",
        "      image[i,:] = 1\n",
        "\n",
        "  white = np.array([1, 1, 1])\n",
        "  mask = np.abs(image - white).sum(axis=2) < 0.05\n",
        "\n",
        "  # Find the bounding box of those pixels\n",
        "  try:\n",
        "    coords = np.array(np.nonzero(~mask))\n",
        "    top_left = np.min(coords, axis=1)\n",
        "    bottom_right = np.max(coords, axis=1)\n",
        "  \n",
        "    out = image[top_left[0]:bottom_right[0],\n",
        "            top_left[1]:bottom_right[1]]\n",
        "    \n",
        "  except:\n",
        "    return None\n",
        "  \n",
        "  return out\n",
        "\n",
        "\n",
        "\n",
        "def extract_crop(ds_path, ds_final_path, input_shape, model):\n",
        "  \"\"\" take the proper dataset created by augmentationImages and extract the newts\n",
        "  by segmenting and cropping the pattern of interest \"\"\"\n",
        "   \n",
        "  !rm -rf /content/imagesCropped\n",
        "\n",
        "    \n",
        "\n",
        "  for class_name in os.listdir(ds_path):\n",
        "      \n",
        "      #print(class_name)\n",
        "      dsPath = ds_path + '/' + class_name\n",
        "      #print(dsPath)\n",
        "      dsFinalPath = ds_final_path + '/' + class_name\n",
        "\n",
        "      for img_name in os.listdir(dsPath):\n",
        "\n",
        "        #if os.path.isfile(img_name):\n",
        "        \n",
        "          #print(img_name)\n",
        "          imagePath = dsPath + '/' + img_name\n",
        "          print(imagePath)\n",
        "          augPath = dsFinalPath + '/' + img_name\n",
        "          if not (os.path.isdir(dsFinalPath)):\n",
        "            os.makedirs(dsFinalPath)\n",
        "          \n",
        "          image = extract_image_unet(imagePath, model)\n",
        "          try:\n",
        "          #plt.imshow(image)\n",
        "          #plt.show()\n",
        "\n",
        "            height = input_shape[0]\n",
        "            width = input_shape[1]\n",
        "          #print(np.max(image))\n",
        "          #print(np.min(image))\n",
        "  \n",
        "            if (image.shape[0] < image.shape[1]):\n",
        "            #image = tf.image.resize(image, [width, height])\n",
        "              image = resize(image, (width, height),\n",
        "                       anti_aliasing=False)\n",
        "            #print(\"height < width\")\n",
        "              image = np.transpose(image,(1,0,2))\n",
        "            else:\n",
        "            #image = tf.image.resize(image, [height, width])\n",
        "              image = resize(image, (height, width),\n",
        "                       anti_aliasing=False)\n",
        "        \n",
        "          #image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "         \n",
        "          #plt.imshow(image)\n",
        "          #plt.show()\n",
        "            plt.imsave(augPath, image)\n",
        "          \n",
        "          except:\n",
        "            pass  \n",
        "\n",
        "def preprocess_newts(dataset_path, img_aug_path, final_path, input_shape):\n",
        "  \"\"\" take as input a folder of images, augment the images,\n",
        "      extract the pattern of the newts, and straighten them automatically.\n",
        "      Create the resulting dataset \"\"\"\n",
        "  #Handle the augmentations for each image\n",
        "  augmentationImages(dataset_path, img_aug_path)\n",
        "  #Handle the pattern extraction and the straightening\n",
        "  Unet = tf.keras.models.load_model('my_model_Unet')\n",
        "  extract_crop(img_aug_path, final_path, input_shape, Unet)\n",
        "\n",
        "dataset_path = '/content/images'\n",
        "img_aug_path = '/content/imagesAug'\n",
        "final_path = '/content/imagesCropped'\n",
        "input_shape = (75,30,3)\n",
        "preprocess_newts(dataset_path,img_aug_path,final_path,input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wv6901iWK2hy",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate the model with the two metrics used in the paper : "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldqCo6yVDEnv",
        "colab_type": "text"
      },
      "source": [
        "## Mean Average Precision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIKTfSkhM5mg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5c691833-414b-4676-c324-935cc5578705"
      },
      "source": [
        "#print(dataset_train)\n",
        "MAP = mean_average_precision(x_test,y_test,model,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl1XS8wSDJYv",
        "colab_type": "text"
      },
      "source": [
        "## Cumulative Matching Characteristc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZXDLKp_pZT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CMC = cumulative_matching_curve(x_test,y_test,model,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4ZFdbrfvCCQ",
        "colab_type": "text"
      },
      "source": [
        "# Full Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z8MN-AcvFj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def random_saturation(rgb, show_result = False):\n",
        "  \"\"\" Modify randomly the saturation of the input image \"\"\"\n",
        "  hsv = skimage.color.rgb2hsv(rgb)\n",
        "\n",
        "  #plt.imshow(hsv)\n",
        "  saturation = uniform(-0.35, 0.35)\n",
        "  \n",
        "  #print(hsv[:,:,1])\n",
        "  hsv[:,:,1] = hsv[:,:,1] + saturation\n",
        "  #print(np.max(lab[:,:,0]))\n",
        "  #print(hsv[:,:,1])\n",
        "  rgb = skimage.color.hsv2rgb(hsv)\n",
        "\n",
        "  if show_result:\n",
        "    plt.imshow(rgb)\n",
        "    plt.show()\n",
        "\n",
        "  return rgb\n",
        "\n",
        "def random_brightness(rgb, show_result = False):\n",
        "  \"\"\" Modify randomly the brightness of the input image \"\"\"\n",
        "  lab = skimage.color.rgb2lab(rgb)\n",
        "\n",
        "  #plt.imshow(lab)\n",
        "  brightness = uniform(-20, 20)\n",
        "  \n",
        "  #print(lab[:,:,0])\n",
        "  lab[:,:,0] = lab[:,:,0] + brightness\n",
        "  #print(np.max(lab[:,:,0]))\n",
        "  #print(lab[:,:,0])\n",
        "  rgb = skimage.color.lab2rgb(lab)\n",
        "  if show_result:\n",
        "    plt.imshow(rgb)\n",
        "    plt.show()\n",
        "\n",
        "  return rgb\n",
        "\n",
        "def preprocess_images(image_path, input_shape):\n",
        "  \"\"\" apply all augmentation methods defined above on the image \"\"\"\n",
        "\n",
        "  image = img_as_float(io.imread(image_path))\n",
        "  image = exposure.equalize_adapthist(image, clip_limit=0.03)\n",
        "  image = random_saturation(image, show_result=False)\n",
        "  image = random_brightness(image, show_result=False)\n",
        "     \n",
        "      \n",
        "  image = image*255\n",
        "      \n",
        "  shear = uniform(-.1, .1)\n",
        "  tfr = AffineTransform(shear=shear)\n",
        "  sheared = transform.warp(image, tfr, order=1, preserve_range=True,mode='constant', cval=255)\n",
        "  \n",
        "  strength = uniform(-1, 1)\n",
        "  image = swirl(sheared, rotation=0, strength=strength, radius=500,mode='constant', cval=255)\n",
        "\n",
        "\n",
        "  return image\n",
        "\n",
        "def augmentationImageUnet(img_path,img_aug_path, input_shape):\n",
        "\n",
        "  \"\"\" Create a proper dataset where each folder contains the images of one \n",
        "  specimen, randomly augmented 20 times for each \"real\" image present in the \n",
        "  original dataset \"\"\"\n",
        "\n",
        "  !rm -rf /content/databaseAug #useful when running the method again for makedirs\n",
        "  data = pd.read_csv('/content/Stage_Tritons/training.csv')\n",
        "\n",
        "  labels = data.iloc[:,4]\n",
        "\n",
        "  names = data.iloc[:,0]\n",
        "\n",
        "  labels_uniques, counts = np.unique(labels, return_counts=True)\n",
        "  \n",
        "\n",
        "  for label in labels_uniques:\n",
        "    os.makedirs(img_aug_path+'/'+label)\n",
        "\n",
        "\n",
        "  print(\"Création de la base de données augmentées en cours...\")\n",
        "  # List all files in a directory using scandir()\n",
        "  basepath = img_path\n",
        "  with os.scandir(basepath) as images:\n",
        "    for im in images:\n",
        "\n",
        "      if(im.name in names.values):\n",
        "        \n",
        "        id = names[names == im.name].index[0]\n",
        "  \n",
        "        label = labels.iloc[id]\n",
        "\n",
        "        id_label = np.where(labels_uniques == label)\n",
        "\n",
        "        imagePath = basepath + '/' + im.name\n",
        "\n",
        "        count = counts[id_label]\n",
        "        \n",
        "        k = 0\n",
        "        while (k < 20):  \n",
        "          image = preprocess_images(imagePath, input_shape)\n",
        "          \n",
        "          augPath = img_aug_path+'/'+label+'/' + im.name[:-4] + str(k) + '.jpg'\n",
        "          image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "          plt.imsave(augPath, image/255)\n",
        "          k += 1\n",
        "  \n",
        "  \n",
        "\n",
        "def extract_image_unet(img_path):\n",
        "  \"\"\" method used to extract the greatest region in the mask output of the \n",
        "  Unet. \n",
        "  \"\"\"\n",
        "  image = plt.imread(img_path)\n",
        "  image = resize(image, (128,128,3), preserve_range=True)\n",
        "  pred_mask = create_mask(model.predict(image[tf.newaxis, ...]/255))\n",
        "  image = resize(image, (200,50,3), preserve_range=True)\n",
        "    \n",
        "  pred_mask = tf.keras.preprocessing.image.img_to_array(pred_mask)\n",
        "\n",
        "   \n",
        "  selem = morphology.disk(6)\n",
        "  pred_mask = closing(np.squeeze(pred_mask*255), selem)\n",
        "  pred_mask = opening(np.squeeze(pred_mask), selem)\n",
        "\n",
        "  pred_mask = resize(pred_mask, (200,50, 1), preserve_range=True)\n",
        "  \n",
        "\n",
        "  try:\n",
        "    labels_mask = measure.label(pred_mask) \n",
        "  except ValueError:  #raised if `y` is empty.\n",
        "    print('no region found.')\n",
        "    return image\n",
        "   \n",
        "\n",
        "  try:\n",
        "    regions = measure.regionprops(labels_mask)\n",
        "  except ValueError:  #raised if `y` is empty.\n",
        "    print(\"no region found.\")\n",
        "    return image\n",
        "  regions.sort(key=lambda x: x.area, reverse=True)\n",
        "\n",
        "  if len(regions) > 1:\n",
        "    for rg in regions[1:]:\n",
        "        labels_mask[rg.coords[:,0], rg.coords[:,1]] = 0\n",
        "\n",
        "\n",
        "  labels_mask[labels_mask!=0] = 1\n",
        "  mask = labels_mask\n",
        "\n",
        "  skeleton = skeletonize(rescale_intensity(tf.keras.preprocessing.image.img_to_array(mask),in_range=(-1,1)))\n",
        "\n",
        "\n",
        "  if mask.shape[-1] > 0:\n",
        "    # We're treating all instances as one, so collapse the mask into one layer\n",
        "    mask = (np.sum(mask, -1, keepdims=True) >= 1)\n",
        "    img_extracted = np.where(mask, image, 255).astype(np.uint8)\n",
        "    image = img_extracted/255\n",
        "\n",
        "\n",
        "  skeleton = np.where(np.squeeze(skeleton) > 0)\n",
        "  skeleton = np.array(skeleton)\n",
        "\n",
        "  a = skeleton[0]\n",
        "  b = skeleton[1]\n",
        " \n",
        "  s = pd.Series(np.squeeze(a))\n",
        "#print(s.values)\n",
        "#print(s[s.duplicated()].index)\n",
        "  duplicates = s[s.duplicated()].index\n",
        " \n",
        "  duplicate = 0\n",
        "  skel_size = skeleton[0].shape[0]\n",
        "  \n",
        "  shifts = []\n",
        "  center = int(pred_mask.shape[1]/2)\n",
        "  i = 0\n",
        "  dups = []\n",
        "  while (i < skel_size):\n",
        "  \n",
        "\n",
        "    if (i in duplicates and not i in dups):\n",
        "     \n",
        "      dups.append(i)\n",
        "      \n",
        "      d = skeleton[1][skeleton[0] == s[i]]\n",
        "     \n",
        "      mid = int(np.mean(d))\n",
        "    \n",
        "      \n",
        "   \n",
        "      diff = mid-center\n",
        "      shifts[-1] = -diff\n",
        "    \n",
        "      i += 1\n",
        "      \n",
        "    elif (i in duplicates and i in dups):\n",
        "      continue\n",
        "    else:\n",
        "      diff = skeleton[1][i]-center\n",
        "      \n",
        "      shifts.append(-diff)\n",
        "      i += 1\n",
        "  \n",
        "  \n",
        "  k = 0\n",
        "  img = image.copy()\n",
        "\n",
        "  for diff in shifts:\n",
        "    \n",
        "    image[s.unique()[k],:,0] = shift(image[s.unique()[k],:,0], diff , output=None, order=3, mode='wrap', prefilter=False)\n",
        "    image[s.unique()[k],:,1] = shift(image[s.unique()[k],:,1], diff , output=None, order=3, mode='wrap', prefilter=False)\n",
        "    image[s.unique()[k],:,2] = shift(image[s.unique()[k],:,2], diff , output=None, order=3, mode='wrap', prefilter=False)\n",
        "    \n",
        "    k += 1\n",
        "\n",
        "\n",
        "  for i in range (image.shape[0]):\n",
        "    if (not i in skeleton[0]):\n",
        "      image[i,:] = 1\n",
        "\n",
        "  white = np.array([1, 1, 1])\n",
        "  mask = np.abs(image - white).sum(axis=2) < 0.05\n",
        "\n",
        "  # Find the bounding box of those pixels\n",
        "  try:\n",
        "    coords = np.array(np.nonzero(~mask))\n",
        "    top_left = np.min(coords, axis=1)\n",
        "    bottom_right = np.max(coords, axis=1)\n",
        "  \n",
        "    out = image[top_left[0]:bottom_right[0],\n",
        "            top_left[1]:bottom_right[1]]\n",
        "    \n",
        "  except:\n",
        "    return None\n",
        "\n",
        "\n",
        "def extract_crop(ds_path, ds_final_path, input_shape):\n",
        "  \"\"\" take the proper dataset created by augmentationImage and extract the newts\n",
        "  by segmenting and cropping \"\"\"\n",
        "   \n",
        "  !rm -rf /content/ds_final\n",
        "\n",
        "  \n",
        "\n",
        "    \n",
        "\n",
        "  for class_name in os.listdir(ds_path):\n",
        "      \n",
        "      #print(class_name)\n",
        "      dsPath = ds_path + '/' + class_name\n",
        "      #print(dsPath)\n",
        "      dsFinalPath = final_path + '/' + class_name\n",
        "\n",
        "      for img_name in os.listdir(dsPath):\n",
        "\n",
        "        #if os.path.isfile(img_name):\n",
        "        \n",
        "          #print(img_name)\n",
        "          imagePath = dsPath + '/' + img_name\n",
        "          print(imagePath)\n",
        "          augPath = dsFinalPath + '/' + img_name\n",
        "          if not (os.path.isdir(dsFinalPath)):\n",
        "            os.makedirs(dsFinalPath)\n",
        "          \n",
        "          image = extract_image_unet(imagePath)\n",
        "          try:\n",
        "          #plt.imshow(image)\n",
        "          #plt.show()\n",
        "\n",
        "            height = input_shape[0]\n",
        "            width = input_shape[1]\n",
        "          #print(np.max(image))\n",
        "          #print(np.min(image))\n",
        "  \n",
        "            if (image.shape[0] < image.shape[1]):\n",
        "            #image = tf.image.resize(image, [width, height])\n",
        "              image = resize(image, (width, height),\n",
        "                       anti_aliasing=False)\n",
        "            #print(\"height < width\")\n",
        "              image = np.transpose(image,(1,0,2))\n",
        "            else:\n",
        "            #image = tf.image.resize(image, [height, width])\n",
        "              image = resize(image, (height, width),\n",
        "                       anti_aliasing=False)\n",
        "        \n",
        "          #image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "         \n",
        "          #plt.imshow(image)\n",
        "          #plt.show()\n",
        "            plt.imsave(augPath, image)\n",
        "          \n",
        "          except:\n",
        "            pass  \n",
        "\n",
        "  return out\n",
        "\n",
        "input_shape = (75,30,3)\n",
        "\n",
        "def preprocess_new_newt(dataset_path, final_path, input_shape):\n",
        "  \"\"\" take as input a folder of images, augment the images,\n",
        "      extract the pattern of the newts, and straighten them automatically.\n",
        "      Create the resulting dataset \"\"\"\n",
        "\n",
        "  #Handle the augmentations for each image\n",
        "  augmentationImageUnet(dataset_path, img_aug_path, input_shape)\n",
        "  #Handle the pattern extraction and the straightening\n",
        "  extract_crop(img_aug_path, final_path, input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3v8KTtevXZA",
        "colab_type": "text"
      },
      "source": [
        "# Online training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkq-egjWvaYv",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}